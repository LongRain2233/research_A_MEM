# Graph-Augmented Large Language Model Agents: Current Progress and Future Prospects

 https://github.com/Shiy-Li/Awesome-Graph-augmented-LLM-Agent

Yixin Liu1, Guibin Zhang2, Kun Wang3, Shiyuan Li1, Shirui Pan1

1Griffith University, Gold Coast, QLD, 4215, Australia 2National University of Singapore, Singapore, 119077, Singapore 3Nanyang Technological University, Singapore, 639798, Singapore Correspondence: s.pan@griffith.edu.au

# Abstract

Autonomous agents based on large language models (LLMs) have demonstrated impressive capabilities in a wide range of applications, including web navigation, software development, and embodied control. While most LLMs are limited in several key agentic procedures, such as reliable planning, long-term memory, tool management, and multi-agent coordination, graphs can serve as a powerful auxiliary structure to enhance structure, continuity, and coordination in complex agent workflows. Given the rapid growth and fragmentation of research on Graph-augmented LLM Agents (GLA), this paper offers a timely and comprehensive overview of recent advances and also highlights key directions for future work. Specifically, we categorize existing GLA methods by their primary functions in LLM agent systems, including planning, memory, and tool usage, and then analyze how graphs and graph learning algorithms contribute to each. For multi-agent systems, we further discuss how GLA solutions facilitate the orchestration, efficiency optimization, and trustworthiness of MAS. Finally, we highlight key future directions to advance this field, from improving structural adaptability to enabling unified, scalable, and multimodal GLA systems. We hope this paper can serve as a roadmap for future research on GLA and foster a deeper understanding of the role of graphs in LLM agent systems.

# 1 Introduction

The emergence of large language models (LLMs), such as GPT-4 (Achiam et al., 2023), Gemini (Team et al., 2024), and DeepSeek (Liu et al., 2024a), has brought about a paradigm shift in the design of autonomous agent systems (Wang et al., 2024; Guo et al., 2024; Xi et al., 2025). By leveraging LLMs as central reasoning engines, a new generation of LLM-based autonomous agents (LLM

![](images/15a504a29fdc26dccd46807c9ec987dcfc866180a1506fee4274bf61fa11fb24.jpg)  
Figure 1: LLM agent framework and multi-agent system.

agents for short) has demonstrated promising capabilities in understanding natural language instructions, executing multi-step tasks, and coordinating with external tools or services (Zhang et al., 2025a; Wu et al., 2024a; Zhai et al., 2024). The emergence of LLM agents enables them to tackle challenges once considered beyond the reach of artificial intelligence, opening doors to novel applications across a broad range of fields, such as software development (Manish, 2024), scientific research (M. Bran et al., 2024), financial analysis (Yu et al., 2024), etc.

Despite the impressive language understanding and reasoning capabilities of LLMs, they are insufficient on their own to support all key functionalities required in autonomous agent systems. As shown in Figure 1, while LLMs serve as powerful cores for agent systems to interpret perceptions and make high-level decisions, they must be complemented with dedicated modules for planning, memory, and tool using, where LLMs may not perform reliably or efficiently. Firstly, LLMs may perform unreliable task planning due to their tendency to hallucinate and limited understanding of multi-step dependencies (Wu et al., 2024b). Secondly, LLMs struggle to maintain long-term memory efficiently in agent systems, primarily due to their stateless architecture and the constraints of a limited context window (Fan et al., 2024). Thirdly, LLMs are inherently difficult to manage and invoke large toolsets due to their limited capacity for accurate selection, tool disambiguation, and consis-

![](images/23218e9f9bb9415689759498bd424de7b787f91dda0212c3429c34bb4ccaccb3.jpg)  
Figure 2: Different graphs in LLM agent systems.

tent reasoning over unfamiliar or similar tools (Liu et al., 2024b). Moreover, when we extend a single agent to multi-agent systems, how to manage interagent communication and coordination remains an open question for LLMs (Guo et al., 2024).

To address these limitations, researchers have increasingly turned to graphs as a complementary infrastructure to organize, enhance, and interpret the modules and execution flows of LLM agents, giving rise to an emerging research direction termed Graph-augmented LLM Agents (GLA) (Liu et al., 2024b; Zhuge et al., 2024; Zhang et al., 2025f). Unlike the sequential language data on which LLMs are grounded, graphs are expressive and generalpurpose data structures that naturally encode complex relationships among entities, tasks, tools, or agents. Within an LLM agent system, graphs can serve as tool managers (e.g., tool graphs, see Figure 2(a)), task decomposition frameworks (e.g., task or workflow graphs, see Figure 2(b)), external knowledge stores (e.g., knowledge graphs, see Figure 2(c)), or communication infrastructures (e.g., agent coordination graphs, see Figure 2(d)), and beyond (Wu et al., 2024b; Liu et al., 2024b; Zhang et al., 2025f; Anokhin et al., 2024).

Compared to purely LLM-based solutions, GLA provides a range of benefits. ❶ Reliability. Graphs ground the reasoning, memory, and knowledge of LLM agents on structured and factual data, reducing hallucinations and improving the reliability of agent systems (Anokhin et al., 2024). ❷ Efficiency. Graphs support efficient information access and management by representing information in a compact, structured, and query-friendly form. Moreover, lightweight graph neural networks enable the training and deployment of auxiliary models over graph structures with minimal computational overhead (Luo et al., 2025b). ❸ Interpretability. The

explicit structure of graphs enhances explainability by revealing how information, tasks, and control signals propagate through the agent system, clarifying the rationale behind decisions and actions. ❹ Flexibility. Graphs promote modularity and reusability, allowing agents to generalize better across tasks by reusing graph-structured information, including but not limited to knowledge, memory, workflow, and communication patterns.

Despite GLA remaining an emerging research direction, there has been, to date, no comprehensive taxonomy or review article on this line of work. To fill the gap, this paper aims to provide a comprehensive overview of existing studies on GLA and offer insights into future opportunities and challenges in this emerging area. Specifically, we first discuss how graphs can augment individual modules within the LLM agent framework, including planning and reasoning, memory and knowledge organization, and tool management. Then, we explore how graphs address unique challenges in LLM-based multi-agent systems, particularly in designing collaborative workflows, ensuring safety, and optimizing efficiency. Finally, we highlight the key future directions, including dynamic and continual graph learning, unified graph abstractions for full-stack agent systems, multimodal graphs for multimodal agents, and large-scale multi-agent system simulation. We hope this article provides useful insights for ML and NLP researchers exploring structured representations in agent systems, graph learning practitioners seeking new applications, and system designers aiming to build more interpretable and collaborative LLM agent systems.

# 2 Graph-Augmented LLM Agent System Framework

Apart from the LLM central agent, the framework of an LLM agent system (as shown in Figure 1(a)) is composed of three critical components: ❶ planning module, responsible for decomposing tasks into actionable steps and reasoning for the task requirements; $\pmb { \varrho }$ memory module, which stores and retrieves contextual knowledge and/or historical memory to support task finishing; and $\pmb { \otimes }$ tool using module, which enables the agent to interact with external APIs or environments to complete tasks beyond its internal capabilities. In each of these components, graphs play a critical role, taking on different forms and functions depending on the requirements of the specific module. In this section,

![](images/31f01fa9087fadcd6e042a8135ddc92e89549b4275cff919ab7676509af7c6db.jpg)  
Figure 3: Graphs for planning in LLM agent system.

we detail the ways in which graphs support planning, memory management, and tool management in LLM agent systems.

# 2.1 Graphs for Agent Planning

The planning module in LLM agent systems aims to decompose high-level goals into executable subtasks, determine the optimal action sequence, and guide the agent behavior in a structured and goaldirected manner. In this process, graphs play diverse roles to improve the reliability and quality of agent planning, assisting with sub-task sketching, sub-task organization, reasoning, and environment perception throughout the planning phase.

# 2.1.1 Plan as a graph

In LLM agent systems, planning typically involves decomposing a complex high-level task into a group of manageable sub-tasks. During this decomposing process, the dependencies among subtasks can be represented as a graph, where nodes are sub-tasks and edges indicate their relationships, as shown in Figure 3(a). The topological planning structure provides a clear and organized view of the task flow, enables the identification of reusable components, and supports efficient coordination of parallel or sequential execution.

Guided by the idea of “plan as a graph”, AFlow (Zhang et al., 2025g) is a representative method that models agentic workflows as graphs where nodes represent LLM invocations and edges capture logical dependencies and execution flow.

Based on the graph-based workflow modeling, AFlow leverages a Monte Carlo Tree Search strategy to automatically explore and optimize these workflows, reducing human effort while improving task performance. While AFlow shows promising improvements in automatically optimizing structured workflows for various LLM-based reasoning tasks, Wei et al. (Wei et al., 2025) further extends the graph-based workflow paradigm to agents for verilog code generation tasks. While AFlow constructs static agentic workflows through searchbased optimization, AgentKit (Wu et al., 2024c) introduces a dynamic graph reasoning framework, where the execution graph evolves during interaction to support structured and context-aware decision making. Apart from optimizing and modeling agent planning, the plan graphs can also serve as structured supervision that teaches LLMs how to plan. By simulating different plan graphs, Planover-Graph (Zhang et al., 2025i) takes the synthetic plan graphs as explicit guidance to improve the parallel planning capabilities of LLMs through supervised fine-tuning and direct preference optimization. Due to their structured and interpretable nature, plan graphs have been recognized by a recent benchmark as a fundamental planning paradigm in agentic workflow generation (Qiao et al., 2025).

# 2.1.2 Sub-task pool as a graph

While directly converting a user request into a plan graph is a simple solution for task decomposition, it is hard to ensure that each node in the generated

plan graph corresponds to a truly executable and meaningful sub-task. As several agentic platforms (e.g., HuggingGPT (Shen et al., 2023)) provide a pool of pre-defined sub-task APIs, a more reliable solution is to ground the sub-tasks into a constrained task graph. In a task graph, each node corresponds to an available and executable sub-task, and each edge represents the dependency relationship between sub-tasks, typically indicating that the output of one task matches the input requirement of the next. Such an organization paradigm explicitly models the sub-task dependencies, allowing for more accurate and interpretable agent planning.

Building upon a sub-task pool graph constructed from HuggingGPT, Wu et al. (Wu et al., 2024b) introduce a graph neural network (GNN)-based approach for agent planning. As illustrated in Figure 3(b), given the user request as a query, the GNN model retrieves a plan subgraph composed of multiple pre-defined sub-tasks, representing the most suitable plan for the request. Empirical evidence shows that both training-free and training-based retrievers achieve reliable performance in generating executable plans, outperforming LLM-based planners that often suffer from hallucinations.

# 2.1.3 Reasoning thought as a graph

Rather than directly generating plans from the user request, involving intermediate reasoning before planning has been proven effective in improving planning accuracy and reliability in LLM agent systems (Huang et al., 2024). Evolving from the Chain-of-Thought (CoT) paradigm (Wei et al., 2022), a recent research trend is to structure the reasoning flow as a graph. As demonstrated in Figure 3(c), each intermediate thought can be represented as a node in a thought graph, where the edges encode logical connections or dependencies between reasoning steps. This graph-based organization of thoughts enables more flexible, interpretable, and self-refining reasoning, allowing LLM agents to refine, backtrack, or expand upon previous steps, leading to more coherent and reliable planning outcomes.

One pioneering approach is the Tree of Thoughts (ToT) (Yao et al., 2023), which enhances deliberate planning by exploring multiple reasoning paths, allowing language models to self-evaluate choices for complex problem-solving. While ToT provides a strong foundation for multi-path reasoning, it faces challenges in balancing factual accuracy and comprehensive logical optimization effectively. To

address this limitation, RATT (Zhang et al., 2025h) addresses the need for factually grounded planning by integrating retrieval-augmented generation to ensure both logical coherence and factual correctness at each step. Recognizing that tree structures can be restrictive for complex planning, Graph of Thought (GoT) (Besta et al., 2024) models reasoning as an arbitrary graph. This allows for more adaptive planning through novel transformations like combining thoughts into synergistic outcomes. These graph-based planning frameworks have also been successfully adapted for domain-specific challenges. For instance, Thought Graph (Hsu et al., 2024) applies these principles to planning in biological research, specifically for gene set analysis, achieving substantial improvements in uncovering semantic relationships between biological processesin uncovering semantic relationships between biological processes. In addition, the goal-oriented thought graph (Badagliacca et al., 2025) represents goals as explicit nodes, enabling transparent and verifiable reasoning processes.

# 2.1.4 Environment as a graph

In addition to the user request, environmental perception is also vital for planning, as it informs the agent of contextual constraints and available actions. For example, for a robotic agent, modeling the environment directly determines the feasibility and efficiency of the generated action plan. In this context, graphs can be a powerful representation for modeling the environment. Figure 3(d) provides an illustration of an environment graph, where entities in the real-world environment (i.e., a room) and their relationships (e.g., distance and interaction) are explicitly modeled, offering essential contextual information to support the decision-making and planning of the robotic agent.

Graphs can be used to describe the environments of various scenarios, from robotic agents to coding agents. For instance, Huang et al. (Huang et al., 2025) propose to model safety constraints in robotic agent planning by constructing a dynamic spatio-semantic safety graph. The environment graph helps the LLM robotic agent to perform realtime hazard detection and adaptive task refinement during task planning. For coding agents, LocAgent (Chen et al., 2025c) leverages code structure graphs to assist LLM agents in localizing and understanding buggy functions. By explicitly modeling function-level and semantic relationships across files, the graph empowers the agent to retrieve rel-

![](images/d22dca1ebcae0da589185c2e242c387011754a4f91fb84e91085f685706fb0e7.jpg)  
Figure 4: Graphs for memory management in LLM agent system.

evant contexts, reduce hallucination, and significantly improve bug localization accuracy.

# 2.2 Graphs for Agent Memory Management

Effective memory management is essential for LLM agents to operate in complex, multi-step environments. As demonstrated in Figure 4(a), agent memory can be categorized into two types: interaction memory and knowledge memory. Interaction memory captures and organizes the agent’s experiences during environment or user interactions, preserving contextual continuity and enabling learning from past encounters. Knowledge memory, conversely, stores structured external information including facts, commonsense, and domain-specific knowledge that informs reasoning and decisionmaking processes. Graph structures offer a particularly powerful paradigm for organizing both memory types, as they naturally represent the interconnected nature of experiences and knowledge. By encoding information as nodes connected through meaningful relationships, graph-based memory systems enable efficient retrieval of contextually relevant information, support multi-hop reasoning across related concepts, and facilitate dynamic integration of new information into existing knowledge frameworks. This unified approach enhances the ability of agents to leverage past experiences,

recognize patterns across interactions, and make informed decisions based on comprehensive contextual understanding.

# 2.2.1 Graph-organized interaction memory

As LLM agents interact with environments and users over extended periods, they generate valuable experiential data that needs to be efficiently stored and retrieved. As shown in Figure 4(b), graphorganized interaction memory represents these experiences as interconnected nodes and edges, where nodes typically represent interaction states, observations, or decisions, and edges capture temporal sequences or causal relationships. This structure enables agents to efficiently recall relevant past experiences, identify patterns across interactions, and leverage historical context for better decisionmaking.

Recent advances in this area include A-MEM (Xu et al., 2025), which proposes an agentic memory system inspired by the Zettelkasten method to create interconnected knowledge networks through dynamic indexing and linking. When new memories are added, the system generates comprehensive notes with structured attributes including contextual descriptions, keywords, and tags, then analyzes historical memories to establish meaningful connections. This approach enables memory evolution, where new memories can trigger updates to existing representations, allowing the network to continuously refine its understanding. Similarly, AriGraph (Anokhin et al., 2024) introduces a memory architecture that integrates semantic and episodic memories within a unified graph framework. As the agent interacts with its environment, each new observation generates an episodic vertex in the memory graph, while an LLM simultaneously extracts relationship triplets (object1, relation, object2) to update the semantic memory, with episodic edges connecting these memory types. This architecture is embedded within the Ariadne cognitive system, where a working memory holds recent observations and relevant knowledge, a planning module generates action plans, and a decision module selects actions for execution, with each observation triggering updates to the agent’s world model.

# 2.2.2 Graph-organized knowledge memory

Beyond managing interaction histories, LLM agents require access to structured external knowledge to support reasoning and decision-making.

As demonstrated in Figure 4(c), graph-organized knowledge memory represents domain knowledge as interconnected entities and relationships, enabling more nuanced understanding and inference capabilities. In these structures, nodes typically represent concepts, facts, or entities, while edges capture semantic relationships between them. This organization allows agents to navigate complex knowledge spaces, perform multi-hop reasoning, and integrate new information within existing knowledge frameworks.

Several recent works have demonstrated the effectiveness of graph-organized knowledge memory for LLM agents. SLAK (Zhou et al., 2024) constructs a location-based knowledge graph (LBKG) that integrates multi-sourced data from locationbased social networks, enabling LLM agents to identify relevant meta-paths for socioeconomic prediction tasks. The framework introduces a cross-task communication mechanism that facilitates knowledge sharing at both agent and knowledge graph levels, significantly enhancing prediction accuracy through this synergistic design. In parallel, KG-Agent (Jiang et al., 2025) proposes an autonomous framework that combines a multifunctional toolbox with a knowledge graph-based executor and dynamic memory system. This integration enables smaller language models to perform complex multi-hop reasoning through an iteration mechanism that autonomously selects appropriate tools and updates memory representations. By leveraging program language to formulate reasoning processes, KG-Agent demonstrates that structured knowledge representations can effectively compensate for model size limitations, outperforming larger models in both in-domain and out-domain question answering tasks.

# 2.3 Graphs for Tool Management

The ability to use external tools is a fundamental capability for LLM agents to solve complex, realworld tasks. With the increasing number and variety of tools, effective tool management becomes critical to help agents select, coordinate, and leverage tools appropriately during complex tasks. To address the challenges of tool management, tool graphs provide a natural and structured way to represent the tool space. As shown in Figure 5, in a tool graph, each node denotes an available tool for agents, and each edge models the functional dependencies and/or compatibility between tools. With the structured representation of the tool graph,

![](images/4e12f3522b338afa9480f1ef949fe0f07d833666592644ebb815001cc8c2c516.jpg)  
Figure 5: Graphs for tool management in LLM agent system.

we can not only perform accurate selection and retrieval of tools, but also enhance the tool-using capabilities of LLM agents.

# 2.3.1 Tool graphs for tool selection

As the number of available tools grows, selecting the appropriate tools given a complex user request becomes a non-trivial task for LLM agents. To address this challenge, graph-based representations provide an effective way for tool selection and retrieval. For instance, ControlLLM (Liu et al., 2024c) constructs a tool graph where nodes represent tools and resources, and edges model their input-output relationships. By searching over the tool graph, ControlLLM identifies executable toolchains that best satisfy the decomposed subtasks of the user request for LLM agents. Sci-ToolAgent (Chen et al., 2025b) further advances this idea by leveraging a manually constructed scientific tool knowledge graph to guide LLMs in planning and executing multi-step toolchains across biology, chemistry, and materials science domains. ToolNet (Liu et al., 2024b) extends this line of work by organizing massive tools into a weighted directed graph, enabling LLMs to navigate the tool space efficiently with adaptive tool selection and dynamic updates based on prior usage. To sum up, the tool graph models both tool dependencies and transition preferences, enabling efficient and adaptive tool selection for LLM agents, especially from a large pool of tools.

# 2.3.2 Tool graphs improve agent tool-use capability

Despite the impressive capabilities across diverse tasks of LLMs, most LLMs are not inherently equipped with the ability to handle external tools

![](images/854a954a0901500fad1851ae5d4b7c7ad4afa653e0dbcf02446ee199bfe8ee8d.jpg)  
Figure 6: Graphs for MAS Orchestration.

properly. To enhance the tool-use capability of LLM agents, supervised fine-tuning with highquality tool-interaction data has become an effective solution. To construct tool-interaction data, tool graphs offer a practical solution to sample related tool combinations as training examples, which helps improve the tool-calling capability of LLM agents. Following this idea, ToolFlow (Wang et al., 2025e) constructs a parameter-level tool graph based on semantic similarity between tool inputs and outputs, enabling the sampling of coherent tool combinations. The sampled tool subsets are then used to guide the generation of multi-turn dialogue plans, which serve as the fine-tuning supervision signals for LLMs to strengthen their toolcalling capability.

# 3 Graph-Augmented LLM Multi-Agent Systems

Recent studies demonstrate that organizing multiple LLM agents into multi-agent systems (MAS) can significantly surpass single-agent capabilities (Guo et al., 2024; Zhu et al., 2024; Ning and Xie, 2024). The inherent topological architecture of MAS naturally lends itself to graph-based modeling. Consequently, substantial research has focused on leveraging graph techniques to enhance MAS collaboration and complex task-solving abilities. This paper systematically investigates this through three dimensions: ❶ Fundamental designs for improving MAS performance via topology/workflowdriven graph concepts; $\pmb { \varrho }$ Optimization of tasksolving efficiency within MAS frameworks; and $\pmb { \otimes }$ A principled synthesis of trustworthy MAS architectures to ensure reliability and deployability via graph-driven techniques.

# 3.1 Graphs for MAS Orchestration

A key distinction between MAS and single-agent setups lies in how MAS connect agents of diverse origins and capabilities to facilitate emergent collective intelligence. But what kind of structured language is suitable for describing, modeling, and managing such collective systems? Researchers from both the agent and graph communities have converged on graphs—a data structure naturally suited for modeling connectivity among large-scale, heterogeneous entities. Intuitively, nodes in the graph represent individual agents, while edges capture their interactions. This modeling approach underpins early graph-based MAS systems such as GPTSwarm (Zhuge et al., 2024), AgentPrune (Zhang et al., 2025e), and Mac-Net (Qian et al., 2025). However, agents often possess internal logic and modular structures. For instance, Anthropic’s “evaluator-optimizer” pattern (Anthropic, 2024) cannot be fully captured by simple node-edge representations. To accommodate such complexity, recent works introduce composite node abstractions to encode richer agentic structures, as seen in AFlow (Zhang et al., 2025g) and MaAS (Zhang et al., 2025c). As a result, graphs have become a foundational tool for MAS modeling. Importantly, just as real-world graphs are dynamic and continuously evolving over time, graph-based MAS have also progressed from static topologies to task-adaptive, and more recently, process-adaptive structures. We will detail the progression in the following sections, and Figure 6 provides an overview.

# 3.1.1 Static MAS Topology

Early works did not explicitly adopt graph structures; for example, AutoGen (Wu et al., 2024a) employed a chained layout, while DyLAN utilized a multi-layer perceptron-like architecture. A

series of debate-based methods, such as ChatEval (Chan et al., 2023), LLM-Debate (Du et al., 2024), and Persuasive-Debate (Khan et al., 2024), implicitly rely on graph-like structures to organize agent interactions. More recent approaches model MAS orchestration explicitly as graphs. GPTSwarm (Zhuge et al., 2024) represents singleagent invocations as base nodes and composite behaviors (e.g., ReAct, CoT) as higher-level nodes. MacNet (Qian et al., 2025) explores a range of graph topologies—including tree, chain, star, random, and complete graphs—and evaluates their scalability as the number of agents grows. AFlow (Zhang et al., 2025g) introduces a two-level node abstraction: operators, defined by a single LLM invocation with specific parameters (prompt, temperature, output format, etc.), and nodes, which group multiple operators into composite agentic units. These nodes are then connected to form agentic workflows. EvoFlow (Zhang et al., 2025b) follows a similar abstraction and applies a genetic algorithm to evolve a population of agentic workflows through query-specific evaluation.

# 3.1.2 Task-dynamic MAS Topology

However, these topologies are task-independent, i.e., the same structure is applied regardless of domain or task complexity. G-Designer (Zhang et al., 2025f) makes the first attempt at task-adaptive topology orchestration, constructing MAS with varying graph complexity (e.g., node count, edge density) tailored to task difficulty. Specifically, it employs a variational graph auto-encoder to encode task-aware multi-agent graphs and generate topologies dynamically adjusted to task complexity. Meanwhile, EIB-learner (Shen et al., 2025) introduced a topological design method that integrates different connection patterns based on causal analysis results, better balancing error suppression and beneficial information propagation. In contrast, ARG-Designer (Li et al., 2025a) models topological design as a graph generation task, creating customized topologies in a flexible and scalable manner based on autoregressive graph generation. Following this direction, (Zhang et al., 2025j) proposes using GNNs as performance predictors for MAS, accelerating MAS topology optimization. Similarly, MaAS (Zhang et al., 2025c) adopts a task-adaptive design paradigm based on an agentic supernet, further improving search efficiency and cost-effectiveness. MASS (Zhou et al., 2025a) provides a systematic analysis of how different

![](images/c2c472941fc0bd6aaa44f19619636b86300dc48f1c14194a7c5c002b31c04929.jpg)  
Figure 7: Graphs for MAS Efficiency.

topologies affect MAS performance.

# 3.1.3 Process-dynamic MAS Topology

While these methods enable task-level adaptivity, they suffer from a key limitation: topologies are statically sampled prior to execution, lacking finegrained adaptation and fault tolerance during runtime. ReSo (Zhou et al., 2025b) addresses this by decomposing the user query into a directed acyclic graph and performing dynamic planning and agent routing at each execution node, enabling more granular MAS evolution. Similarly, EvoMAC (Hu et al., 2025) adapts both topology and prompting based on environment feedback from each execution. AnyMAC (Wang et al., 2025d) also performs step-wise topology planning guided by subtask progression.

# 3.2 Graph for MAS Efficiency

Just as real-world graph datasets often suffer from redundancy and noise, necessitating techniques such as graph structure learning (Li et al., 2023; Zhu et al., 2021; Li et al., 2025c, 2024a) and graph pruning (Zhang et al., 2024a, 2025d; Spielman and Srivastava, 2008) to refine the graph topology, graph-based MAS have likewise been observed to exhibit various forms of redundancy. For instance, many inter-agent communications are found to be ineffective or even detrimental (Zhang et al., 2025e; Li et al., 2024b); increasing the number of agents (nodes) does not always lead to performance gains (Wang et al., 2025g); and the marginal utility of additional multi-agent utterance rounds diminishes over time. Interestingly, these redundancy patterns parallel classical graph lightweighting phenomena: redundant inter-agent communication mirrors edge redundancy, excessive agents correspond to removable, unnecessary nodes, and diminishing returns from prolonged multi-agent interactions resemble the over-smoothing issue in GNNs, where deeper layers degrade performance.

In what follows, we examine MAS efficiency issues from these three perspectives and discuss potential solutions inspired by graph-theoretic insights. A sketched illustration is provided in Figure 7.

# 3.2.1 Edge Redundancy in MAS

A considerable number of MAS frameworks adopt predefined inter-agent communication paths (i.e., edges), as seen in DyLAN (Liu et al., 2023), MachineSOM (Zhang et al., 2024b), and Consensus-LLM (Chen et al., 2023). Designing such topologies poses a critical challenge: how to strike a delicate balance between sufficient information exchange for task completion and minimizing token consumption. In practice, many predefined topologies are not readily conducive to effective multiagent collaboration. For example, MacNet (Qian et al., 2025) evaluates various hand-crafted graph structures—MLP-like graphs, complete graphs, random graphs, stars, trees—but observes that performance does not consistently improve with increased edge density. AgentPrune (Zhang et al., 2025e) is the first to formally define the Communication Redundancy problem in MAS, demonstrating that many systems can achieve comparable performance even after pruning a subset of inter-agent communication edges. These removable edges are referred to as redundancies. Inspired by classical rank-based graph sparsification techniques, such as the low-rank sparsity loss in ProGNN (Jin et al., 2020), AgentPrune models the MAS communication pipeline as a spatio-temporal graph and reformulates it as a learnable adjacency matrix. By optimizing a trainable graph mask, the method identifies and prunes redundant edges within the existing topology. Similarly, MAD (Li et al., 2024b) demonstrates in multi-agent debate settings that sparse communication topologies can enhance both effectiveness and efficiency, while overly dense topologies often become burdensome. Addressing this issue, TalkHier (Wang et al., 2025f) proposes a well-structured, context-rich communication protocol that activates agent teams hierarchically, offering greater flexibility compared to approaches like AgentPrune and GPTSwarm, which rely on a fixed topology across all tasks. Overall, as task complexity increases and contextual inputs grow longer, edge redundancy remains a persistent challenge in MAS. Balancing communication token costs with system performance continues to be an open and important direction for future exploration.

# 3.2.2 Node Redundancy in MAS

In conventional GNN research, it has been shown that randomly or strategically dropping edges or nodes can improve training efficiency and robustness without sacrificing, or even enhancing, performance, as observed in DropEdge (Rong et al., 2020), PTDNet (Luo et al., 2021), and DropGNN (Papp et al., 2021). Interestingly, similar insights hold in MAS: AgentDropout (Wang et al., 2025g) identifies underperforming or inactive agents and dynamically removes them, achieving node-level de-redundancy. Their approach also exhibits strong transferability, i.e., MAS pruned and optimized on one dataset generalize well to others.

# 3.2.3 Layer Redundancy in MAS

Oversmoothing has long been a persistent challenge in the GNN community (Chen et al., 2020; Cai and Wang, 2020): as the number of layers increases, quantitative performance often plateaus or even deteriorates. When mapped to MAS, a similar issue arises: system performance does not always improve with more rounds of multi-agent dialogue. This phenomenon was first observed in multi-agent debate frameworks: (Liang et al., 2024) found that while disagreement among agents decreases with more debate iterations, performance metrics do not consistently improve. Similarly, (Li et al., 2024b) showed that beyond five rounds of debate, additional iterations yield no performance gains. Although studies remain limited, recent work has begun to address MAS over-smoothing by drawing on GNN strategies. Residual Mixture-of-Agents (MoA) (Xie et al., 2025) introduces residual connection modules that insert residual agents between generation rounds to compress historical information, enabling faster performance improvements in multi-turn MoA settings. Debate Only When Necessary (DOWN) (Eo et al., 2025) introduces a simple yet effective Debate Engagement Check to determine whether engaging in a debate is necessary, thus reducing unnecessary communication overhead.

# 3.3 Graphs for Trustworthy MAS

Trustworthiness is a fundamental requirement for ensuring the operational reliability of agentic systems (Chen et al., 2025a; Wang et al., 2025a; Yu et al., 2025a; Liu et al., 2025b; Wang et al., 2025b; Liu et al., 2025a). The unique topological structure of MAS has motivated research into how different network configurations affect the propagation of

hazardous information. For instance, NetSafe (Yu et al., 2025b) and ARGUS (Li et al., 2025b) systematically investigated the flow of biases and harmful content through MAS architectures, while AgentSafe (Mao et al., 2025) further examined their potential impacts on memory subsystems. Building on these foundations, G-Safeguard (Wang et al., 2025c) leverages the inductive bias of graph neural networks (Wu et al., 2020) to model threat propagation in MAS, enabling the prediction and detection of malicious nodes without requiring explicit predictor training. Complementing these approaches, FlowReasoner (Gao et al., 2025) introduces a reasoning-based meta-agent to automate the design optimization of query-level MAS architectures.

Complementing technical research, several benchmarks have emerged to address agent safety concerns. Agent-SafetyBench (Zhang et al., 2024c) systematically investigates safety issues in simulated environments, while AgentAuditor (Luo et al., 2025a) provides formal safety evaluation frameworks for monitoring agent behavior throughout operational processes.

# 4 Conclusion and Future Directions

Despite recent progress in GLA, this research area remains in its early stages of development. To guide future exploration, we summarize several promising research opportunities below.

# 4.1 Dynamic and Continual Graph Learning for Agent Systems

Most current GLA systems rely on static or sessionspecific graph structures, which are constructed separately for each task and remain fixed throughout the execution process of agents. Nevertheless, real-world scenarios often involve dynamic environments and shifting task requirements, which demand continual updates to graph structures and graph learning modules. To adapt to evolving tasks and dynamic environments, a promising future direction is to develop dynamic and continual graph learning frameworks, where graph structures and representations evolve alongside agent interactions and environmental feedback. With the ability to incrementally update task plans, memory structures, and tool-use pathways based on new experiences, such systems can enable lifelong learning and persistent improvement, thereby enhancing agent adaptability in complex scenarios and bring-

ing them closer to human-like learning behaviors.

# 4.2 Unified Graph Abstractions for Full-Stack Agent Systems

In the existing methods for LLM agents, the graphs and graph learning modules are designed independently for individual modules, such as planning, memory, tool orchestration, or agent collaboration. However, full-stack agent intelligence often requires tight integration across these components to support coherent reasoning, modular reuse, and efficient adaptation. To this end, a promising path forward is to construct unified graph abstractions that holistically represent agent knowledge, workflows, and interactions across the full stack. To reach the goal, graph foundation models emerge as a compelling option: pretrained on largescale agent-related graph data, they offer adaptable and reusable representations that can seamlessly integrate into various agent modules. A unified graph abstraction can help agents perform more consistent reasoning, facilitate information sharing across modules, and ultimately enhance generalization and scalability in complex, multi-task environments.

# 4.3 Multimodal Graphs for Multimodal Agents

As LLM agents are increasingly deployed in multimodal settings involving language, vision, audio, and action, a major challenge arises in organizing and reasoning over heterogeneous sensory inputs and outputs. Existing graph-based solutions for agents typically focus on textual or symbolic domains, lacking the flexibility to represent crossmodal relationships and temporal dynamics. To address this, future work can explore the development of multimodal graphs that unify diverse modalities within a coherent graph representation, where nodes correspond to visual objects, speech segments, text entities, or actions, and edges capture semantic, spatial, or temporal dependencies. Such graphs would enable agents to perform structured, multi-hop reasoning across modalities, facilitate modality alignment and fusion, and support tasks like grounded planning, embodied interaction, or video question answering.

# 4.4 Graphs for Trustworthy Multi-Agent Systems

The proliferation of multi-agent systems has led to a heightened focus on their trustworthiness, includ-

ing crucial aspects such as security, fairness, and privacy. It is our contention that a graph modeling perspective can provide substantial support for enhancing these properties. Taking federated multiagent systems for example, where agents from disparate entities, each potentially possessing private data, must cooperate, ensuring that sensitive information is not divulged during inter-agent communication is critical. Graph-based methodologies present a promising avenue for resolving this issue. For instance, techniques like node decomposition combined with homomorphic encryption can be conceptualized within a graph framework to facilitate secure information exchange between agents. Furthermore, the inherent openness of many multiagent systems renders them susceptible to security threats, such as the infiltration of malicious agents intent on executing attacks like prompt injection or memory poisoning. To fortify system security, inspiration can be drawn from the domain of graph learning. Methodologies for detecting malicious agents can be developed by modeling the system as a dynamic interaction graph and identifying anomalous patterns at the node, edge, or even subgraph level. Finally, the principle of fairness is indispensable for the long-term stability and effectiveness of multi-agent systems, especially those involving resource allocation or collaborative task execution. Graph theory provides a formal language to describe and analyze fairness in these contexts, fostering mechanisms that not only optimize for system efficiency but also ensure that outcomes are equitable for all participating agents, preventing issues like resource starvation and promoting sustained cooperation.

# 4.5 Graphs for Large-Scale Multi-Agent System Simulation

Simulating large-scale multi-agent systems has substantial real-world value, enabling researchers to explore emergent behaviors, evaluate coordination strategies, and stress-test agent architectures in complex settings such as smart cities, supply chains, and social platforms. However, most existing graph-based MAS approaches are confined to small-scale scenarios, typically modeling only a few dozen agents, and fall short in capturing the complexity and scale of population-level interactions. Scaling up introduces significant challenges, including communication overload, decentralized control, and the need for dynamic topology adaptation as agents and tasks evolve over time. To tackle

these issues, future work can explore large-scale graph learning algorithms that support efficient representation, inference, and adaptation over massive, evolving agent interaction graphs. Such methods would enable more realistic MAS simulations and support the deployment of large-scale agent systems in diverse domains such as social behavior modeling, industrial robotics, autonomous traffic control, and multi-agent financial systems.

# References

Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, and 1 others. 2023. GPT-4 technical report. arXiv preprint arXiv:2303.08774.   
Petr Anokhin, Nikita Semenov, Artyom Sorokin, Dmitry Evseev, Mikhail Burtsev, and Evgeny Burnaev. 2024. Arigraph: Learning knowledge graph world models with episodic memory for llm agents. arXiv preprint arXiv:2407.04363.   
Anthropic. 2024. Building effective ai agents.   
Dario Badagliacca, Gabriele Caruso, Agnese Augello, and Luca Sabatucci. 2025. Graph of goal-oriented thoughts: Design and implementation of llm agents. In SOCIALIZE 2025, CEUR Workshop Proceedings.   
Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Michal Podstawski, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Hubert Niewiadomski, Piotr Nyczyk, and 1 others. 2024. Graph of thoughts: Solving elaborate problems with large language models. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pages 17682–17690.   
Chen Cai and Yusu Wang. 2020. A note on oversmoothing for graph neural networks. In ICML 2020 Workshop on Graph Representation Learning and Beyond.   
Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang Zhang, Jie Fu, and Zhiyuan Liu. 2023. Chateval: Towards better llm-based evaluators through multi-agent debate. In Twelfth International Conference on Learning Representations.   
Ada Chen, Yongjiang Wu, Junyuan Zhang, Shu Yang, Jen-tse Huang, Kun Wang, Wenxuan Wang, and Shuai Wang. 2025a. A survey on the safety and security threats of computer-using agents: Jarvis or ultron? arXiv preprint arXiv:2505.10924.   
Deli Chen, Yankai Lin, Wei Li, Peng Li, Jie Zhou, and Xu Sun. 2020. Measuring and relieving the oversmoothing problem for graph neural networks from the topological view. In Proceedings of the AAAI conference on artificial intelligence, volume 34, pages 3438–3445.

Huaben Chen, Wenkang Ji, Lufeng Xu, and Shiyu Zhao. 2023. Multi-agent consensus seeking via large language models. arXiv preprint arXiv:2310.20151.   
Huajun Chen, Keyan Ding, Jing Yu, Junjie Huang, Yuchen Yang, and Qiang Zhang. 2025b. Scitoolagent: A knowledge graph-driven scientific agent for multi-tool integration.   
Zhaoling Chen, Xiangru Tang, Gangda Deng, Fang Wu, Jialong Wu, Zhiwei Jiang, Viktor Prasanna, Arman Cohan, and Xingyao Wang. 2025c. Locagent: Graphguided llm agents for code localization. In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics.   
Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, and Igor Mordatch. 2024. Improving factuality and reasoning in language models through multiagent debate. In Proceedings of the 41st International Conference on Machine Learning, pages 11733–11763.   
Sugyeong Eo, Hyeonseok Moon, Evelyn Hayoon Zi, Chanjun Park, and Heuiseok Lim. 2025. Debate only when necessary: Adaptive multiagent collaboration for efficient llm reasoning. arXiv preprint arXiv:2504.05047.   
Wenqi Fan, Yujuan Ding, Liangbo Ning, Shijie Wang, Hengyun Li, Dawei Yin, Tat-Seng Chua, and Qing Li. 2024. A survey on rag meeting llms: Towards retrieval-augmented large language models. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages 6491– 6501.   
Hongcheng Gao, Yue Liu, Yufei He, Longxu Dou, Chao Du, Zhijie Deng, Bryan Hooi, Min Lin, and Tianyu Pang. 2025. Flowreasoner: Reinforcing query-level meta-agents. arXiv preprint arXiv:2504.15257.   
Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao Pei, Nitesh V Chawla, Olaf Wiest, and Xiangliang Zhang. 2024. Large language model based multi-agents: a survey of progress and challenges. In Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence, pages 8048– 8057.   
Chi-Yang Hsu, Kyle Cox, Jiawei Xu, Zhen Tan, Tianhua Zhai, Mengzhou Hu, Dexter Pratt, Tianlong Chen, Ziniu Hu, and Ying Ding. 2024. Thought graph: Generating thought process for biological reasoning. In Companion Proceedings of the ACM Web Conference 2024, pages 537–540.   
Yue Hu, Yuzhu Cai, Yaxin Du, Xinyu Zhu, Xiangrui Liu, Zijie Yu, Yuchen Hou, Shuo Tang, and Siheng Chen. 2025. Self-evolving multi-agent collaboration networks for software development. In Thirteenth International Conference on Learning Representations.   
Wanjing Huang, Tongjie Pan, and Yalan Ye. 2025. Graphormer-guided task planning: Beyond static rules with llm safety perception. arXiv preprint arXiv:2503.06866.

Xu Huang, Weiwen Liu, Xiaolong Chen, Xingmei Wang, Hao Wang, Defu Lian, Yasheng Wang, Ruiming Tang, and Enhong Chen. 2024. Understanding the planning of llm agents: A survey. arXiv preprint arXiv:2402.02716.   
Jinhao Jiang, Kun Zhou, Wayne Xin Zhao, Yang Song, Chen Zhu, Hengshu Zhu, and Ji-Rong Wen. 2025. Kg-agent: An efficient autonomous agent framework for complex reasoning over knowledge graph. In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics.   
Wei Jin, Yao Ma, Xiaorui Liu, Xianfeng Tang, Suhang Wang, and Jiliang Tang. 2020. Graph structure learning for robust graph neural networks. In Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery & data mining, pages 66–74.   
Akbir Khan, John Hughes, Dan Valentine, Laura Ruis, Kshitij Sachan, Ansh Radhakrishnan, Edward Grefenstette, Samuel R Bowman, Tim Rocktäschel, and Ethan Perez. 2024. Debating with more persuasive llms leads to more truthful answers. In Proceedings of the 41st International Conference on Machine Learning, pages 23662–23733.   
Shiyuan Li, Yixin Liu, Qingsong Wen, Chengqi Zhang, and Shirui Pan. 2025a. Assemble your crew: Automatic multi-agent communication topology design via autoregressive graph generation. arXiv preprint arXiv:2507.18224.   
Yuhan Li, Zhixun Li, Peisong Wang, Jia Li, Xiangguo Sun, Hong Cheng, and Jeffrey Xu Yu. 2024a. A survey of graph meets large language model: Progress and future directions. In Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence.   
Yunxuan Li, Yibing Du, Jiageng Zhang, Le Hou, Peter Grabowski, Yeqing Li, and Eugene Ie. 2024b. Improving multi-agent debate with sparse communication topology. In Findings of the Association for Computational Linguistics: EMNLP 2024, pages 7281–7294.   
Zherui Li, Yan Mi, Zhenhong Zhou, Houcheng Jiang, Guibin Zhang, Kun Wang, and Junfeng Fang. 2025b. Goal-aware identification and rectification of misinformation in multi-agent systems. arXiv preprint arXiv:2506.00509.   
Zhixun Li, Dingshuo Chen, Tong Zhao, Daixin Wang, Hongrui Liu, Zhiqiang Zhang, Jun Zhou, and Jeffrey Xu Yu. 2025c. Iceberg: Debiased self-training for class-imbalanced node classification. In Proceedings of the ACM on Web Conference 2025, pages 3160–3170.   
Zhixun Li, Liang Wang, Xin Sun, Yifan Luo, Yanqiao Zhu, Dingshuo Chen, Yingtao Luo, Xiangxin Zhou, Qiang Liu, Shu Wu, and 1 others. 2023. Gslb: The graph structure learning benchmark. Advances in Neural Information Processing Systems, 36:30306– 30318.

Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang, Shuming Shi, and Zhaopeng Tu. 2024. Encouraging divergent thinking in large language models through multi-agent debate. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing.   
Aishan Liu, Zonghao Ying, Le Wang, Junjie Mu, Jinyang Guo, Jiakai Wang, Yuqing Ma, Siyuan Liang, Mingchuan Zhang, Xianglong Liu, and 1 others. 2025a. Agentsafe: Benchmarking the safety of embodied agents on hazardous instructions. arXiv preprint arXiv:2506.14697.   
Aishan Liu, Yuguang Zhou, Xianglong Liu, Tianyuan Zhang, Siyuan Liang, Jiakai Wang, Yanjun Pu, Tianlin Li, Junqi Zhang, Wenbo Zhou, and 1 others. 2025b. Compromising llm driven embodied agents with contextual backdoor attacks. IEEE Transactions on Information Forensics and Security.   
Aixin Liu, Bei Feng, Bing Xue, Bingxuan Wang, Bochao Wu, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, and 1 others. 2024a. DeepSeek-v3 technical report. arXiv preprint arXiv:2412.19437.   
Xukun Liu, Zhiyuan Peng, Xiaoyuan Yi, Xing Xie, Lirong Xiang, Yuchen Liu, and Dongkuan Xu. 2024b. Toolnet: Connecting large language models with massive tools via tool graph. arXiv preprint arXiv:2403.00839.   
Zhaoyang Liu, Zeqiang Lai, Zhangwei Gao, Erfei Cui, Ziheng Li, Xizhou Zhu, Lewei Lu, Qifeng Chen, Yu Qiao, Jifeng Dai, and 1 others. 2024c. Controlllm: Augment language models with tools by searching on graphs. In European Conference on Computer Vision, pages 89–105.   
Zijun Liu, Yanzhe Zhang, Peng Li, Yang Liu, and Diyi Yang. 2023. Dynamic llm-agent network: An llmagent collaboration framework with agent team optimization. arXiv preprint arXiv:2310.02170.   
Dongsheng Luo, Wei Cheng, Wenchao Yu, Bo Zong, Jingchao Ni, Haifeng Chen, and Xiang Zhang. 2021. Learning to drop: Robust graph neural network via topological denoising. In Proceedings of the 14th ACM international conference on web search and data mining, pages 779–787.   
Hanjun Luo, Shenyu Dai, Chiming Ni, Xinfeng Li, Guibin Zhang, Kun Wang, Tongliang Liu, and Hanan Salam. 2025a. Agentauditor: Human-level safety and security evaluation for llm agents. arXiv preprint arXiv:2506.00641.   
Linhao Luo, Zicheng Zhao, Gholamreza Haffari, Dinh Phung, Chen Gong, and Shirui Pan. 2025b. Gfmrag: Graph foundation model for retrieval augmented generation. arXiv preprint arXiv:2502.01113.   
Andres M. Bran, Sam Cox, Oliver Schilter, Carlo Baldassari, Andrew D White, and Philippe Schwaller.

2024. Augmenting large language models with chemistry tools. Nature Machine Intelligence, 6(5):525– 535.   
Sanwal Manish. 2024. An autonomous multi-agent llm framework for agile software development. International Journal of Trend in Scientific Research and Development, 8(5):892–898.   
Junyuan Mao, Fanci Meng, Yifan Duan, Miao Yu, Xiaojun Jia, Junfeng Fang, Yuxuan Liang, Kun Wang, and Qingsong Wen. 2025. Agentsafe: Safeguarding large language model-based multi-agent systems via hierarchical data management. arXiv preprint arXiv:2503.04392.   
Zepeng Ning and Lihua Xie. 2024. A survey on multiagent reinforcement learning and its application. Journal of Automation and Intelligence, 3(2):73–91.   
Pál András Papp, Karolis Martinkus, Lukas Faber, and Roger Wattenhofer. 2021. Dropgnn: Random dropouts increase the expressiveness of graph neural networks. Advances in Neural Information Processing Systems, 34:21997–22009.   
Chen Qian, Zihao Xie, Yifei Wang, Wei Liu, Yufan Dang, Zhuoyun Du, Weize Chen, Cheng Yang, Zhiyuan Liu, and Maosong Sun. 2025. Scaling largelanguage-model-based multi-agent collaboration. In Thirteenth International Conference on Learning Representations.   
Shuofei Qiao, Runnan Fang, Zhisong Qiu, Xiaobin Wang, Ningyu Zhang, Yong Jiang, Pengjun Xie, Fei Huang, and Huajun Chen. 2025. Benchmarking agentic workflow generation. In Thirteenth International Conference on Learning Representations.   
Yu Rong, Wenbing Huang, Tingyang Xu, and Junzhou Huang. 2020. Dropedge: Towards deep graph convolutional networks on node classification. In Eight International Conference on Learning Representations.   
Xu Shen, Yixin Liu, Yiwei Dai, Yili Wang, Rui Miao, Yue Tan, Shirui Pan, and Xin Wang. 2025. Understanding the information propagation effects of communication topologies in llm-based multi-agent systems. In Findings of the Association for Computational Linguistics: EMNLP 2025.   
Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, and Yueting Zhuang. 2023. Hugginggpt: Solving ai tasks with chatgpt and its friends in hugging face. Advances in Neural Information Processing Systems, 36:38154–38180.   
Daniel A Spielman and Nikhil Srivastava. 2008. Graph sparsification by effective resistances. In Proceedings of the fortieth annual ACM symposium on Theory of computing, pages 563–568.   
Gemini Team, Petko Georgiev, Ving Ian Lei, Ryan Burnell, Libin Bai, Anmol Gulati, Garrett Tanzer, Damien Vincent, Zhufeng Pan, Shibo Wang, and 1

others. 2024. Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context. arXiv preprint arXiv:2403.05530.   
Kun Wang, Guibin Zhang, Zhenhong Zhou, Jiahao Wu, Miao Yu, Shiqian Zhao, Chenlong Yin, Jinhu Fu, Yibo Yan, Hanjun Luo, and 1 others. 2025a. A comprehensive survey in llm (-agent) full stack safety: Data, training and deployment. arXiv preprint arXiv:2504.15585.   
Le Wang, Zonghao Ying, Tianyuan Zhang, Siyuan Liang, Shengshan Hu, Mingchuan Zhang, Aishan Liu, and Xianglong Liu. 2025b. Manipulating multimodal agents via cross-modal prompt injection. arXiv preprint arXiv:2504.14348.   
Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, and 1 others. 2024. A survey on large language model based autonomous agents. Frontiers of Computer Science, 18(6):186345.   
Shilong Wang, Guibin Zhang, Miao Yu, Guancheng Wan, Fanci Meng, Chongye Guo, Kun Wang, and Yang Wang. 2025c. G-safeguard: A topology-guided security lens and treatment on llm-based multi-agent systems. In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics.   
Song Wang, Zhen Tan, Zihan Chen, Shuang Zhou, Tianlong Chen, and Jundong Li. 2025d. Anymac: Cascading flexible multi-agent collaboration via next-agent prediction. arXiv preprint arXiv:2506.17784.   
Zezhong Wang, Xingshan Zeng, Weiwen Liu, Liangyou Li, Yasheng Wang, Lifeng Shang, Xin Jiang, Qun Liu, and Kam-Fai Wong. 2025e. Toolflow: Boosting llm tool-calling through natural and coherent dialogue synthesis. In Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 4246–4263.   
Zhao Wang, Sota Moriyama, Wei-Yao Wang, Briti Gangopadhyay, and Shingo Takamatsu. 2025f. Talk structurally, act hierarchically: A collaborative framework for llm multi-agent systems. arXiv preprint arXiv:2502.11098.   
Zhexuan Wang, Yutong Wang, Xuebo Liu, Liang Ding, Miao Zhang, Jie Liu, and Min Zhang. 2025g. Agentdropout: Dynamic agent elimination for tokenefficient and high-performance llm-based multi-agent collaboration. arXiv preprint arXiv:2503.18891.   
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, and 1 others. 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems, 35:24824– 24837.

Yangbo Wei, Zhen Huang, Huang Li, Wei W Xing, Ting-Jung Lin, and Lei He. 2025. Vflow: Discovering optimal agentic workflows for verilog generation. arXiv preprint arXiv:2504.03723.   
Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li, Erkang Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang, Jiale Liu, and 1 others. 2024a. Autogen: Enabling next-gen llm applications via multiagent conversation. In ICLR 2024 Workshop on Large Language Model (LLM) Agents.   
Xixi Wu, Yifei Shen, Caihua Shan, Kaitao Song, Siwei Wang, Bohang Zhang, Jiarui Feng, Hong Cheng, Wei Chen, Yun Xiong, and 1 others. 2024b. Can graph learning improve planning in llm-based agents? In The Thirty-eighth Annual Conference on Neural Information Processing Systems.   
Yue Wu, Yewen Fan, So Yeon Min, Shrimai Prabhumoye, Stephen McAleer, Yonatan Bisk, Ruslan Salakhutdinov, Yuanzhi Li, and Tom Mitchell. 2024c. Agentkit: Structured llm reasoning with dynamic graphs. In First Conference on Language Modeling.   
Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and S Yu Philip. 2020. A comprehensive survey on graph neural networks. IEEE transactions on neural networks and learning systems, 32(1):4–24.   
Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, and 1 others. 2025. The rise and potential of large language model based agents: A survey. Science China Information Sciences, 68(2):121101.   
Zhentao Xie, Chengcheng Han, Jinxin Shi, Wenjun Cui, Xin Zhao, Xingjiao Wu, and Jiabao Zhao. 2025. Rmoa: Optimizing mixture-of-agents through diversity maximization and residual compensation. arXiv preprint arXiv:2505.24442.   
Wujiang Xu, Kai Mei, Hang Gao, Juntao Tan, Zujie Liang, and Yongfeng Zhang. 2025. A-mem: Agentic memory for llm agents. arXiv preprint arXiv:2502.12110.   
Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao, and Karthik Narasimhan. 2023. Tree of thoughts: Deliberate problem solving with large language models. Advances in neural information processing systems, 36:11809–11822.   
Miao Yu, Fanci Meng, Xinyun Zhou, Shilong Wang, Junyuan Mao, Linsey Pang, Tianlong Chen, Kun Wang, Xinfeng Li, Yongfeng Zhang, and 1 others. 2025a. A survey on trustworthy llm agents: Threats and countermeasures. In Proceedings of the 31th ACM SIGKDD international conference on knowledge discovery & data mining.   
Miao Yu, Shilong Wang, Guibin Zhang, Junyuan Mao, Chenlong Yin, Qijiong Liu, Qingsong Wen, Kun

Wang, and Yang Wang. 2025b. Netsafe: Exploring the topological safety of multi-agent networks. In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics.   
Yangyang Yu, Zhiyuan Yao, Haohang Li, Zhiyang Deng, Yuechen Jiang, Yupeng Cao, Zhi Chen, Jordan Suchow, Zhenyu Cui, Rong Liu, and 1 others. 2024. Fincon: A synthesized llm multi-agent system with conceptual verbal reinforcement for enhanced financial decision making. Advances in Neural Information Processing Systems, 37:137010–137045.   
Simon Zhai, Hao Bai, Zipeng Lin, Jiayi Pan, Peter Tong, Yifei Zhou, Alane Suhr, Saining Xie, Yann LeCun, Yi Ma, and 1 others. 2024. Fine-tuning large visionlanguage models as decision-making agents via reinforcement learning. Advances in neural information processing systems, 37:110935–110971.   
Chi Zhang, Zhao Yang, Jiaxuan Liu, Yanda Li, Yucheng Han, Xin Chen, Zebiao Huang, Bin Fu, and Gang Yu. 2025a. Appagent: Multimodal agents as smartphone users. In Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems, pages 1–20.   
Guibin Zhang, Kaijie Chen, Guancheng Wan, Heng Chang, Hong Cheng, Kun Wang, Shuyue Hu, and Lei Bai. 2025b. Evoflow: Evolving diverse agentic workflows on the fly. arXiv preprint arXiv:2502.07373.   
Guibin Zhang, Luyang Niu, Junfeng Fang, Kun Wang, Lei Bai, and Xiang Wang. 2025c. Multi-agent architecture search via agentic supernet. In Forty-second International Conference on Machine Learning.   
Guibin Zhang, Xiangguo Sun, Yanwei Yue, Chonghe Jiang, Kun Wang, Tianlong Chen, and Shirui Pan. 2025d. Graph sparsification via mixture of graphs. In Thirteenth International Conference on Learning Representations.   
Guibin Zhang, Yanwei Yue, Zhixun Li, Sukwon Yun, Guancheng Wan, Kun Wang, Dawei Cheng, Jeffrey Xu Yu, and Tianlong Chen. 2025e. Cut the crap: An economical communication pipeline for llm-based multi-agent systems. In Thirteenth International Conference on Learning Representations.   
Guibin Zhang, Yanwei Yue, Xiangguo Sun, Guancheng Wan, Miao Yu, Junfeng Fang, Kun Wang, Tianlong Chen, and Dawei Cheng. 2025f. G-designer: Architecting multi-agent communication topologies via graph neural networks. In Forty-second International Conference on Machine Learning.   
Guibin Zhang, Yanwei Yue, Kun Wang, Junfeng Fang, Yongduo Sui, Kai Wang, Yuxuan Liang, Dawei Cheng, Shirui Pan, and Tianlong Chen. 2024a. Two heads are better than one: boosting graph sparse training via semantic and topological awareness. In Proceedings of the 41st International Conference on Machine Learning, pages 60197–60219.   
Jiayi Zhang, Jinyu Xiang, Zhaoyang Yu, Fengwei Teng, Xionghui Chen, Jiaqi Chen, Mingchen Zhuge, Xin

Cheng, Sirui Hong, Jinlin Wang, and 1 others. 2025g. Aflow: Automating agentic workflow generation. In Thirteenth International Conference on Learning Representations.   
Jinghan Zhang, Xiting Wang, Weijieying Ren, Lu Jiang, Dongjie Wang, and Kunpeng Liu. 2025h. Ratt: A thought structure for coherent and correct llm reasoning. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 39, pages 26733–26741.   
Jintian Zhang, Xin Xu, Ningyu Zhang, Ruibo Liu, Bryan Hooi, and Shumin Deng. 2024b. Exploring collaboration mechanisms for llm agents: A social psychology view. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics.   
Shiqi Zhang, Xinbei Ma, Zouying Cao, Zhuosheng Zhang, and Hai Zhao. 2025i. Plan-over-graph: Towards parallelable llm agent schedule. arXiv preprint arXiv:2502.14563.   
Yuanshuo Zhang, Yuchen Hou, Bohan Tang, Shuo Chen, Muhan Zhang, Xiaowen Dong, and Siheng Chen. 2025j. Gnns as predictors of agentic workflow performances. arXiv preprint arXiv:2503.11301.   
Zhexin Zhang, Shiyao Cui, Yida Lu, Jingzhuo Zhou, Junxiao Yang, Hongning Wang, and Minlie Huang. 2024c. Agent-safetybench: Evaluating the safety of llm agents. arXiv preprint arXiv:2412.14470.   
Han Zhou, Xingchen Wan, Ruoxi Sun, Hamid Palangi, Shariq Iqbal, Ivan Vulic, Anna Korhonen, and Ser-´ can Ö Arık. 2025a. Multi-agent design: Optimizing agents with better prompts and topologies. arXiv preprint arXiv:2502.02533.   
Heng Zhou, Hejia Geng, Xiangyuan Xue, Li Kang, Yiran Qin, Zhiyong Wang, Zhenfei Yin, and Lei Bai. 2025b. Reso: A reward-driven self-organizing llmbased multi-agent system for reasoning tasks. arXiv preprint arXiv:2503.02390.   
Zhilun Zhou, Jingyang Fan, Yu Liu, Fengli Xu, Depeng Jin, and Yong Li. 2024. Synergizing llm agents and knowledge graph for socioeconomic prediction in lbsn. arXiv preprint arXiv:2411.00028.   
Changxi Zhu, Mehdi Dastani, and Shihan Wang. 2024. A survey of multi-agent deep reinforcement learning with communication. Autonomous Agents and Multi-Agent Systems, 38(1):4.   
Yanqiao Zhu, Weizhi Xu, Jinghao Zhang, Yuanqi Du, Jieyu Zhang, Qiang Liu, Carl Yang, and Shu Wu. 2021. A survey on graph structure learning: Progress and opportunities. arXiv preprint arXiv:2103.03036.   
Mingchen Zhuge, Wenyi Wang, Louis Kirsch, Francesco Faccio, Dmitrii Khizbullin, and Jürgen Schmidhuber. 2024. Gptswarm: Language agents as optimizable graphs. In Forty-first International Conference on Machine Learning.