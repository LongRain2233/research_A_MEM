# Key-value memory in the brain

Samuel J. Gershman1,2,3,∗, Ila Fiete4, and Kazuki Irie1

1Department of Psychology

2Center for Brain Science

3Kempner Institute for the Study of Natural and Artificial Intelligence,

Harvard University, Cambridge, MA, USA

4McGovern Institute for Brain Research and Department of Brain and Cognitive Sciences,

Massachusetts Institute of Technology

∗Corresponding author: gershman@fas.harvard.edu

March 5, 2025

# Abstract

Classical models of memory in psychology and neuroscience rely on similarity-based retrieval of stored patterns, where similarity is a function of retrieval cues and the stored patterns. While parsimonious, these models do not allow distinct representations for storage and retrieval, despite their distinct computational demands. Key-value memory systems, in contrast, distinguish representations used for storage (values) and those used for retrieval (keys). This allows key-value memory systems to optimize simultaneously for fidelity in storage and discriminability in retrieval. We review the computational foundations of key-value memory, its role in modern machine learning systems, related ideas from psychology and neuroscience, applications to a number of empirical puzzles, and possible biological implementations.

# 1 Introduction

Despite the apparent fragility of memory, there is no decisive evidence that information, once stored, is ever permanently lost. The storage capacity of the brain of course must be finite, but that does not seem to be the principal limiting factor on memory performance. Rather, it is the retrieval process that fundamentally limits performance: the relevant information may be there, but cannot always be found1–4. Some of the evidence supporting this view will be summarized below.

A retrieval-oriented view of memory performance places the primary explanatory burden on how memories are addressed (i.e., how the retrieval system keeps track of storage locations), and how they are queried (i.e., how the retrieval system maps sensory cues to addresses). There is a long history of theorizing about these concepts in cognitive psychology and neuroscience5,6. Recently, the field of machine learning has developed its own analysis of these concepts, which form the basis of high-performing systems like transformers and fast weight programmers7,8. There is increasing recognition that a significant aspect of intelligence (in both natural and artificial systems) is effective information retrieval9–13.

Our goal is to connect the dots between conceptualizations of memory retrieval in psychology, neuroscience, and machine learning. Central to this effort is the concept of key-value memory, which we formalize below. The basic idea is that inputs (memoranda) are transformed into two distinct representations—keys and values—which are both stored in memory. The keys represent memory addresses, while the values store memory content. Memories are accessed by first matching a query to each key, and then retrieving a combination of values weighted by their corresponding matches. Importantly, the mappings from inputs into keys and values can be optimized separately, allowing the system to distinguish between information useful for finding memories (stored in the keys) and information useful for answering the query (stored in the values). This distinction is familiar in human-designed information retrieval systems. For example, books often have alphabetically organized indices, which are helpful for finding particular subjects. The indices do not contain any information about the meaning of the subjects themselves; this information is stored in the book’s text, retrieved by going to the page number associated with the index.

We will argue that memory in the brain follows similar principles. In particular, we posit a division of labor between a key storage system in the medial temporal lobe and a value storage system in the neocortex. As reviewed below, closely related ideas have already been proposed in psychology and neuroscience. By connecting these ideas to key-value memories, we can begin to understand what makes memory in the brain computationally powerful. To illustrate these points, we present simulations that recapitulate a number of empirical phenomena. Implications for the convergence of natural and artificial intelligence are discussed in the concluding section.

# 2 Computational foundations of key-value memory

In this section, we introduce the technical ideas underlying key-value memory, exposing the multitude of ways in which this idea has been conceptualized. We place key-value memory within a modern machine learning framework by discussing how the key and value representations can be learned, comparing an end-to-end learning approach with fixed (or partially fixed) “scaffolds” for key representations.

# 2.1 From correlations to kernels

One of the earliest formalizations of a key-value memory was Kohonen’s correlation matrix memory model14, which was subsequently used by Pike 15 to explain a range of human memory phenomena. Here we slightly change the notation and terminology to bring this model into correspondence with more recent formalizations (Figure 1, left). Each input, indexed by $n ,$ consists of a key vector $\mathbf { k } _ { n }$ and a value vector $\mathbf { v } _ { n }$ (which we take to be row vectors). Intuitively, the keys encode information about memory addresses (hence we will refer to the set of possible keys as the address space), while the values encode information about memory content. These two representations are linked in memory by an “associator” matrix M, which is initialized at 0 and incremented by the outer product of the key and value vectors after each input is presented:

$$
\Delta \mathbf {M} \propto \mathbf {k} _ {n} ^ {\top} \mathbf {v} _ {n}. \tag {1}
$$

It is easy to see that this is just simple Hebbian learning between key and value units encoding the vector elements. In neurobiology, the standard interpretation is that $M _ { i j }$ is encoded by the

![](images/0c774945ec850bd5e92f17b87fa538c4405bb60250a8e7dd14c6c6535b6f75dc.jpg)

![](images/41d1e8bdf305310d3a6bf2479233dc5eef6fc802fab4c345e8d7e79ea943b86d.jpg)  
Figure 1: Two architectures for key-value memory. Black symbols denote vectors and blue symbols denote matrices. (Left) Input x is mapped to key (k), query (q), and value (v) vectors. During memory writing, the weight matrix M is updated using Hebbian learning between the key and value vectors. During reading, the query is projected onto M to produce a retrieved value $\hat { \mathbf { v } }$ . (Right) The input vector is mapped to a hidden layer $\alpha$ , which is then mapped to an output layer $\hat { \mathbf { v } }$ . The input-to-hidden weights correspond to the stored keys; the hidden-to-output weights correspond to the stored values.

synaptic strength between neurons representing value element $j$ and key element i. The synaptic strength is increased when the two neurons fire coincidentally16. Needless to say, learning in the brain is more complicated than this, but for present purposes we will take for granted the biological plausibility of Eq. 1 (see also17 for a related, but more complex, learning rule).

The correlation matrix memory is heteroassociative because M stores information about the relationship between two different kinds of objects or object properties (see also18 for one of the earliest such models). If we impose the constraint that keys and values are the same, we get an autoassociative memory19–22. This idea is now most closely associated with the work of Hopfield23, and such models (when the inputs are binary) are typically referred to as Hopfield networks.

The correlation matrix memory is queried by taking the inner product between the associator matrix and a query vector q (with the same dimensionality as the key vectors):

$$
\hat {\mathbf {v}} = \mathbf {q} \mathbf {M}. \tag {2}
$$

In neural network terms, this is equivalent to activating pattern q on the key units, which produces an activity pattern in downstream value units based on the learned synaptic strengths (M). The retrieved value vector $\hat { \mathbf { v } }$ combines stored values associated with keys that are similar to the query

vector. To see this, it is helpful to rewrite Eq. 2 in its “dual” form24,25:

$$
\hat {\mathbf {v}} \propto \sum_ {n = 1} ^ {N} \alpha_ {n} \mathbf {v} _ {n}, \tag {3}
$$

where $\left\{ \alpha _ { n } \right\}$ is a set of “attention weights” computed by $\alpha = \sigma ( S ( \mathbf { K } , \mathbf { q } ) ) = \mathbf { q } \mathbf { K } ^ { \top } .$ , and K is the matrix consisting of all $N$ key vectors (i.e., its rows are $\mathbf { k } _ { n }$ ). The function $S ( \cdot , \cdot )$ is a similarity kernel (linear in this case), expressing the match between keys and queries, and $\sigma ( \cdot )$ is a separation operator (the identity function in this case), pushing apart similar memories. The retrieved value vector is thus a weighted combination of stored values, where the attention weights correspond to the similarity between the query and each key, mapped through a separation operator.

The dual form is useful because it shows how the model can be straightforwardly generalized by considering other similarity kernels and separation operators. Any positive semidefinite kernel can be expressed as the inner product in some vector space26, which means that alternative similarity functions can be constructed by mapping the keys and queries through a feature transform $\phi ( \cdot )$ applied to each row:

$$
S (\mathbf {K}, \mathbf {q}) = \phi (\mathbf {q}) \phi (\mathbf {K}) ^ {\top}. \tag {4}
$$

It is also possible to construct kernels with infinite-dimensional vector spaces by working directly with an explicitly defined similarity kernel, such as the widely used radial basis function kernel, which Tsai and colleagues27 found to produce the best results.

The generalized correlation matrix memory can implement the celebrated self-attention mechanism in transformers7:

$$
S (\mathbf {K}, \mathbf {q}) = \frac {\mathbf {q} \mathbf {K} ^ {\top}}{\sqrt {D}} \tag {5}
$$

$$
\sigma (\tilde {\alpha}) = \frac {\exp (\tilde {\alpha})}{\sum_ {n} \exp (\tilde {\alpha} _ {n})}, \tag {6}
$$

where $D$ is the dimensionality of the key/value vectors, and the softmax function is used as the separation operator. Here we have used $\tilde { \alpha }$ to denote the attention weights prior to the application of the separation operator. When $\sigma ( \cdot )$ is set to the identity function, we recover linearized attention25, which can be expressed as a special form of recurrent neural network known as a fast weight programmer8,28. Linearized attention has a potential computational advantage over softmax attention, because its recurrent form allows for linear-complexity sequence processing, while giving up the parallel computation property of the attention form (whose complexity, however, is quadratic in the number of sequence elements). Several studies 29,30 have shown how to rigorously approximate softmax attention using random features.

As shown by Millidge and colleagues31, a variety of classical memory models can also be derived by different choices of similarity kernel and separation function. For example, sparse distributed memory32 can be obtained by setting $\sigma ( \cdot )$ to a threshold function, and dense associative memory33 can be obtained by setting $\sigma ( \cdot )$ to a rectified polynomial.

In the noiseless setting, the ideal separation function is the max operator, since this will always return the stored value associated with the matching key31. However, this separation function is not robust to noise—small perturbations can cause large retrieval errors. Thus, the design of a memory system needs to balance separability and robustness. In addition, the memory may

be used for generalization to new inputs 7,34,35, in which case perfect matching is not the goal. For example, key-value memories have been used extensively for question-answering tasks 36,37, where q represents a question and v represents an answer. The system stores a set of questionanswer pairs and tries to use this knowledge base to answer novel questions.

# 2.2 Representational structure

So far, our setup has assumed a memory system provided with keys, values, and queries—where do these representations come from? In modern machine learning, they are derived as mappings from input vectors, $\left\{ { \bf x } _ { n } \right\}$ . A typical assumption in transformers and fast weight programming is to parametrize the mappings with a set of linear functions:

$$
\mathbf {k} _ {n} = \mathbf {x} _ {n} \mathbf {W} _ {k} \tag {7}
$$

$$
\mathbf {v} _ {n} = \mathbf {x} _ {n} \mathbf {W} _ {v} \tag {8}
$$

$$
\mathbf {q} _ {n} = \mathbf {x} _ {n} \mathbf {W} _ {q}. \tag {9}
$$

where $\{ \mathbf { W } _ { k } , \mathbf { W } _ { v } , \mathbf { W } _ { q } \}$ are learned weight matrices. The input vectors may themselves be learned embeddings of raw input data, harnessing the power of deep learning systems trained end-to-end.

In some systems, the key and query mappings are assumed to be fixed, either randomly or based on some regular structure. In these systems, the address space is conceived as a kind of “scaffold” for the indexing of information content. In the sparse distributed memory model 32, the scaffold is random, so that similar keys do not systematically index similar values. This mimics (approximately) the organization of random access memory in digital computers. A familiar example of a structured scaffold is the alphabetical index found at the end of books. In the Hopfield network23 and related autoassociative memory models, the scaffold is identical to the value space. This property endows the models with content addressability38: memory addresses are accessed by matching values directly to queries. Most psychological and neural models of memory share this property, though they implement it in different ways.

Some models assume that the scaffold is randomly constructed in such a way that it carries a structural imprint. For example, if inputs are assigned to random addresses, but these addresses change slowly over time, then inputs experienced nearby in time will encoded as more “similar” in the address space. Temporal autocorrelation, in the absence of additional structure, is able to account for many aspects of human39 and animal40 memory.

Below, we will discuss neurobiologically inspired architectures that implement a fixed scaffold, which can even outperform a learned mapping. We will also show that learning the key and query mappings allows us to explain data on repulsion effects in memory and hippocampal representations. These results pose a number of questions for future research: Does the brain use a combination of fixed and learned mappings? Is such a combination useful for machine learning applications?

# 2.3 The ubiquity of key-value memory

The work reviewed above focused on explicit constructions of key-value memory. It turns out that other models are sometimes implicitly equivalent. Irie and colleagues12 showed that linear layers trained by gradient descent (ubiquitous in many machine learning models) can also be expressed as key-value memories. Here we briefly review this theorem.

Let ${ \bf x } _ { n }$ be the input vector at time $n ,$ as in the previous section. The output of a linear layer is ${ \bf y } _ { n } = { \bf x } _ { n } { \bf W } _ { , }$ , where W is as weight matrix. The weight matrix is trained by gradient descent, yielding the following after $N$ timesteps:

$$
\mathbf {W} = \mathbf {W} _ {0} + \sum_ {n = 1} ^ {N} \mathbf {x} _ {n} ^ {\top} \mathbf {e} _ {n}, \tag {10}
$$

where $\mathbf { W } _ { 0 }$ is the initial weight matrix, and $\mathbf { e } _ { n } = - \eta _ { n } ( \nabla _ { \mathbf { y } } \mathcal { L } ) _ { n }$ is the error signal with learning rate $\eta _ { n }$ and loss function $\mathcal { L }$ . Generalizing a classic result on kernel machines 41, Irie and colleagues 12 showed that this construction is equivalent (in the sense of producing the same output for a given input) to the following linear key-value memory:

$$
\mathbf {y} = \mathbf {x} \mathbf {W} _ {0} + \sum_ {n = 1} ^ {N} \alpha_ {n} \mathbf {v} _ {n}, \tag {11}
$$

where (using our earlier notation) $\alpha = { \bf q } { \bf K } ^ { \top }$ with $\begin{array} { r } { { \bf v } _ { n } = { \bf e } _ { n } , { \bf k } _ { n } = { \bf x } _ { n } , } \end{array}$ and $\mathbf { q } = \mathbf { x } ,$ , given an arbitrary input x. Thus, linear layers effectively memorize their experienced error patterns, computing their outputs as linear functions of these memories. This interpretation is intriguing in light of the fact that errors are particularly salient in human memory42–46.

The linear layers retain information about all training inputs—they never “forget”12. However, retrieval access may be (transiently) lost. We discuss evidence for this idea from psychology and neuroscience below.

# 3 Neurobiological substrates

While key-value memories are loosely inspired by the brain, it remains an open question how to implement them in a biologically plausible manner. Eq. 1 is a (somewhat) biologically plausible rule for learning associations between keys and values, but we still need rules for storing the keys and values themselves. In the section on representation learning, we described the widely used approach of modeling keys, queries, and values as linear mappings from input vectors (which themselves could be learned). This implies additional learning rules for the linear mappings. One could posit that they are learned by backpropagating the errors from whatever objective function is being optimized for a downstream task17. This would require a biologically plausible approximation of the backpropagation algorithm47.

Kozachkov and colleagues 48 have proposed an architecture based on the “tripartite synapse” consisting of pre-synaptic and post-synaptic neurons modulated by an astrocyte (a type of glial cell). In particular, they posited that this motif applies to the hidden-to-output synapses in the three-layer network implementation of key-value memory. The activation of each astrocyte process is modeled as a linear function of the hidden unit activations. They showed how the astrocyte processes collectively compute the similarity function $S ( \mathbf { K } , \mathbf { q } )$ , which then multiplicatively modulate the hidden-to-output weights so that the network as a whole implements the transformer self-attention described earlier.

Alternatively, Tyulmankov and colleagues 49 have proposed a non-Hebbian learning rule for key learning. They view the key-value memory as a three-layer neural network, where the input x (first layer) is transformed into a pattern of attention $\pmb { \alpha }$ (hidden layer), which is finally transformed into retrieved values $\hat { \mathbf { v } }$ (output layer); see the right panel of Figure 1. Each hidden layer

unit represents a “slot” to which a single input (or possibly multiple inputs) gets assigned. In this view, the key matrix K corresponds to the input-hidden synaptic strengths, and the value matrix V (where row $n$ corresponds to value vector $\mathbf { v } _ { n }$ ) corresponds to the hidden-output synaptic strengths. The proposed learning rule for the synapse connecting input unit $j$ to hidden unit $i$ is (simplifying slightly, and dropping time indices):

$$
\Delta K _ {i j} \propto \mu \gamma_ {i} (x _ {j} - K _ {i j}), \tag {12}
$$

where $\mu \in \{ 0 , 1 \}$ is a global third factor (possibly a neuromodulator like acetylcholine or dopamine) and $\gamma _ { i } ~ \in ~ \{ 0 , 1 \}$ is a local third factor (possibly a dendritic spike). The factors are binary to promote sparsity in the hidden layer. The local third factor tags the least-recently-used hidden unit as eligible for plasticity. The authors point out that the key learning rule resembles behavioral time scale plasticity50, which has been observed in the hippocampus. The possibility that key learning occurs in the hippocampus will be considered in detail below.

For value learning, Tzyulmankov and colleagues clamp the output layer to the target value v and then update the synapse connecting hidden unit $i$ to output unit m according to:

$$
\Delta V _ {m i} \propto \mu \gamma_ {i} \alpha_ {i} \left(v _ {m} - V _ {m i}\right). \tag {13}
$$

This is a Hebbian rule, because it depends on the co-activation of hidden and output units. It could potentially describe modification of the output projections from the hippocampal area CA1 to entorhinal cortex.

Using a similar architecture (but with the important addition of recurrence), Whittington and colleagues51 have shown that the Tolman-Eichenbaum Machine 52, a model of the entorhinalhippocampal system, implements a form of key-value memory. The hippocampus, according to this model, stores conjunctive representations of sensory inputs from lateral entorhinal cortex and a “structural code” provided by cells in medial entorhinal cortex, which are updated recurrently. Conjunctive representations in the hippocampus function as both the keys and the values (i.e., an autoassociative memory). In a 2D open field, the model can reproduce hippocampal “place cells” (firing fields localized to a particular spatial location), while the structural code generates grid celllike responses (grid cells fire with hexagonal periodicity as an animal moves through space53). In environments of different dimensions, topologies, and geometries, the structural code need not be grid-like. Whittington and colleagues note that the structural code in their model functions as a form of “position encoding”—widely used in transformers and other sequence models—where the encodings (i.e., addresses) are adapted to the structure of space. This is a critical aspect of the model: the structure-sensitive properties of their modeled hippocampal and entorhinal cells would not have been obtained using the fixed positional encodings typically used in regular transformers. Related ideas have proven successful in the machine learning literature54.

# Box 1: Memory with error-correcting key-query matching

Vector- $\mathrm { \cdot H a S H } ^ { 5 5 }$ and ${ \mathrm { M E S H } } ^ { 5 6 }$ are tripartite networks consisting of an input (sensory) layer s, a densely connected layer $d ,$ and a layer consisting of a modular set of fixed recurrent attractor networks $a$ . These models dissociate content storage from query-matching and directly translate to a key-query-value formulation. Define the tripartite network weights to be $\mathbf { W } _ { s d }$ ${ \mathbf { W } } _ { s d } , { \mathbf { W } } _ { d a } , { \mathbf { W } } _ { a d } , { \mathbf { W } } _ { d s } ,$ $\mathbf { W } _ { d a }$ and the attractor, dense layer, and sensory states to be $\{ \mathbf { a } \} , \{ \mathbf { d } \} , \{ \mathbf { s } \} ,$ respectively. Given some sensory input s, the network retrieves the nearest relevant stored state ˆs by performing the following operations (treating the dense layer responses as linear, though in practice they are nonlinear):

$$
\hat {\mathbf {s}} = \phi (\mathbf {s} \mathbf {W} _ {s d} \mathbf {W} _ {d a}, \{\mathbf {a} \}) \mathbf {W} _ {a d} \mathbf {W} _ {d s}.
$$

Here $\phi ( . , . )$ represents an efficient nearest-neighbor (NN) operation performed by the scaffold (combined dense and attractor layers), to select the closest attractor state for the given input. The readout weights $W _ { a d } , W _ { d s }$ reconstruct the sensory memory from the selected attractor state. This model maps to the key-value system of Figure 1B: the output of the attractor layer is a (denoised) query

$$
\mathbf {q} _ {n} = \phi (\mathbf {s W} _ {s d} \mathbf {W} _ {d a}, \{\mathbf {a} \}) \equiv \mathbf {x} _ {n}
$$

and the key and valuweights, repsectively, $\textbf { K } = \textbf { W } _ { a d } ^ { \top }$ re, $\textbf { V } = \textbf { W } _ { d s }$ he attractor-to-dense and dense-to-sensory. Thus, the scaffold computes a similarity $\sigma ( S ( { \bf K } , { \bf q } ) )$ and the network produces the output

$$
\hat {\mathbf {v}} _ {n} = \hat {\mathbf {s}} _ {n} = \alpha_ {n} \mathbf {W} _ {d s} = \phi (\mathbf {s} _ {n} \mathbf {W} _ {s d} \mathbf {W} _ {d a}, \{\mathbf {a} \}) \mathbf {W} _ {a d} \mathbf {W} _ {d s} = \sigma (S (\mathbf {K}, \mathbf {q} _ {n})) \mathbf {V}
$$

where the attention weights (Fig. 1B’s hidden states) are $\alpha _ { n } = \mathbf { x } _ { n } \mathbf { W } _ { a d }$ .

The value weights (from the dense to the sensory layer) and part of the query weights (from the sensory to the dense layer) are trained by a Hebbian rule, so that $\begin{array} { r } { \bar { \bf W _ { \it s d } } = \sum _ { n } \bar { \bf s } _ { n } ^ { \top } \mathbf { d } _ { n } } \end{array}$ and $\begin{array} { r } { \mathbf { W } _ { d s } = \sum _ { n } \mathbf { \dot { d } } _ { n } ^ { \top } \mathbf { s } _ { n } } \end{array}$ the weights $\mathbf { W } _ { d a }$ are random and fixed, and $\mathbf { W } _ { a d }$ are also held fixed (after being set as a pseudoinverse on the random $\mathbf { W } _ { d a } ,$ so these may also be viewed as random). Thus, the query weights are partly random, fixed, and coupled with the keys, and partly learned through Hebbian plasticity. The choice of modular attractor states and random projections (key weights) from attractor to dense layer pre-defines both well-separated keys and a NN operation for robust error-correction and matching of noisy queries with keys. Though learning is heteroassociative and values are stored separately from keys and queries, unlike Hopfield networks, the networks are content-addressable.

In contrast to the adaptive addresses used in the Tolman-Eichenbaum Machine, Sharma, Chandra and colleagues56,55 proposed neurobiologically motivated models (MESH and Vector-HaSH) that use random projections of modular fixed point (attractor) networks to address memories (see Box 1 for details). The fixed points within each modular attractor, which are fixed and not learned, may be sparse and random56 or possess a 2-dimensional geometry55 such as the hexagonally periodic activity patterns of grid cells. Consisent with the non-learned assumption, grid cells exhibit a fixed relational organization regardless of environment and behavioral state57–60. The same

relationships are re-used to encode the organization of non-spatial variables61–63. The fixed modular attractor networks in the models randomly and densely project into a larger network (the hippocampus in Vector-HaSH) with self-consistent return projections, forming a large scaffold of quasi-random stable fixed point address states. Thus, we may view MESH and Vector-HaSH as fitting the diagram of Fig. 1 (right), except that the hidden layer in the diagram is replaced by a bipartite scaffold circuit (modular attractor network bidirectionally coupled to the densely connected layer) that computes nonlinear robust NN search to compute $\sigma ( S ( { \bf K } , { \bf Q } ) )$ , with keys that are random and fixed. In Vector-HaSH, keys reside in hippocampus and the memory values are reconstructed at the sensory input layer (cortex).

The advantages of this construction, beyond standard key-value constructions, are that (i) the address space is large, and (ii) the scaffold fixed points possess large and uniform basins of attraction. These properties allow many memories to be robustly addressed, with error correction and without the “memory cliff’ that afflicts many memory models combine keys and values 64,65 or learn the keys 55: after a threshold number of inputs have been stored, retrieval performance crashes. In contrast, MESH and Vector-HaSH produce graceful degradation as multiple memories share overlapping addresses, much like human memory66. Remarkably, these models also outperform a flexible encoder trained to minimize reconstruction error67, suggesting that the entorhinalhippocampal system may be a highly effective memory addressing system discovered by evolution.

The 2-dimensional and geometric aspect of Vector-HaSH over MESH becomes relevant for memorizing (possibly discrete) items embedded, remembered, or retrieved through traversal of a continuous low-dimensional space. This may involve sequential episodic memories (where time is the continuous dimension) or spatial memories (where space is the continuous dimension).

# 4 Evidence from psychology and neuroscience

In this section, we review several lines of evidence suggestive of key-value memory in the brain. Our review is organized around the following claims central to the theory:

1. Memories are stored indelibly but subject to retrieval interference.   
2. Memories are addressed by representations (keys) that are distinct from the representations of memory content (values). The representational structure of the keys is optimized for discriminability, whereas the representational structure of the values is optimized for fidelity.   
3. The information stored in keys is not available to conscious access (i.e., recall). In other words, the brain uses keys to recall values but cannot recall the keys themselves.

# 4.1 Retrieval interference, not erasure, is the principal limiting factor in memory performance

An important implication of key-value memory systems is that memory performance is constrained primarily by the ability to retrieve relevant information, not by storage capacity. In this section, we review some of the theoretical arguments and empirical evidence that this assumption can be plausibly applied to the brain.

A number of attempts have been made to estimate the storage capacity of the human brain68. Depending on different assumptions about numbers of neurons and connectivity, estimates can range from $1 0 ^ { 7 }$ to $1 0 ^ { 1 5 }$ bits. The total number of bits arriving from sensory systems with minimal compression are estimated to range from $1 0 ^ { 1 3 }$ to $1 0 ^ { 1 7 }$ . These rough numbers suggest that with adequate compression, storage capacity may not be the strongest constraint on memory performance.

Perhaps more persuasively than these theoretical arguments, we can make the case based on observations about behavior. If memory storage has reached its capacity limit, then it is impossible to store new information without removing some old information. This implies that old information should become permanently inacessible at some point. In contrast, studies of human memory demonstrate that memories can be stored over decades, despite being rarely rehearsed69–72.

One might try to explain these findings by arguing that memory storage has not reached the capacity limit, but then it would be very challenging to explain forgetting over the much shorter intervals studied in experiments on list memory. When presented with a list of random words, the proportion of recalled words declines with list length (typically in the range of 5 to 20 items). If this was due to removal of items from memory, then one would expect catastrophic forgetting over intervals of decades. Furthermore, a series of experiments by Shiffrin73 demonstrated that, when presented with a sequence of lists and then asked to recall the list before the most recently presented list, performance depended not on the length of the most recent list but only on the length of the list being recalled. This suggests that forgetting is not due to displacement of old items by items from the last list. The limiting factor is retrieval interference from other items on the same list.

Using word-location pairs, Berens and colleagues 74 separately estimated memory accessibility (whether or not a location is recalled at all given a word cue) and precision (the variance of angular errors). They found that accessibility, but not precision, declined as a function of the retention interval. Similar results have been reported using memory for real-world events75. Thus, memories do not melt into oblivion, but rather disappear from view. When they come back into view, they are as sharp as they were before they disappeared.

Supposedly lost memories can be found when appropriate retrieval cues are used76, when the number of retrieval attempts increases 77,78, or even spontaneously after a sufficiently long delay79. This holds not only for standard memory tasks in healthy subjects but also for retrograde amnesia induced experimentally or by neurological damage. Spontaneous “shrinkage” of amnesia is a common clinical observation following brain trauma80, presumably due to the restoration of memory access. In laboratory studies, amnesia can be induced experimentally in a range of ways, such as electroconvulsive shock, hypothermia, protein synthesis inhibition, and lesion or inactivation of the hippocampus, with recovery also induced in a range of ways81,82,4. For example, protein synthesis inhibition following classical conditioning typically eliminates conditioned responding on long-term memory tests. However, delayed testing sometimes reveals recovery of performance83–85. It is even possible to restore performance using the amnestic agent itself86–88.

These observations about amnesia mirror well-known phenomena in classical conditioning. Extinction of a previously conditioned stimulus (i.e., presenting the stimulus in the absence of the unconditioned stimulus) causes a decline in conditioned responding, eventually reaching baseline levels. This decline is transient: conditioned responding can return spontaneously89, or can be induced by a single “reminder” of the unconditioned stimulus90.

In summary, considerable evidence suggests that failures of remembering primarily arise from

failures of retrieval, typically due to interference from other memories. Memories thought to be lost can later be found under the right conditions. We will explore this idea computationally when we discuss model simulations.

# 4.2 Distinct representations of keys and values

The influential “Complementary Learning Systems” framework holds that there is a division of labor between the hippocampus and neocortex91,92, with the hippocampus specialized for episodic memory (remembering events that occurred in a specific spatiotemporal context) and a set of neocortical areas (sometimes referred to as “association cortex”) that are specialized for semantic memory (remembering regularities that generalize across episodes). This framework has also influenced the design of artificial intelligence systems93. In this section, we will argue that this framework can be understood in terms of key-value memory.

Rather than thinking about the hippocampus as directly storing memory content, we can alternatively conceptualize it as storing keys and matching queries to keys, which address memory content stored in neocortex. This view emphasizes the point that episodic memories need to be bound to semantic content—otherwise, they’re essentially empty vessels, as in cases of semantic demantia, where degeneration of anterior temporal lobe and prefrontal areas produces profound semantic impairments despite relatively intact recognition memory for recent experiences 94.

If the hippocampus provides the keys necessary for activating neocortical values, then we would expect a causal interplay between the two. Indeed, there is empirical evidence for the following facts: (i) cortical encoding-related activity is reinstated at the time of memory retrieval; (ii) cortical reinstatement depends on the hippocampus; and (iii) the reinstatement is necessary for memory retrieval95–100.

Another line of evidence comes from studies of generalization. In the absence of the hippocampus, neocortical values cannot be accessed in a targeted way, leading to overgeneralization. A study by Winocur and colleagues 101 offers a good example. When trained to anticipate a shock in Context A, rats specifically freeze in Context A but not in Context B when tested a day later. When tested a week later, rats show a generalization effect (loss of context specificity), freezing in both contexts. This generalization might arise because of interference from memories acquired during the intervening time. Context specificity can be restored by “reminding” the rat of the original memory (briefly placing it back in Context A). This reminder effect can be interpreted as activation of the appropriate address given a highly specific cue. Importantly, the reminder effect disappears in hippocampal-lesioned rats, consistent with the claim that the hippocampus stores the keys necessary for targeting specific memories (see also102 for converging evidence).

The idea that the hippocampus stores keys was to a large extent anticipated by the hippocampal memory indexing theory103, which proposed that the hippocampus indexes memory content stored in neocortical areas. Since it was first proposed, new techniques have uncovered much more detailed support for the theory104,105. In particular, the advent of activity-dependent labeling and optogenetic manipulation have enabled the identification of “engram cells” in the hippocampus which are causally linked to specific memories106,107. Goode and colleagues 105 interpret hippocampal engrams as indices (in the sense of Teyler and DiScenna), linking together information stored in a distributed network of neocortical areas.

Several brain-wide engram mapping studies in rodents have reported a collection of neocortical (as well as subcortical) areas that are active during both encoding and retrieval, and therefore qualify as engrams 108,109. What makes the hippocampus special is its role as a hub region with

high connectivity to neocortical regions 110. This allows the hippocampus to exert strong control over neocortical regions. In addition, hippocampal engrams are highly sparse (involving a small subset of hippocampal cells) and conjunctively tuned to multiple sensory and cognitive inputs; these features make hippocampal engrams well-suited to encoding episodically unique memories. A recent study of food-caching birds111 provides a particularly dramatic demonstration: hippocampal ensembles encoded unique representations for over 100 cache sites (including multiple caches at the same location), which were reactivated upon memory retrieval.

If hippocampal representations are optimized for discriminating between distinct episodes in a cue-dependent manner, then we should expect changes in these representations under different retrieval demands. For example, overlapping routes in spatial navigation need to be discriminated in order to avoid confusion. Chanales and colleagues112 showed that this situation produces repulsion of hippocampal representations specifically for overlapping locations (see also113). The repulsion effect emerges gradually over the course of learning, ultimately reversing the objective similarity relations between locations. The strength of the repulsion effect also correlated with behaviorally measured discrimination accuracy.

Note that optimization for discriminability is only part of the story, since the hippocampus receives noisy inputs which may activate the wrong keys. The hippocampus needs to do some error correction / pattern completion in order to “clean up” the retrieved keys. This may be accomplished by attractor dynamics such that nearby inputs get mapped to a corresponding attractor (pattern completion), while more distant inputs are separated into distinct attractors (pattern separation). It remains to be seen if such attractor dynamics are implemented by the recurrent hippocampal-entorhinal loop55 (Box 1) or by the proposal that both occur within hippocampus, with pattern separation by dentate gyrus and pattern completion by area CA3114.

In summary, evidence suggests a division of labor between key encoding in the hippocampus and value encoding in the neocortex. Hippocampal keys are optimized for discrimination, whereas neocortical values are optimized for encoding semantic regularities.

# 4.3 Values, but not keys, are available for recall

Keys store information which is never overtly recalled. Testing this hypothesis is challenging because it is possible that some information stored in keys is also stored in values. Clear support comes from evidence that there is information used to guide retrieval (putatively stored in keys) which nonetheless is not available for overt recall. More technically, we characterize “overt recall” of a key as the ability to report some aspect of the key vector. The evidence presented below suggests that keys can be matched to queries without making the content of the keys available for report.

Many of us are familiar with the experience of having a memory at the “tip of the tongue”— stored in memory yet temporarily unrecallable 115,116. Closely related is the “feeling of knowing”— a subjective judgment about the likelihood of subsequently recognizing items which are presently unrecallable. The typical study procedure is to present subjects with difficult general knowledge questions, elicit feelings of knowing for questions they cannot presently answer, and then subsequently test their ability to recognize correct answers to the questions. An important finding from this literature is that feelings of knowing predict (though not perfectly) subsequent recognition117,118, indicating that people are able to judge whether some piece of information is stored in memory despite not being able to retrieve it. Similar results have been found with cued recall tests119. Another clue comes from studies examining response times: Reder120 found that people

could report answerability for trivia questions faster than they could report the answers, again indicating that metamemory does not require retrieval of memory content. Furthermore, feelings of knowing (but not recall) can be spuriously increased by increasing cue familiarity121,122, possibly due to increased key-query match without increased probability that the correct keys are matched.

These phenomena are broadly consistent with the hypothesis that key-query matching can be used to judge whether some information (e.g., the answer to a question) is stored in memory, without accessing the memory content (value) itself. This idea has appeared in the human long-term memory literature under various guises; for example, Koriat123 discuss the tip-of-the-tongue phenomenon in terms of “pointers” (cues that specify a memory address without specifying memory content), whereas Morton and colleagues124 use “headings” to refer to essentially the same idea.

A pointer system has also been invoked to understand short-term memory: rather than storing transient copies of long-term memories, short-term memory might store pointers which refer to information in long-term memory125,126. This may explain why people can detect changes even when they cannot report what exactly has changed127, analogous to the “butcher on the bus” phenomenon in long term memory128, where people can recognize familiar items without being able to recollect any details about them. Both change detection without identification and familiarity without recollection might be accomplished using keys (pointers) that are content addressable but do not obligatorily activate their associated values55.

Many standard models of memory cannot check whether information is stored without retrieving that information at least partially. This is because most models base recognition memory judgments on the match between the cue and stored content; there is no separate representation of keys that can be used to check whether something is stored in memory. This makes it challenging for these models to explain why people can be knowledgeable about what is stored in memory without recalling it.

# 5 Illustrative simulations

In this section, we provide two simulations that illustrate some of the distinctive characteristics of key-value models highlighted above. Further implementation details can be found in our public code repository, available at https://github.com/kazuki-irie/kv-memory-brain.

# 5.1 Distinct representations for keys and values

As we discussed earlier, one of the essential properties of key-value memory is the separate representations allocated for keys and values, which can be optimized for their specific roles in retrieval and storage, respectively. Here we present a toy simulation that illustrates this property.

We consider a minimal key-value model whose trainable parameters are a set of pairs of key and value vectors (i.e., in this model, we skip the step of mapping inputs to keys and values, and directly examine the properties of key/value representations). We set both keys and values to be 2-dimensional (2D) vectors which can be easily visualized in the 2D space. The model can take an arbitrary 2D vector as an input which is treated as a query; the query is compared to all the keys through dot product to obtain a similarity score for each key (as in Eq. 5). The resulting scores are normalized by applying the softmax function (Eq. 6) to obtain the final “attention” scores. The output of the model is the weighted average of value vectors using these attention scores (Eq. 2).

![](images/7fd88bab989416b89952a06835ddc731bb0ab32013943dc80bd45da575602c0a.jpg)  
A

![](images/bcf2d36bb9552bbd36efc2c396fc9ac6bfe3d15173852e41423fed3926a8d9cf.jpg)

![](images/5f18edbdc291123e61dd7ec3c96a0b67adbca6e7d8c90013fa184aaa353eb56b.jpg)

![](images/a33038d7323026e9841cb428a0ea626de6ece4de33a33534311795b9b3dd7ff9.jpg)

![](images/d26b9bb8ed4b0d9b04c910f5e2b6d65d6dd87098ff0956bb9dbff309a92ff80e.jpg)

![](images/8ca3e8d5b9549ab0313c1358e80858f8ac1b526117ceee6e3b0d6b0220f6a1e6.jpg)

![](images/877afe0033c0f7915ee4e1cd03be8249a990bd7a64e9d71488d5af32c71207d4.jpg)  
B

![](images/8fff149ab89a4b764433b206afe68139fa87273a85cc3badea3f685f2d00769a.jpg)

![](images/9d12212ff4bb2958285390075c3a43264abf49873cd779c1e584ff5adf7d5891.jpg)

![](images/fd3ccadb323b573f0ea1f74705668df6d0cb6e9bfd1544b268aba21732a2ffdd.jpg)

![](images/6f221522850fe51779106a15463f98d20ed5368b82c4db5a97e090c2784e6201.jpg)

![](images/6fcdf0a12b1fbc091e49e89f64e196847248bb144e8d7f7fc1dff4771ea641b4.jpg)  
Figure 2: Optimization of key and value representations. Each point represents an event in the memory and belongs to one of (A) two or (B) three classes, represented by different colors. In each case, the evolution of key (Top row) and value (Bottom row) representations during the optimization process is shown; each row shows (Left) Random initialization, (Middle) trajectory of representations during the optimization process, with the final positions marked by gray points, (Right) final configuration. We observe that keys are optimized for retrieval/separability, while values are optimized to store the memory content.

To train the model, we randomly assign each key/value pair to a class; we test two settings using either two or three classes in total. Each class has a fixed feature vector (representing some specific object or event): in the two-class case, the feature vectors for Class $' 0 ^ { \prime }$ and $\mathbf { \zeta } ^ { \prime } 1 ^ { \prime }$ are vectors $( 0 , 1 )$ and $( 1 , 0 )$ in the 2D space, respectively; in the three-class case, we additionally have a third class, Class $' 2 ^ { \prime }$ with $( 1 , 1 )$ as its feature vector. The task of the model is to output the correct class feature vector when one of the keys is fed to the model as input. We apply the sigmoid function to the value vectors to ensure their effective values are between 0 and 1. The key and value vectors are initialized with a uniform distribution between 0 and 1, and our goal is to examine what key and value representations emerge when this key-value model is optimized for this simple retrieval task. We use the mean squared error loss and the gradient descent algorithm, as is commonly used in modern deep learning.

The results are shown in Figure 2. We observe that key and value representations effectively exhibit different optimal configurations. The key configuration is optimized for softmax-based discrimination, facilitating effective retrieval: as we can see in Figure 2A, Top row (the two-class case), the two classes take two opposite quadrants (which are highly distinguishable through dot product and softmax). The trend is similar for the three-class case (Figure 2B, Top row). In contrast, the value representations are optimized to represent the class features (i.e., the memory content). For example, in the two-class case (Figure 2A, Bottom row), they are optimized to represent $( 0 , 1 )$ for Class ‘blue’ and $( 1 , 0 )$ for Class ‘red’. Again, the trend is similar for the three-class case (Figure 2B, Bottom row). This illustrates how the key-value memory architecture allows for separate representations for keys and values, optimized for retrieval and storage, respectively.

# 5.2 Forgetting as retrieval failure, and recovery by memory reactivation

Another distinctive property of the key-value memory we highlighted earlier is that, as recall relies on successful retrieval, forgetting can be conceptualized as retrieval failure; that is, even when a memory trace (i.e., a key/value pair corresponding to an event) is stored in memory, forgetting can still occur when retrieval fails due to interference/inaccessibility. This also implies that, if we manage to fix the failure in the retrieval process, there is a hope for recovering the corresponding memory without having to relive the event itself. Here we present a simulation illustrating these phenomena using an artificial neural network that learns two tasks sequentially (the so-called continual learning scenario), and examine it through the lens of key-value memory. We also highlight how this simple experiment echoes neurobiological findings on optogenetic recovery of memory following retrograde amnesia129,130.

We train a simple feedforward neural network on two binary image classification tasks sequentially. Using two classic image datasets commonly used in deep learning, MNIST and FashionMNIST131,132, we construct the two toy tasks that involve classifying images from the two first classes of MNIST (digit $' 0 ^ { \prime }$ vs. ‘1’) and FashionMNIST (‘T-shirt’ vs. ‘Trouser’), respectively. The model has one hidden layer (i.e., it has two linear transformations: input-to-hidden, and hiddento-output mappings with a rectifier linear activation function in-between). The input images are grayscale and their dimension is $2 8 \times 2 8 ,$ they are flattened to yield a 784-dimensional vector accepted by the input layer. We set the hidden-layer dimension to 64, and the model output size is 4 (for two times two-way classification tasks). The model is trained on the cross-entropy loss using the gradient descent algorithm; by applying the dual formulation described earlier, each linear layer in the model can be formalized as a key-value system keeping memory traces of the entire learning experience by storing layer inputs as keys and error signals as values for every learning step.

In this sequential learning setting, we first train the model on Task 1 (MNIST) for 5 epochs, after which the model is trained for another 5 epochs on the training dataset of Task 2 (FashionM-NIST) without having access to the Task 1 training data anymore. While such a training process produces a set of weight matrices for neural networks in their conventional form, in the key-value memory view, the final model consists of a sequence of key/value vectors; in this specific scenario of two-task sequential learning, each key/value pair belongs to either Task 1 (MNIST) or Task 2 (FashionMNIST) learning experiences.

Figure 3A shows the evolution of model performance on the test set of the two tasks as a function of training epochs. We observe that the model achieves ${ \sim } 9 9 \%$ test accuracy on Task 1 (MNIST) in the first 5 epochs corresponding to Task 1 learning, but this performance drops to ${ \sim } 9 \%$ after learning Task 2 (FashionMNIST) until the model achieves ${ \sim } 9 5 \%$ test accuracy on Task 2 (we deliberately train the model long enough to observe forgetting). This amnesic phenomenon, reminiscent of catastrophic forgetting in neural networks65,133,134, is intriguing given the key-value memory view of the model, in which the key/value memory pairs belonging to Task 1 remain part of the model parameters, explicitly and indefinitely. By using the same terminology as in neuroscience experiments129, these Task 1-related key/value memories became “silent” after Task 2 learning.

An interesting question is whether we can reactivate these silent key/value memories to recover the model’s performance on Task 1 without any retraining on Task 1, akin to how experimental neuroscientists successfully reactivated “silent engrams” through an optogenetic procedure 130. For this, we introduce a single positive scalar $\beta \geq 1$ (an “optogenetic strength”) to multiply/am-

![](images/b01635e2a6de1d4d91c87ef52d4f044fff4c84f74a4a82d81a47fc8ad4a692e6.jpg)

![](images/180a9d5121e11adab7c179c3364007aec03bed447fa52c9c301cd776d7bb3855.jpg)  
Figure 3: Forgetting and reactivation of memory events. A one-layer feedforward neural network is trained on two tasks sequentially, Task 1 and 2, constructed using the MNIST and FashionM-NIST datasets, respectively. (A) The evolution of the test classification accuracy for the two tasks as a function of training epochs. After epoch 5, the training dataset changes from Task 1 to Task 2; resulting in forgetting of Task 1 as the model learns Task 2. (B) The accuracy of the trained model on Task 1 as a function of the value of the artificial scaler $\beta$ used to amplify the keys in all key-value memory pairs corresponding to Task 1 learning.

plify the keys (or, equivalently in this model, the values) in all key-value pairs corresponding to Task 1 in the trained model. Figure 3B shows the performance of the model on Task 1 (MNIST) as a function of the optogenetic strength $\beta$ ( $\beta = 1$ corresponds to no intervention on the model). We observe that by simply increasing $\beta$ (i.e., by artificially “reactivating” the existing key-value memories corresponding to the model’s prior MNIST learning experiences), the model becomes capable of solving MNIST again without any retraining.

This simulation not only illustrates the core property of the key-value memory, where forgetting can be attributed to retrieval failure, but also resonates with the neuroscientific findings of silent memory engrams in retrograde amnesia and their recovery through artificial reactivation.

# 6 Conclusions

Our goal in this paper was to connect ideas about key-value memory across artificial intelligence, cognitive science, and neuroscience. We have argued that the brain might plausibly implement a key-value memory system in the division of labor between hippocampus and neocortex. We have also argued that a number of behavioral findings from memory studies (e.g., the ability to report item familiarity without recollection) is consistent with a key-value architecture.

Presently, the connections we have highlighted are speculative. On the empirical side, we hope that more direct experimental tests will be undertaken. For example, the key-value architecture implies that repulsion effects in long-term memory should be reversible—a prediction that has not yet been tested. On the theoretical side, we hope that more biologically detailed models will be

developed which can explain the plethora of findings discussed in previous sections.

Our paper was motivated by the fact that key-value memory seems to be an important ingredient in the success of several modern artificial intelligence systems such as transformers and fast weight programmers. The idea that the brain may implement something like this indicates evidence for convergence 135 and suggests that this is a promising direction for exploring brain-like mechanisms that can power intelligent systems.

# Acknowledgments

The authors are grateful for support from the Kempner Institute for the Study of Natural and Artificial Intelligence, and from the Department of Defense MURI program under ARO grant W911NF-23-1-0277.

# Declaration of interests

The authors declare no competing interests.

# References

[1] Endel Tulving. Cue-dependent forgetting. American Scientist, 62:74–82, 1974.   
[2] Robert G Crowder. Principles of Learning and Memory. Lawrence Erlbaum, 1976.   
[3] Donald J Lewis. Psychobiology of active and inactive memory. Psychological bulletin, 86(5): 1054, 1979.   
[4] Ralph R Miller. Failures of memory and the fate of forgotten memories. Neurobiology of Learning and Memory, 181:107426, 2021.   
[5] Michael Jacob Kahana. Foundations of Human Memory. Oxford University Press, 2012.   
[6] Rishidev Chaudhuri and Ila Fiete. Computational principles of memory. Nature Neuroscience, 19:394–403, 2016.   
[7] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in Neural Information Processing Systems, volume 30, 2017.   
[8] Jürgen Schmidhuber. Learning to control fast-weight memories: An alternative to dynamic recurrent networks. Neural Computation, 4(1):131–139, 1992.   
[9] Alex Graves, Greg Wayne, Malcolm Reynolds, Tim Harley, Ivo Danihelka, Agnieszka Grabska-Barwi ´nska, Sergio Gómez Colmenarejo, Edward Grefenstette, Tiago Ramalho, John Agapiou, et al. Hybrid computing using a neural network with dynamic external memory. Nature, 538:471–476, 2016.   
[10] Samuel J Gershman and Nathaniel D Daw. Reinforcement learning and episodic memory in humans and animals: an integrative framework. Annual Review of Psychology, 68:101–128, 2017.

[11] Mor Geva, Roei Schuster, Jonathan Berant, and Omer Levy. Transformer feed-forward layers are key-value memories. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 5484–5495, 2021.   
[12] Kazuki Irie, Róbert Csordás, and Jürgen Schmidhuber. The dual form of neural networks revisited: Connecting test time predictions to training patterns via spotlights of attention. In International Conference on Machine Learning, pages 9639–9659. PMLR, 2022.   
[13] Zeyuan Allen-Zhu and Yuanzhi Li. Physics of language models: Part 3.1, knowledge storage and extraction. In Forty-first International Conference on Machine Learning, 2024. URL https: //openreview.net/forum?id=5x788rqbcj.   
[14] Teuvo Kohonen. Correlation matrix memories. IEEE transactions on computers, 100:353–359, 1972.   
[15] Ray Pike. Comparison of convolution and matrix distributed memory systems for associative recall and recognition. Psychological Review, 91:281–294, 1984.   
[16] Natalia Caporale and Yang Dan. Spike timing-dependent plasticity: A hebbian learning rule. Annual Review of Neuroscience, 31:25–46, 2008.   
[17] Thomas Limbacher and Robert Legenstein. H-mem: Harnessing synaptic plasticity with hebbian memory networks. Advances in Neural Information Processing Systems, 33:21627– 21637, 2020.   
[18] Karl Steinbuch and Uwe A. W. Piske. Learning matrices and their applications. IEEE Transactions on Electronic Computers, 12(6):846–862, 1963.   
[19] David J Willshaw, O Peter Buneman, and Hugh Christopher Longuet-Higgins. Nonholographic associative memory. Nature, 222(5197):960–962, 1969.   
[20] James A Anderson. Two models for memory organization using interacting traces. Mathematical Biosciences, 8:137–160, 1970.   
[21] S-I Amari. Learning patterns and pattern sequences by self-organizing nets of threshold elements. IEEE Transactions on Computers, 100:1197–1206, 1972.   
[22] Kaoru Nakano. Associatron-a model of associative memory. IEEE Transactions on Systems, Man, and Cybernetics, pages 380–388, 1972.   
[23] John J Hopfield. Neural networks and physical systems with emergent collective computational abilities. Proceedings of the National Academy of Sciences, 79:2554–2558, 1982.   
[24] Jimmy Ba, Geoffrey E Hinton, Volodymyr Mnih, Joel Z Leibo, and Catalin Ionescu. Using fast weights to attend to the recent past. In Advances in Neural Information Processing Systems, pages 4331–4339, Barcelona, Spain, December 2016.   
[25] Angelos Katharopoulos, Apoorv Vyas, Nikolaos Pappas, and François Fleuret. Transformers are RNNs: Fast autoregressive transformers with linear attention. In Proceedings of the 37th International Conference on Machine Learning, volume 119 of Proceedings of Machine Learning Research, pages 5156–5165. PMLR, 2020. URL https://proceedings.mlr.press/v119/ katharopoulos20a.html.

[26] B Schölkopf. Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond. MIT Press, 2002.   
[27] Yao-Hung Hubert Tsai, Shaojie Bai, Makoto Yamada, Louis-Philippe Morency, and Ruslan Salakhutdinov. Transformer dissection: An unified understanding for transformer’s attention via the lens of kernel. In Proceedings of the Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 4344–4353, Hong Kong, China, November 2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1443. URL https://aclanthology.org/ D19-1443.   
[28] Imanol Schlag, Kazuki Irie, and Jürgen Schmidhuber. Linear transformers are secretly fast weight programmers. In Proceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research, pages 9355–9366. PMLR, 2021. URL https://proceedings.mlr.press/v139/schlag21a.html.   
[29] Krzysztof Marcin Choromanski, Valerii Likhosherstov, David Dohan, Xingyou Song, Andreea Gane, Tamas Sarlos, Peter Hawkins, Jared Quincy Davis, Afroz Mohiuddin, Lukasz Kaiser, David Benjamin Belanger, Lucy J Colwell, and Adrian Weller. Rethinking attention with performers. In International Conference on Learning Representations, 2021. URL https://openreview.net/forum?id=Ua6zuk0WRH.   
[30] Hao Peng, Nikolaos Pappas, Dani Yogatama, Roy Schwartz, Noah A Smith, and Lingpeng Kong. Random feature attention. In International Conference on Learning Representations, 2021.   
[31] Beren Millidge, Tommaso Salvatori, Yuhang Song, Thomas Lukasiewicz, and Rafal Bogacz. Universal Hopfield networks: A general framework for single-shot associative memory models. In International Conference on Machine Learning, pages 15561–15583. PMLR, 2022.   
[32] Pentti Kanerva. Sparse Distributed Memory. MIT Press, 1988.   
[33] Dmitry Krotov and John J. Hopfield. Dense associative memory for pattern recognition. In Advances in Neural Information Processing Systems, volume 29, 2016. URL https://proceedings.neurips.cc/paper_files/paper/2016/file/ eaae339c4d89fc102edd9dbdb6a28915-Paper.pdf.   
[34] Hubert Ramsauer, Bernhard Schäfl, Johannes Lehner, Philipp Seidl, Michael Widrich, Lukas Gruber, Markus Holzleitner, Thomas Adler, David Kreil, Michael K Kopp, Günter Klambauer, Johannes Brandstetter, and Sepp Hochreiter. Hopfield networks is all you need. In International Conference on Learning Representations, 2021. URL https://openreview.net/ forum?id=tL89RnzIiCd.   
[35] Trenton Bricken, Xander Davies, Deepak Singh, Dmitry Krotov, and Gabriel Kreiman. Sparse distributed memory is a continual learner. In International Conference on Learning Representations, 2023. URL https://openreview.net/forum?id $\underset { . } { = }$ JknGeelZJpHP.   
[36] Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. End-to-end memory networks. In Advances in Neural Information Processing Systems, volume 28. Curran Associates, Inc., 2015. URL https://proceedings.neurips.cc/paper_files/paper/2015/file/ 8fb21ee7a2207526da55a679f0332de2-Paper.pdf.

[37] Alexander Miller, Adam Fisch, Jesse Dodge, Amir-Hossein Karimi, Antoine Bordes, and Jason Weston. Key-value memory networks for directly reading documents. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1400–1409, 2016.   
[38] Teuvo Kohonen. Content-Addressable Memories. Springer Science & Business Media, 1980.   
[39] Thomas K Landauer. Memory without organization: Properties of a model with random storage and undirected retrieval. Cognitive Psychology, 7:495–531, 1975.   
[40] WK Estes. Statistical theory of spontaneous recovery and regression. Psychological Review, 62:145–154, 1955.   
[41] MA Aizerman, EM Braverman, and LI Rozonoer. Theoretical foundations of the potential function method in pattern recognition learning. Automation and Remote Control, 25:821–837, 1964.   
[42] RT Green. Surprise as a factor in the von Restorff effect. Journal of Experimental Psychology, 52:340–344, 1956.   
[43] Elliot Hirshman, M Margaret Whelley, and Michael Palij. An investigation of paradoxical memory effects. Journal of Memory and Language, 28:594–609, 1989.   
[44] Yasuaki Sakamoto and Bradley C Love. Schematic influences on category learning and recognition memory. Journal of Experimental Psychology: General, 133:534–553, 2004.   
[45] N Rouhani, KA Norman, and Y Niv. Dissociable effects of surprising rewards on learning and memory. Journal of Experimental psychology. Learning, Memory, and Cognition, 44:1430– 1443, 2018.   
[46] Oded Bein, Natalie A Plotkin, and Lila Davachi. Mnemonic prediction errors promote detailed memories. Learning & Memory, 28:422–434, 2021.   
[47] Timothy P Lillicrap, Adam Santoro, Luke Marris, Colin J Akerman, and Geoffrey Hinton. Backpropagation and the brain. Nature Reviews Neuroscience, 21:335–346, 2020.   
[48] Leo Kozachkov, Ksenia V Kastanenka, and Dmitry Krotov. Building transformers from neurons and astrocytes. Proceedings of the National Academy of Sciences, 120:e2219150120, 2023.   
[49] Danil Tyulmankov, Ching Fang, Annapurna Vadaparty, and Guangyu Robert Yang. Biological learning in key-value memory networks. Advances in Neural Information Processing Systems, 34:22247–22258, 2021.   
[50] Katie C Bittner, Aaron D Milstein, Christine Grienberger, Sandro Romani, and Jeffrey C Magee. Behavioral time scale synaptic plasticity underlies ca1 place fields. Science, 357: 1033–1036, 2017.   
[51] James C. R. Whittington, Joseph Warren, and Tim E.J. Behrens. Relating transformers to models and neural representations of the hippocampal formation. In International Conference on Learning Representations, 2022. URL https://openreview.net/forum?id=B8DVo9B1YE0.

[52] James CR Whittington, Timothy H Muller, Shirley Mark, Guifen Chen, Caswell Barry, Neil Burgess, and Timothy EJ Behrens. The Tolman-Eichenbaum machine: unifying space and relational memory through generalization in the hippocampal formation. Cell, 183:1249– 1263, 2020.   
[53] Torkel Hafting, Marianne Fyhn, Sturla Molden, May-Britt Moser, and Edvard I Moser. Microstructure of a spatial map in the entorhinal cortex. Nature, 436:801–806, 2005.   
[54] Xuanqing Liu, Hsiang-Fu Yu, Inderjit Dhillon, and Cho-Jui Hsieh. Learning to encode position for transformer with continuous dynamical model. In International Conference on Machine Learning, pages 6327–6335. PMLR, 2020.   
[55] Sarthak Chandra, Sugandha Sharma, Rishidev Chaudhuri, and Ila Fiete. Episodic and associative memory from spatial scaffolds in the hippocampus. Nature, pages 1–13, 2025.   
[56] Sugandha Sharma, Sarthak Chandra, and Ila Fiete. Content addressable memory without catastrophic forgetting by heteroassociation with a fixed scaffold. In International Conference on Machine Learning, pages 19658–19682. PMLR, 2022.   
[57] KiJung Yoon, Michael A Buice, Caswell Barry, Robin Hayman, Neil Burgess, and Ila R Fiete. Specific evidence of low-dimensional continuous attractor dynamics in grid cells. Nature Neuroscience, 16:1077–1084, 2013.   
[58] Richard J Gardner, Li Lu, Tanja Wernle, May-Britt Moser, and Edvard I Moser. Correlation structure of grid cells is preserved during sleep. Nature Neuroscience, 22:598–608, 2019.   
[59] Sean G Trettel, John B Trimper, Ernie Hwaun, Ila R Fiete, and Laura Lee Colgin. Grid cell coactivity patterns during sleep reflect spatial overlap of grid fields during active behaviors. Nature Neuroscience, 22:609–617, 2019.   
[60] Richard J Gardner, Erik Hermansen, Marius Pachitariu, Yoram Burak, Nils A Baas, Benjamin A Dunn, May-Britt Moser, and Edvard I Moser. Toroidal topology of population activity in grid cells. Nature, 602:123–128, 2022.   
[61] Alexandra O Constantinescu, Jill X O’Reilly, and Timothy EJ Behrens. Organizing conceptual knowledge in humans with a gridlike code. Science, 352:1464–1468, 2016.   
[62] Dmitriy Aronov, Rhino Nevers, and David W Tank. Mapping of a non-spatial dimension by the hippocampal–entorhinal circuit. Nature, 543:719–722, 2017.   
[63] Nathaniel J Killian, Michael J Jutras, and Elizabeth A Buffalo. A map of visual space in the primate entorhinal cortex. Nature, 491:761–764, 2012.   
[64] Daniel J Amit, Hanoch Gutfreund, and H Sompolinsky. Statistical mechanics of neural networks near saturation. Annals of Physics, 173:30–67, 1987.   
[65] Michael McCloskey and Neal J Cohen. Catastrophic interference in connectionist networks: The sequential learning problem. In Psychology of Learning and Motivation, volume 24, pages 109–165. Elsevier, 1989.

[66] Jean M Barnes and Benton J Underwood. “fate”’ of first-list associations in transfer theory. Journal of experimental psychology, 58:97–105, 1959.   
[67] Adityanarayanan Radhakrishnan, Mikhail Belkin, and Caroline Uhler. Overparameterized neural networks implement associative memory. Proceedings of the National Academy of Sciences, 117:27162–27170, 2020.   
[68] Y Dudai. How big is human memory, or on being just useful enough. Learning & Memory, 3:341–365, 1997.   
[69] HP Bahrick, PO Bahrick, and RP Wittlinger. Fifty years of memory for names and faces: A cross-sectional approach. Journal of Experimental Psychology: General, 104:54–75, 1975.   
[70] Harry P Bahrick and Lynda K Hall. Lifetime maintenance of high school mathematics content. Journal of Experimental Psychology: General, 120:20–33, 1991.   
[71] Martin A Conway, Gillian Cohen, and Nicola Stanhope. On the very long-term retention of knowledge acquired through formal education: Twelve years of cognitive psychology. Journal of Experimental Psychology: General, 120:395–409, 1991.   
[72] Ashleigh M Maxcey, Richard M Shiffrin, Denis Cousineau, and Richard C Atkinson. Two case studies of very long-term retention. Psychonomic Bulletin & Review, pages 1–5, 2021.   
[73] Richard M Shiffrin. Forgetting: Trace erosion or retrieval failure? Science, 168:1601–1603, 1970.   
[74] Sam C Berens, Blake A Richards, and Aidan J Horner. Dissociating memory accessibility and precision in forgetting. Nature Human Behaviour, 4:866–877, 2020.   
[75] Nicholas B Diamond, Michael J Armson, and Brian Levine. The truth is out there: Accuracy in recall of verifiable real-world events. Psychological Science, 31:1544–1556, 2020.   
[76] Willem A Wagenaar. My memory: A study of autobiographical memory over six years. Cognitive Psychology, 18:225–252, 1986.   
[77] Herman Buschke. Spontaneous remembering after recall failure. Science, 184:579–581, 1974.   
[78] HL Roediger and LA Thorpe. The role of recall time in producing hypermnesia. Memory & Cognition, 6:296–305, 1978.   
[79] DG Payne. Hypermnesia and reminiscence in recall: a historical and empirical review. Psychological Bulletin, 101:5–27, 1987.   
[80] N Kapur. Syndromes of retrograde amnesia: a conceptual and empirical synthesis. Psychological Bulletin, 125:800–825, 1999.   
[81] Donald J Lewis, James R Misanin, and Ralph R Miller. Recovery of memory following amnesia. Nature, 220(5168):704–705, 1968.   
[82] David C Riccio and Rick Richardson. The status of memory following experimentally induced amnesias: Gone, but not forgotten. Physiological Psychology, 12:59–72, 1984.

[83] LB Flexner, JB Flexner, and RB Roberts. Stages of memory in mice treated with acetoxycycloheximide before or immediately after learning. Proceedings of the National Academy of Sciences, 56:730–735, 1966.   
[84] Roger G Serota. Acetoxycycloheximide and transient amnesia in the rat. Proceedings of the National Academy of Sciences, 68:1249–1250, 1971.   
[85] Larry R Squire and Samuel H Barondes. Variable decay of memory and its recovery in cycloheximide-treated mice. Proceedings of the National Academy of Sciences, 69:1416–1420, 1972.   
[86] PM Bradley and KM Galal. State-dependent recall can be induced by protein synthesis inhibition: behavioural and morphological observations. Developmental Brain Research, 40: 243–251, 1988.   
[87] James F Briggs and Brian P Olson. Reexposure to the amnestic agent alleviates cycloheximide-induced retrograde amnesia for reactivated and extinction memories. Learning & Memory, 20:285–288, 2013.   
[88] Pascale Gisquet-Verrier, Joseph F Lynch, Pasquale Cutolo, Daniel Toledano, Adam Ulmen, Aaron M Jasnow, and David C Riccio. Integration of new information with active memory accounts for retrograde amnesia: a challenge to the consolidation/reconsolidation hypothesis? Journal of Neuroscience, 35:11623–11633, 2015.   
[89] IP Pavlov. Conditioned Reflexes. Oxford University Press, 1927.   
[90] RA Rescorla and CD Heth. Reinstatement of fear to an extinguished conditioned stimulus. Journal of Experimental psychology. Animal Behavior Processes, 1:88–96, 1975.   
[91] JL McClelland, BL McNaughton, and RC O’Reilly. Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory. Psychological Review, 102:419–457, 1995.   
[92] Randall C O’Reilly and Kenneth A Norman. Hippocampal and neocortical contributions to memory: Advances in the complementary learning systems framework. Trends in Cognitive Sciences, 6(12):505–510, 2002.   
[93] Dharshan Kumaran, Demis Hassabis, and James L McClelland. What learning systems do intelligent agents need? complementary learning systems theory updated. Trends in Cognitive Sciences, 20:512–534, 2016.   
[94] Kim S Graham, Karalyn Patterson, and John R Hodges. Episodic memory: new insights from the study of semantic dementia. Current Opinion in Neurobiology, 9:245–250, 1999.   
[95] Bernhard P Staresina, Richard NA Henson, Nikolaus Kriegeskorte, and Arjen Alink. Episodic reinstatement in the medial temporal lobe. Journal of Neuroscience, 32:18150–18156, 2012.   
[96] Sander E Bosch, Janneke FM Jehee, Guillén Fernández, and Christian F Doeller. Reinstatement of associative memories in early visual cortex is signaled by the hippocampus. Journal of Neuroscience, 34:7493–7500, 2014.

[97] Kazumasa Z Tanaka, Aleksandr Pevzner, Anahita B Hamidi, Yuki Nakazawa, Jalina Graham, and Brian J Wiltgen. Cortical representations are reinstated by the hippocampus during memory retrieval. Neuron, 84:347–354, 2014.   
[98] Jared F Danker, Alexa Tompary, and Lila Davachi. Trial-by-trial hippocampal encoding activation predicts the fidelity of cortical reinstatement during subsequent retrieval. Cerebral Cortex, 27:3515–3524, 2017.   
[99] D Pacheco Estefan, Martí Sánchez-Fibla, Armin Duff, Alessandro Principe, Rodrigo Rocamora, Hui Zhang, Nikolai Axmacher, and Paul FMJ Verschure. Coordinated representational reinstatement in the human hippocampus and lateral temporal cortex during episodic memory retrieval. Nature Communications, 10:2255, 2019.   
[100] Melissa Hebscher, James E Kragel, Thorsten Kahnt, and Joel L Voss. Enhanced reinstatement of naturalistic event memories due to hippocampal-network-targeted stimulation. Current Biology, 31:1428–1437, 2021.   
[101] Gordon Winocur, Paul W Frankland, Melanie Sekeres, Stuart Fogel, and Morris Moscovitch. Changes in context-specificity during memory reconsolidation: selective effects of hippocampal lesions. Learning & Memory, 16:722–729, 2009.   
[102] Brian J Wiltgen, Miou Zhou, Ying Cai, J Balaji, Mikael Guzman Karlsson, Sherveen N Parivash, Weidong Li, and Alcino J Silva. The hippocampus plays a selective role in the retrieval of detailed contextual memories. Current Biology, 20:1336–1344, 2010.   
[103] TJ Teyler and P DiScenna. The hippocampal memory indexing theory. Behavioral Neuroscience, 100:147–154, 1986.   
[104] Timothy J Teyler and Jerry W Rudy. The hippocampal indexing theory and episodic memory: updating the index. Hippocampus, 17:1158–1169, 2007.   
[105] Travis D Goode, Kazumasa Z Tanaka, Amar Sahay, and Thomas J McHugh. An integrated index: engrams, place cells, and hippocampal memory. Neuron, 107:805–820, 2020.   
[106] Xu Liu, Steve Ramirez, Petti T Pang, Corey B Puryear, Arvind Govindarajan, Karl Deisseroth, and Susumu Tonegawa. Optogenetic stimulation of a hippocampal engram activates fear memory recall. Nature, 484:381–385, 2012.   
[107] Steve Ramirez, Xu Liu, Pei-Ann Lin, Junghyup Suh, Michele Pignatelli, Roger L Redondo, Tomás J Ryan, and Susumu Tonegawa. Creating a false memory in the hippocampus. Science, 341:387–391, 2013.   
[108] Gisella Vetere, Justin W Kenney, Lina M Tran, Frances Xia, Patrick E Steadman, John Parkinson, Sheena A Josselyn, and Paul W Frankland. Chemogenetic interrogation of a brain-wide fear memory network in mice. Neuron, 94:363–374, 2017.   
[109] Dheeraj S Roy, Young-Gyun Park, Minyoung E Kim, Ying Zhang, Sachie K Ogawa, Nicholas DiNapoli, Xinyi Gu, Jae H Cho, Heejin Choi, Lee Kamentsky, et al. Brain-wide mapping reveals that engrams for a single memory are distributed across multiple brain regions. Nature Communications, 13:1799, 2022.

[110] Francesco P Battaglia, Karim Benchenane, Anton Sirota, Cyriel MA Pennartz, and Sidney I Wiener. The hippocampus: hub of brain network communication for memory. Trends in Cognitive Sciences, 15(7):310–318, 2011.   
[111] Selmaan N Chettih, Emily L Mackevicius, Stephanie Hale, and Dmitriy Aronov. Barcoding of episodic memories in the hippocampus of a food-caching bird. Cell, 187:1922–1935, 2024.   
[112] Avi JH Chanales, Ashima Oza, Serra E Favila, and Brice A Kuhl. Overlap among spatial memories triggers repulsion of hippocampal representations. Current Biology, 27:2307–2317, 2017.   
[113] Guo Wanjia, Serra E Favila, Ghootae Kim, Robert J Molitor, and Brice A Kuhl. Abrupt hippocampal remapping signals resolution of memory interference. Nature Communications, 12:4816, 2021.   
[114] Edmund T Rolls. The mechanisms for pattern completion and pattern separation in the hippocampus. Frontiers in Systems Neuroscience, 7:74, 2013.   
[115] Roger Brown and David McNeill. The “tip of the tongue”’ phenomenon. Journal of Verbal Learning and Verbal Behavior, 5:325–337, 1966.   
[116] AS Brown. A review of the tip-of-the-tongue experience. Psychological Bulletin, 109:204–223, 1991.   
[117] JT Hart. Memory and the feeling-of-knowing experience. Journal of Educational Psychology, 56:208–216, 1965.   
[118] JL Freedman and TK Landauer. Retrieval of long-term memory: “tip-of-the-tongue”’ phenomenon. Psychonomic Science, 4:309–310, 1966.   
[119] Michael M Gruneberg and Joseph Monks. ‘feeling of knowing’ and cued recall. Acta Psychologica, 38:257–265, 1974.   
[120] Lynne M Reder. Strategy selection in question answering. Cognitive Psychology, 19:90–138, 1987.   
[121] Lynne M Reder and Frank E Ritter. What determines initial feeling of knowing? familiarity with question terms, not with the answer. Journal of Experimental Psychology: Learning, Memory, and Cognition, 18:435–451, 1992.   
[122] BL Schwartz and J Metcalfe. Cue familiarity but not target retrievability enhances feelingof-knowing judgments. Journal of Experimental psychology. Learning, Memory, and Cognition, 18:1074–1083, 1992.   
[123] Asher Koriat and Israel Lieblich. A study of memory pointers. Acta Psychologica, 41:151–164, 1977.   
[124] John Morton, Richard H Hammersley, and DA Bekerian. Headed records: A model for memory and its failures. Cognition, 20:1–23, 1985.

[125] Daniel S Ruchkin, Jordan Grafman, Katherine Cameron, and Rita S Berndt. Working memory retention systems: A state of activated long-term memory. Behavioral and Brain sciences, 26:709–728, 2003.   
[126] D Norris. Short-term memory and long-term memory are still different. Psychological Bulletin, 143:992–1009, 2017.   
[127] Felix Ball and Niko A Busch. Change detection on a hunch: Pre-attentive vision allows “sensing”’ of unique feature changes. Attention, Perception, & Psychophysics, 77:2570–2588, 2015.   
[128] George Mandler. Recognizing: The judgment of previous occurrence. Psychological Review, 87:252–271, 1980.   
[129] Tomás J Ryan, Dheeraj S Roy, Michele Pignatelli, Autumn Arons, and Susumu Tonegawa. Engram cells retain memory under retrograde amnesia. Science, 348(6238):1007–1013, 2015.   
[130] Dheeraj S Roy, Shruti Muralidhar, Lillian M Smith, and Susumu Tonegawa. Silent memory engrams as the basis for retrograde amnesia. Proceedings of the National Academy of Sciences, 114(46):E9972–E9979, 2017.   
[131] Yann LeCun, Corinna Cortes, and Christopher JC Burges. The MNIST database of handwritten digits. URL https://ossci-datasets.s3.amazonaws.com/mnist, 1998.   
[132] Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-MNIST: a novel image dataset for benchmarking machine learning algorithms. Preprint arXiv:1708.07747, 2017.   
[133] Roger Ratcliff. Connectionist models of recognition memory: constraints imposed by learning and forgetting functions. Psychological review, 97(2):285, 1990.   
[134] Robert M French. Catastrophic forgetting in connectionist networks. Trends in cognitive sciences, 3(4):128–135, 1999.   
[135] Samuel J Gershman. What have we learned about artificial intelligence from studying the brain? Biological Cybernetics, pages 1–5, 2024.   
[136] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Köpf, Edward Z. Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. PyTorch: An imperative style, high-performance deep learning library. In Advances in Neural Information Processing Systems (NeurIPS), pages 8026–8037, Vancouver, Canada, December 2019.   
[137] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In International Conference on Learning Representations (ICLR), San Diego, CA, USA, May 2015.

# STAR ⋆ METHODS

# KEY RESOURCES TABLE

<table><tr><td>RESOURCE</td><td>SOURCE</td><td>IDENTIFIER</td></tr><tr><td>Data</td><td></td><td></td></tr><tr><td>MNIST</td><td>LeCun et al.131</td><td>https://ossci-datasets.s3.amazon.com/mnist</td></tr><tr><td>Fashion MNIST</td><td>Xiao et al.132</td><td>http://fashion-mnist.s3-website.eu-central-1.amazon.com</td></tr><tr><td>Software</td><td></td><td></td></tr><tr><td>PyTorch 2.5.1</td><td>Paszke et al.136</td><td>https://pytorch.org/</td></tr><tr><td>Code for this paper</td><td>This paper</td><td>https://doi.org/10.5281/zenodo.14920916</td></tr></table>

# RESOURCE AVAILABILITY

Lead contact Further information and requests for resources should be directed to the lead contact, Samuel J. Gershman (gershman@fas.harvard.edu).

Materials availability This study did not generate new materials.

Data and code availability Our code is publicly available online at: https://github.com/ kazuki-irie/kv-memory-brain. This repository contains the code required to reproduce all the simulation results presented in this paper, including Figures 2 and 3.

# METHOD DETAILS

Our code was implemented using PyTorch136.

Distinct representations for keys and values In both the two-class and three-class settings, 100 two-dimensional vectors were uniformly sampled from the range [0, 1] for each key and value within each class, resulting in a total of 200 key/value pairs for the two-class case (Figure 2A) and 300 for the three-class case (Figure 2B).

The optimization was performed using the Adam optimizer 137 with a learning rate of 3e-4 for 5,000 steps in the two-class setting and 10,000 steps in the three-class setting.

The experiments were conducted using the free version of Google Colab with a CPU. The python notebooks to reproduce the results are https://github.com/ kazuki-irie/kv-memory-brain/blob/master/2classes_key_value_optimization.ipynb and https://github.com/kazuki-irie/kv-memory-brain/blob/master/3classes_key_value_ optimization.ipynb for the two-class and three-class cases, respectively.

Forgetting as retrieval failure, and recovery by memory reactivation Both the MNIST and Fashion MNIST datasets were used without modifications. We used the class $' 0 ^ { \prime }$ and $' 1 ^ { \prime }$ images from each dataset; resulting in 12,665 training images for MNIST and 12,000 for Fashion MNIST. Note that MNIST does not have an equal number of examples per class: 5,923 for class $' 0 ^ { \prime }$ and 6,742 for class ‘1.’ We left this imbalance as is, as it is irrelevant to the main goal of our experiment. The corresponding test sets consist of 2,115 and 2,000 images for MNIST and Fashion MNIST, respectively.

The initial weights of the two linear layers within the feedforward neural network were uni-√ formly sampled from a uniform distribution over the range $[ - a , \ a ]$ where $a = 1 / \sqrt { d } \mathrm { i n } ,$ and $d _ { \mathrm { i n } }$ denotes the input dimension of the corresponding layer. No bias was applied in either of the two layers. The optimization was conducted using the standard stochastic gradient descent algorithm using a learning rate of 6e-4 and a batch size of 128 images. We refer to one “epoch” of optimization as a single iteration over the entire training dataset.

The experiments were conducted using the free version of Google Colab with a T4 GPU. The python notebook to reproduce the corresponding results can be found at: https://github.com/ kazuki-irie/kv-memory-brain/blob/master/Forgetting_and_recovery.ipynb.