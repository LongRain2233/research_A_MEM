# MOOM: Maintenance, Organization and Optimization of Memory in Ultra-Long Role-Playing Dialogues

Weishu Chen1, Jinyi Tang2, Zhouhui Hou2, Shihao $\mathbf { H } \mathbf { a n } ^ { 2 }$ , Mingjie Zhan2, Zhiyuan Huang2, Delong Liu1, Jiawei Guo 2, Zhicheng Zhao1,3, Fei $\mathbf { S u 1 } ^ { 3 }$ ,

1Beijing University of Posts and Telecommunications, 2SenseTime,

3Beijing Key Laboratory of Network System and Network Culture,

chenweishu@bupt.edu.cn

# Abstract

Memory extraction is crucial for maintaining coherent ultra-long dialogues in humanrobot role-playing scenarios. However, existing methods often exhibit uncontrolled memory growth. To address this, we propose MOOM, the first dual-branch memory plugin that leverages literary theory by modeling plot development and character portrayal as core storytelling elements. Specifically, one branch summarizes plot conflicts across multiple time scales, while the other extracts the user’s character profile. MOOM further integrates a forgetting mechanism, inspired by the “competition-inhibition” memory theory, to constrain memory capacity and mitigate uncontrolled growth. Furthermore, we present ZH-4O, a Chinese ultra-long dialogue dataset specifically designed for role-playing, featuring dialogues that average 600 turns and include manually annotated memory information. Experimental results demonstrate that MOOM outperforms all state-of-the-art memory extraction methods, requiring fewer large language model invocations while maintaining a controllable memory capacity. Code is available at here.

# 1 Introduction

Large language models (LLMs) (Bai et al., 2023; Achiam et al., 2023; Lu et al., 2024) are no longer simply regarded as practical assistants, but have been increasingly sought for obtaining emotional support. For example, users reshape the LLMs into their favorite idol, ideal companion, gaming partner, or confidant for personal concerns. This practice of assigning specific personas or characters to a language model is commonly referred to as role-playing (Chen et al., 2024b), where both the language model and the users actively play their respective roles, including but not limited to themselves, fictional characters, or entirely new protagonists. However, when these narratives become

excessively long, due to limited context windows or inherent issues such as hallucinations (Xu et al., 2024), current LLMs often overlook historical information provided by users or confuse critical details, potentially degrading the user experience.

In this paper, we view role-playing dialogues with LLMs as “stories” co-created by users with the assistance of LLMs. Traditional literary theory (Forster, 1927) identifies the plot and characters as the core elements of a story. Inspired by this, we propose the MOOM plugin to extract key information from role-playing dialogues, enabling dialogue models to access and align with the plot and character context, thereby generating responses that conform to the narrative and user-defined roles. MOOM consists of two branches: one branch summarizes the progression of the plot across varying temporal scales, while the other uses predefined keywords to construct and update character profiles. Additionally, to prevent unrestricted memory growth in ultra-long dialogues, we design a forgetting algorithm based on the “competitioninhibition” theory (Anderson, 2003), which mimics human memory by prioritizing relevant information through temporal decay and retrieval reinforcement while suppressing outdated or noisy data. This allows MOOM to maintain flexible memory capacity while preserving a diverse range of memory information.

To evaluate the effectiveness of the MOOM plugin, we establish a new Chinese ROle-Playing LOng DialOgue MemOry Dataset named ZH-4O. First, we collect role-playing dialogues between annotators and LLMs. Subsequently, a group of independent annotators annotate key information and its corresponding positions within these dialogues. Finally, a total of 28 dialogues with memory annotations are obtained, each of which has an average length of 600 turns. Additionally, to assess the impact of memory information generated by different memory frameworks on the LLM responses, we

design multiple sets of probing questions, aiming to comprehensively cover various types of roleplaying information.

Our main contributions can be summarized as follows:

(1) We propose MOOM, a novel memory extraction framework that models two core story elements: “plot development” and “character portrayal”. To the best of our knowledge, this is the first long-memory extraction method designed around “story elements”.   
(2) We introduce a forgetting algorithm to constrain memory capacity and mitigate uncontrolled memory expansion.   
(3) We construct ZH-4O, a new dataset comprising authentic, ultra-long human-LLM dialogues in role-playing scenarios, along with manually annotated memory information, serving as a benchmark for evaluating memory extraction methods.   
(4) Experiments demonstrate that, compared with state-of-the-art methods, MOOM achieves higher memory extraction accuracy and enables LLMs to generate more efficient and contextually coherent responses.

# 2 Related Work

# 2.1 Long-term Memory Extraction in Conversations

Due to the inefficiency of using the entire dialogue history as long-term memory, several techniques have been developed to extract and organize key information from past interactions. MemoChat divides conversations into distinct topics and generates concise summaries for each sub-dialogue to construct memory (Lu et al., 2023). COMEDY employs a fine-tuned model to compress memory into three categories: user profiles, relationship descriptions, and event records (Chen et al., 2024a). LTM employs a personality extractor to classify users into predefined personality categories (Xu et al., 2022). Regarding memory updating, (Bae et al., 2022) represents memory as unstructured text descriptions and utilizes a fine-tuned T5-based classification model to iteratively compare and update old and new memory entries. Similarly, the opensource framework Mem01 employs a graph-based

representation of memory and relies on LLMs to determine update operations for each memory entry. Unlike these approaches, which primarily rely on semantic similarity or topic segmentation, MOOM integrates literary theory to model narrative and persona, offering a more structured and contextually relevant memory framework.

# 2.2 Forgetting in Long-term Memory Management

Managing long-term memory in conversations involves strategies to control memory capacity and update or discard information over time to maintain efficiency. MemoryBank incorporates the Ebbinghaus Forgetting Curve to model memory decay over time (Zhong et al., 2024). MemoCRS utilizes a First-In-First-Out (FIFO) strategy to control memory capacity (Xi et al., 2024). In general, most memory extraction methods rely on semantic similarity comparisons between historical and new memory entries during the update process to decide whether to retain or discard specific information (Qian et al., 2024; Schuurmans, 2023; Bae et al., 2022). However, existing methods still struggle with uncontrolled memory growth in ultra-long dialogues. In contrast, we propose a competitioninhibition-based forgetting algorithm to mitigate uncontrolled memory expansion and improve memory efficiency.

# 2.3 Dialogue Dataset

Numerous efforts have been made to construct dialogue datasets (Shao et al., 2023; Li et al., 2023; Wang et al., 2024). For instance, some datasets, such as those in (Xu et al., 2022; Zhou et al., 2023; Tu et al., 2024), consist of humanannotated dialogues but are limited by their relatively short lengths, averaging fewer than 20 turns. In contrast, datasets like LoCoMo, which average 300 turns (Maharana et al., 2024), are primarily machine-generated, with human intervention restricted to correcting logical errors. As a result, these machine-generated datasets do not fully capture the dynamics of human-machine conversations. Consequently, despite the variety of datasets available for conversational large language models, there remains a scarcity of datasets specifically designed for ultra-long dialogues with reliable memory annotations. To address these limitations, we introduce ZH-4O, an ultra-long dialogue dataset comprising real human-computer interactions, with an average of 600 turns per dialogue and manually

![](images/0d27f62a5affd66aaf6eb8f3cd43f9167fb2dda92ed519fa8171db57c194d5d5.jpg)

![](images/c51ad88d16b3b7da3467ecdaf6b794db5979cb03d360bf7c23a53eca6bd01225.jpg)

![](images/95275d63a388aa7195e10a73cd707044a6218df40749e285e4dcab57366bb3af.jpg)  
Figure 1: Overview of the MOOM framework.

annotated memory information.

# 3 Methodology

The task of memory extraction can be defined as follows: A dialogue dataset $D ( d _ { 1 } , d _ { 2 } , . . . , d _ { t } )$ consists of a series of prior dialogue sessions between a chatbot and a user. At a given time step $t$ , the dialogue context is represented as ${ d _ { t } } = \{ c _ { t } , u _ { t } \}$ , where $c$ and $u$ denote the chatbot’s and the user’s responses, respectively. The objective of the memory extraction task is to leverage a model to extract memories $M = \{ m _ { 1 } , m _ { 2 } , . . . , m _ { t - 1 } \}$ from $D$ that are related to the user. Hence, an effective memory extraction framework is expected to exhibit the following characteristics: (1) content completeness, (2) low latency, and (3) controllable capacity.

The classic literary theory posits that the essence of a story lies in its narrative and characters (Forster, 1927), which is compatible with roleplaying scenarios. Therefore, we regard humancomputer dialogues as stories co-created by users and chatbot first, and then propose our memory framework that comprises two branches: the first Narrative Summarization Branch (NSB) summarizes storyline conflicts across multi-dimensional time scales, while the second Persona Construction Branch (PCB) captures user personas to deliver a personalized experience. Finally, to address the issue of unbounded memory growth in ultralong dialogues, we introduce a forgetting algorithm based on the “competition-inhibition” memory theory (Lindsay and Norman, 2013a; Anderson et al., 1994) to constrain memory quantity.

# 3.1 Narrative Summarization Branch(NSB)

![](images/348f2d7d1655fe838e1e1c63743bd8e59ecc6e348021ce7971e75fa229df53db.jpg)  
Figure 2: Illustration of the hierarchical summarization process in the Narrative Summarization Branch. The input dialogue $I ^ { ( 1 ) }$ is first condensed into $S ^ { ( 2 ) }$ , capturing key events, and then further refined into $S ^ { ( 3 ) }$ , which extracts the core narrative elements and focuses on highlevel story progression.

In lengthy dialogues within a role-playing scenario, the narrative unfolded through a sequence of conflicts, resolutions, and turning points, which collectively define the storyline. Building on this observation, the NSB is designed to extracts key plots by capturing critical moments across multiple temporal scales. Moreover, To handle ultra-long dialogues, we implement a hierarchical summarization algorithm that structures and compresses information flow while preserving pivotal narrative elements.

Specifically, for each dialogue turn, we initially store it as raw information flow, capturing the micro-level plot development. When the cumulative dialogue turns reach the threshold $\theta _ { 1 }$ for firstlevel packaging, they will be aggregated into a firstlevel information unit (1) $I _ { j } ^ { ( 1 ) }$ , which can be expressed

as:

$$
I _ {j} ^ {(1)} = \left\{d _ {(j - 1) \theta_ {1} + 1}, d _ {(j - 1) \theta_ {1} + 2},..., d _ {j \theta_ {1}} \right\}, j \in \mathbb {N} _ {+} (1)
$$

The primary units encapsulate the original dialogue into structured segments. The segments are then iteratively summarized. Whenever the number of segments at a given level reaches the packaging threshold $\theta _ { m }$ , they are forwarded to the LLM for integration and summarization, resulting in a more abstract summary:

$$
S _ {l} ^ {(m + 1)} = \mathrm {L L M} (\{S _ {(l - 1) \theta_ {m} + 1} ^ {(m)},..., S _ {l \theta_ {m}} ^ {(m)} \}), l \in \mathbb {N} _ {+} (2)
$$

In this work, the original packaged dialogue undergoes two iterative summarization stages, as illustrated in Fig. 2. In our implementation, the threshold $\theta _ { 1 }$ is empirically set to 6, while both $\theta _ { 2 }$ and $\theta _ { 3 }$ are set to 5.

This multi-level compression and abstraction process distills the dialogue into a high-density structured storyline, efficiently reducing the dependency on extended contexts while preserving the storylines’ critical elements.

# 3.2 Persona Construction Branch(PCB)

The PCB focuses on efficiently constructing and dynamically updating user personas via combining the strengths of LLMs and lightweight models. Firstly, we leverage large-scale data to extract abstract persona keys, such as “Name”, “Preferences”, and “Profession”, which serve as the foundation for user characterization (details are provided in the Appendix B). Then, the LLM extracts corresponding persona values for these keys at specific intervals of dialogue turns, thereby generating a persona snapshot.

After a new persona snapshot is generated, it will be integrated with the existing persona sketch through a fusion mechanism tailored to the properties of each key. Given that leveraging LLMs for fusion is time-consuming, we reduce reliance on LLMs by introducing three distinct merging strategies, which prioritize efficiency while maintaining high-quality integration:

(1) Rule-based Merging: For keys with clear update rules, such as those with replaceable or appendable values, we either append new values from the persona snapshot to the corresponding existing values or overwrite old values with new ones.

(2) Embedding-based Merging: For keys prone to contradictions, such as “Favorite Animals” and “Disliked Animals”, we compute the BGE score(Xiao et al., 2024b) between conflicting values. Those outdated values with high similarity will be deleted   
(3) LLM-based Merging: For keys that cannot be efficiently handled by rules or embeddings, we delegate the merging scheme to the LL, and it will assess and integrates the new and old information.

In implementation, the majority of keys rely on rule-based merging, while embedding-based and LLM-based strategies are reserved for more complex cases. Therefore, this design balances the speed and resource efficiency of the persona updating process.

By dynamically capturing and integrating key persona elements, the PCB complements the NSB, thus collectively addressing the dual focus on “plot” and “characters” in memory extraction.

To accommodate diverse practical deployment needs—such as performance, latency, and memory consumption—our PCB framework is designed to be highly flexible in its choice of language models. It seamlessly supports both general-purpose LLMs and specialized, fine-tuned models, depending on the specific application scenario. As an illustrative example, we demonstrate the use of ChatGPT-4 (Achiam et al., 2023) to distill the Qwen2-7B model (Yang et al., 2024), resulting in an optimized model for persona snapshot extraction (details provided in Appendix C). This example highlights the framework’s adaptability, allowing users to leverage either proprietary or open-source LLMs, with or without fine-tuning, based on different requirements.

# 3.3 Forgetting Mechanism

Cognitive science explains forgetting via two main theories: interference (memory traces compete) and inhibitory control (active suppression of irrelevant memories) (Lindsay and Norman, 2013b; Mensink and Raaijmakers, 1988). Competitioninhibition mimics human memory by prioritizing relevant information and suppressing outdated or noisy data. For instance, when someone updates their phone number, repeated retrieval of the new number gradually suppresses recall of the old one, leading to its eventual forgetting.

Inspired by this, we model forgetting as a priority-based reallocation, combining temporal decay with inhibitory suppression. When a memory $c$ triggers retrieval from memory pool $M$ , we divide memories into: $\mathbb { R } _ { c }$ : relevant and effective memories, $\mathbb { N } _ { c }$ : interfering (noisy) memories and $\mathbb { U } _ { c }$ : unactivated memories.

The mechanism operates from two aspects:

Score Computation. We first define a round $r$ as a pair of consecutive turns in a dialogue, consisting of an utterance and its direct response. Then for every new round, each memory’s importance score $S$ is calculated using

$$
S = \alpha \frac {1}{\exp (\gamma \left(r _ {c} - b\right)) + (1 - \epsilon)} + \beta \sum_ {r \in R _ {c}} \frac {1}{r _ {c} - r + \epsilon}, \tag {3}
$$

where $r _ { c }$ is the current round, $b$ the creation round. $R _ { c }$ is the set of rounds in which the memory is retrieved. $\epsilon$ is a very small value to ensure that the denominator is not 0. $\alpha$ weighs the first term temporal decay, reducing the importance of older memories, while $\beta$ weighs the second term models retrieval reinforcement, boosting recently retrieved memories.

Retrieval Reinforcement and Suppression. After calculating all memories scores $S$ , we retrieve top $2 k$ memories in memory pool. Among them the top $k$ memories are regarded as relevant memories $( \mathbb { R } _ { c } )$ . We record the current round $r _ { c }$ into the $R _ { c }$ of these memories so that they can be enhanced during the subsequent calculation of $S$ . On the other hand, the next $k$ ones (i.e. $\mathbb { N } _ { c } .$ ) will be suppressed by halving their scores $S$ , while the unactivated memories (i.e. $\mathbb { U } _ { c }$ ) remain unchanged. After this step, only memories with higher scores are retained.

This mechanism efficiently prioritizes memory in dialogue systems, preserving relevant content while reducing interference. In practice, we use BGE reranker (Xiao et al., 2024b) as our retriever. The parameters $\alpha = 0 . 1$ , $\beta = 0 . 9$ weigh temporal decay and retrieval reinforcement, respectively. In addition, $k$ is set to 9, which are detailed in Appendix D.

# 4 ZH-4O dataset

As mentioned earlier, ultra-long conversations play a decisive role in role-playing, but the corresponding datasets are rather scarce. To make up for the deficiency, we construct the ZH-4O dataset, with an average conversation length of 600 turns—significantly exceeding that of existing

datasets. Aiming to emulate realistic role-playing scenarios, ZH-4O minimizes restrictions on participants, enabling dialogue annotators and memory labelers to freely exert their creativity and judgment. It is composed of three components: dialogue collection, memory annotation and probe table.

# 4.1 Dialogue Collection

To construct the ZH-4O dataset, we designed diverse chatbot personas to enhance dialogue variety and generalization. Annotators are briefed on: (1) the chatbot’s persona; (2) adherence to ethics and laws, prohibiting inappropriate content. Each annotator pair completed dialogues of at least 500 turns, with content and style left to their creativity for natural, diverse conversations. Notably, as the dataset is constructed in Chinese, the dialogues reflect distinctive characteristics of the Chinese cultural context. Annotators incorporated culturally specific references, such as Chinese cuisine (e.g., Sichuan cuisine and hotpot) and Chinese celebrities, embedding authentic elements of the Chinesespeaking environment into the conversations. As a result, we collect 28 dialogue sessions, with each session averaging 600 turns in length.

# 4.2 Memory Annotation

After collecting the long dialogues, we assign them to another group of annotators for manual annotation. The annotators are tasked with extracting notable information from the dialogues and indicating the specific turn in which the information appeared. To ensure consistency while minimizing potential bias, we establish a unified workflow for identifying notable information, while allowing flexibility in the specific content and format of the annotations based on annotators’ individual judgments. Ultimately, we obtain 1,115 memory annotations. More details on the workflow of annotation are presented in Appendix A.

# 4.3 Memory Probing

To systematically evaluate memory extraction frameworks, we design a probing task within the ZH-4O dataset. Specifically, annotators are instructed to review dialogue contexts and formulate 1068 multiple-choice questions from the robot’s perspective, each targeting a distinct memory point. Each question is associated with four candidate user responses, among which only one accurately reflects the correct memory information, with the remaining three acting as distractors. This

Table 1: Memory extraction accuracy evaluation of Mem0, MemoChat, MemoryBank and our method MOOM. 14B denotes the use of Qwen1.5-14B as the LLM within the framework, while 32B and 72B refer to Qwen2.5-32B and Qwen2.5-72B, respectively. The MOOM-7B finetuned framework employs a fine-tuned Qwen2-7B model specifically for user character profiling, whereas plot summarization is still conducted using the non-fine-tuned Qwen1.5-14B. The MemScore, evaluated using Qwen2.5-72B, quantifies the similarity between the extracted memory and the corresponding labels, with a maximum score of 5 and a minimum score of 0. All metrics presented in the table follow the principle that higher values indicate better performance.Bold indicates the best performance. Underline indicates the second best.   

<table><tr><td>Method</td><td>BERTScore</td><td>M3E</td><td>ROUGE-2</td><td>ROUGE-L</td><td>MemScore</td><td>QA precision</td></tr><tr><td>Mem0-14B</td><td>0.6955</td><td>0.8612</td><td>0.1542</td><td>0.4056</td><td>0.411</td><td>0.459</td></tr><tr><td>Mem0-32B</td><td>0.7055</td><td>0.8672</td><td>0.1724</td><td>0.4145</td><td>0.504</td><td>0.509</td></tr><tr><td>Mem0-72B</td><td>0.7108</td><td>0.8717</td><td>0.1851</td><td>0.4288</td><td>0.519</td><td>0.612</td></tr><tr><td>MemoChat-14B</td><td>0.7728</td><td>0.8940</td><td>0.1973</td><td>0.3462</td><td>2.515</td><td>0.511</td></tr><tr><td>MemoChat-32B</td><td>0.7786</td><td>0.8884</td><td>0.2040</td><td>0.3424</td><td>2.535</td><td>0.718</td></tr><tr><td>MemoChat-72B</td><td>0.7788</td><td>0.8897</td><td>0.2033</td><td>0.3404</td><td>2.303</td><td>0.693</td></tr><tr><td>MemoryBank-14B</td><td>0.7474</td><td>0.8301</td><td>0.0292</td><td>0.0683</td><td>1.589</td><td>0.513</td></tr><tr><td>MemoryBank-32B</td><td>0.7591</td><td>0.8419</td><td>0.0396</td><td>0.0830</td><td>1.732</td><td>0.651</td></tr><tr><td>MemoryBank-72B</td><td>0.7592</td><td>0.8374</td><td>0.0403</td><td>0.0839</td><td>1.780</td><td>0.692</td></tr><tr><td>MOOM-7B finetuned</td><td>0.8018</td><td>0.9017</td><td>0.2806</td><td>0.4834</td><td>3.170</td><td>0.832</td></tr><tr><td>MOOM-14B</td><td>0.7525</td><td>0.8912</td><td>0.2816</td><td>0.4832</td><td>2.590</td><td>0.827</td></tr><tr><td>MOOM-32B</td><td>0.7795</td><td>0.8931</td><td>0.2914</td><td>0.4971</td><td>2.784</td><td>0.813</td></tr><tr><td>MOOM-72B</td><td>0.8071</td><td>0.9149</td><td>0.3341</td><td>0.5153</td><td>3.317</td><td>0.840</td></tr></table>

structured probing approach enables us to rigorously assess the effectiveness of different memory frameworks in supporting accurate role-playing dialogues.

In addition, the ZH-4O dataset includes a Probe Table, a concise evaluation tool designed to adapt to most role-playing scenarios. For more details, please refer to the Appendix H.

# 5 Experiments

In this section, we outline the experimental setup, including experiments settings, metrics, and a comprehensive analysis of the experimental results.

# 5.1 Experiments Settings

To enhance the comparison with our proposed method, we evaluate three representative approaches: Mem0, MemoChat (Lu et al., 2023), and MemoryBank (Zhong et al., 2024). Mem0 is an open-source memory extraction plugin designed for general-purpose scenarios. MemoChat facilitates consistent performance in LLMs during extended, open-domain conversations. Memory-Bank is tailored for human-computer interactions in roleplay settings. We translate the prompts of Mem0 and MemoChat, which lack native Chinese support, into Chinese to ensure a fair and consistent evaluation.

In the memory extraction experiments, both our proposed MOOM framework and the base-

line methods rely on LLMs for memory extraction. To investigate the performance of different frameworks across LLMs with varying parameter scales, we utilize Qwen1.5-14B (Bai et al., 2023), Qwen2.5-32B (Yang et al., 2024), and Qwen2.5- 72B as the primary LLMs in our experiments. Additionally, as discussed earlier, we fine-tune the Qwen2-7B model based on results from GPT-4, making it a specialized model for character profile extraction within the MOOM framework. All experiments are repeated three times and the average results are reported. The experiments were conducted on a eight NVIDIA H800 GPUs to accommodate the computational requirements of a 72B parameter model. For experiments involving models with smaller parameter sizes, such as 7B, execution was typically performed on a single NVIDIA H800 GPU.

# 5.2 Metrics

To evaluate memory extraction accuracy, let $M$ be the set of extracted memories, $L$ the humanannotated memory labels, and $U$ all dialogue information. As $L$ reflects human preferences, we prioritize a scoring function $f ( l , M )$ to measure how well $M$ aligns with $L$ , over $g ( m , L )$ , which focuses on the relevance of memories $m$ to labels, better capturing human-centric priorities.

We employ multiple evaluation metrics to quantify the accuracy of memory extraction, including BERTScore (Zhang et al., 2020) precision,

![](images/09b69b85a20fb8529f60a0eaf1f0769890849b16f3da197684fb339b78223bf7.jpg)

![](images/d4492bca2903d9201069587ffc078ea0279e30b96f2134d76f0463eba3eaccc1.jpg)  
Figure 3: Results of our forget mechanism experiments. Ebbinghause curve, without inhibition strategy method and ours’ competition-inhibition method (w/ inhibition) are in the finetuned MOOM-7B framework. Other methods use Qwen2.5-72B.

M3E (Wang Yuxin, 2023) embedding similarity, and ROUGE (Lin, 2004) precision. For each label $l \in L$ , we calculate its similarity score with all memories in $M$ using these metrics and select the highest similarity score as the score for that label. Finally, we average the scores $f$ of all labels to obtain the final score for the framework.

To evaluate memory extraction fidelity, we introduce MemScore, a metric based on large language model (LLM) assessments. For each memory $m \in M$ , we compute its BERTScore similarity with reference labels $L$ , selecting the highestscoring label as the best match. An LLM then scores (0–5) how well $m$ captures the label’s semantic intent, retaining the highest score for repeated labels. Unmatched labels receive a score of 0 to penalize incomplete recall, ensuring scalable and robust evaluation.

Besides, we employ probe questions from the ZH-4O dataset. After providing the extracted information, we prompt the model to determine the optimal choice for each probe question. The model’s selections are then compared against the labeled ground-truth answers to calculate the precision metric. This precision score serves as an indicator for assessing the performance of memory plugins.

# 5.3 Memory Extraction Accuracy Evaluation

The results in Table 1 demonstrate that the MOOM framework consistently exhibits superior memory extraction accuracy under different model capacities. Notably, with the fine-tuned 7B model, MOOM achieves significantly higher scores compared with other frameworks, and also obtains a relatively high LLM score (3.170). This indicates that adopting a task-specific fine-tuned model within

the MOOM framework effectively enhances the extraction of critical memory information.

For larger models (e.g., 32B), MOOM significantly boosts LLM scores (2.784) and outperforms in ROUGE-L and M3E, demonstrating its robustness across scales. This is due to its detailed keyvalue summaries, which enhance large models’ summarization capabilities. Even with an untuned small model (14B), MOOM achieves comparable or superior performance to frameworks using much larger models (72B), highlighting its effectiveness in memory extraction.

In terms of time efficiency, a H800 GPU process 20 rounds of dialogue requires approximately 8 seconds for 7B model. When utilizing the same LLM, the time consumption ratio of MOOM compared with Mem0, MemoChat, and MemoryBank is approximately 1:2.5:3:1.5, respectively. This demonstrates that MOOM not only maintains high accuracy but also significantly reduces memory extraction latency.

MOOM also outperforms baselines on the English LoCoMo dataset, demonstrating its applicability beyond Chinese dialogues. The detailed results can be found in the Appendix G.

# 5.4 Forget Mechanism Evaluation

In Fig. 3, it can be observed that within the MOOM framework, both the Ebbinghaus forgetting strategy and the proposed competition-inhibition strategy outperform other methods under comparable memory capacities. For example, in terms of BERTScore, MOOM surpasses MemoryBank at a memory size of $3 \mathrm { k }$ and outperforms Mem0 at 6k. Notably, our competition-inhibition forgetting algorithm consistently achieves better performance than the Ebbinghaus strategy. More results are presented in Appendix E.

These results demonstrate that the proposed competition-inhibition forgetting algorithm enables flexible adjustment of the memory capacity within the MOOM framework. Compared to other forgetting strategies, our method attains a more efficient balance between memory retention and forgetting. This makes it a superior solution for memory management in ultra-long dialogue scenarios, ensuring both adaptability and effectiveness.

# 5.5 Comparison with Long Context Methods

To assess the efficacy of memory retrieval in enhancing dialogue model performance, we compare our proposed MOOM with InfLLM (Xiao et al.,

Table 2: Results of the ablation study for the MOOM framework.   

<table><tr><td></td><td>BERTScore</td><td>M3E</td><td>ROUGE-2</td><td>ROUGE-L</td><td>MemScore</td><td>QA precision</td></tr><tr><td>NSB Only</td><td>0.7729</td><td>0.8569</td><td>0.0535</td><td>0.1058</td><td>2.603</td><td>0.693</td></tr><tr><td>PCB Only</td><td>0.7898</td><td>0.9021</td><td>0.2376</td><td>0.4224</td><td>2.468</td><td>0.752</td></tr><tr><td>MOOM</td><td>0.8018</td><td>0.9017</td><td>0.2806</td><td>0.4834</td><td>3.170</td><td>0.832</td></tr></table>

Table 3: Probe-based QA evaluation: All the model use Qwen1.5-14B as base model. The context window of vanilla Qwen1.5, InfLLM, RAPTOR, HippoRAG2 and MOOM are set to 8k, 2k and 1k. The context window of vanilla Qwen2.5-1M is no limited.   

<table><tr><td></td><td>vanilla</td><td>InfLLM</td><td>RAPTOR</td><td>HippoRAG2</td><td>MOOM</td></tr><tr><td>Qwen1.5-7B</td><td>0.607</td><td>0.570</td><td>0.626</td><td>0.730</td><td>0.793</td></tr><tr><td>Qwen1.5-14B</td><td>0.687</td><td>0.635</td><td>0.717</td><td>0.763</td><td>0.827</td></tr><tr><td>Qwen2.5-1M-7B</td><td>0.781</td><td>0.673</td><td>0.722</td><td>0.759</td><td>0.831</td></tr><tr><td>Qwen2.5-1M-14B</td><td>0.852</td><td>0.703</td><td>0.740</td><td>0.792</td><td>0.836</td></tr></table>

2024a), a long-context model employing slidingwindow attention and context memory modules, and the vanilla Qwen model. The vanilla Qwen model concatenates dialogues and questions into a single prompt, as does InfLLM within its framework. In contrast, MOOM integrates only the recalled memory with the questions, excluding the original dialogues. Specifically, MOOM’s context window incorporates nine retrieved memory contents.

As presented in Table 3, MOOM achieves superior performance compared to both InfLLM and vanilla Qwen, despite utilizing significantly shorter context window. For instance, the vanilla Qwen1.5- 7B model, with an 8k context window, requires approximately 32GB of GPU memory. InfLLM lowers the GPU memory demand to around 16GB. MOOM, accounting for the memory required during retrieval, also operates efficiently with approximately 16GB memory. This demonstrates that MOOM is well suited for resource-constrained environments with limited GPU capacity.

For further comparison, we evaluate MOOM against newer models designed for ultra-long contexts, such as Qwen2.5-7B-1M and Qwen2.5-14B-1M, which support unrestricted context windows (e.g., up to $3 2 \mathrm { k }$ tokens for the longest dialogues in ZH-4O). These models achieve QA probing scores of 0.781 and 0.852, respectively. Despite the extended context capabilities of these models, MOOM remains highly competitive. Notably, in practical applications, MOOM’s memory retrieval framework can operate in parallel with the dialogue model, significantly reducing memory overhead. In contrast, directly processing entire dialogues with ultra-long-context models demands

substantial GPU memory, making MOOM a more resource-efficient solution for open-domain dialogue systems.

# 5.6 Ablation study

To validate the effectiveness of MOOM’s dualbranch design, we conduct ablation experiments by isolating the two branches: NSB and PCB. The results are summarized in Table 2.

The complete MOOM framework, integrating both branches, achieves the highest performance across all metrics. When evaluating the branches independently, distinct strengths become evident. The narrative summarization-only branch demonstrates superior performance in MemScore (2.603), outperforming the persona-only branch (2.468). This advantage suggests that NSB effectively captures interconnected memory points reflective of coherent plot narratives, closely aligning with memory structures evaluated by MemScore.

Conversely, the persona-only branch exhibits stronger performance in QA precision (0.752), surpassing the narrative-only branch (0.693). This result likely arises because PCB separately encodes individual informational elements from dialogues, which better aligns with the probe-style evaluation employed by QA precision.

These results highlight the complementary strengths of the NSB and PCB branches within MOOM. More ablation studies are represented in Appendix F.

# 6 Conclusion

In this paper, we propose MOOM, a dual-branch memory extraction framework for role-playing in ultra-long dialogues. To mitigate uncontrolled memory growth, we propose a forgetting mechanism based on “competition-inhibition” theory. Additionally, we present ZH-4O, a Chinese ultralong dialogue dataset with high-quality annotated memory. Experimental results show that MOOM exceeds the SOTA methods in accuracy, efficiency, and memory control.

# 7 Limitations

Annotation Diversity. One limitation of our study lies in the diversity of the annotation team. Our annotation team consists of 10 members, 6 females and 4 males. Since the ZH-4O dataset is in Chinese, all annotators are Chinese. In addition, all annotators received a high level of education, which may not fully represent the general population. Although ZH-4O is designed to include various types of intimate relationships, privacy information such as personal backgrounds do not be collected. This lack of demographic diversity may introduce bias, potentially limiting the dataset’s generalizability to real-world scenarios.

Language. Our research primarily focuses on the Chinese. While the proposed MOOM framework demonstrates strong performance on both Chinese (ZH-4O) and English (LoCoMo) datasets, our ZH-4O dataset is exclusively in Chinese, which limits its linguistic diversity. In future work, we plan to expand the ZH-4O dataset to include more languages, enhancing its applicability to multilingual dialogue scenarios.

Practical Applications. Through fine-tuning, our approach enables a 7B-parameter model to outperform larger models in other frameworks, and the overall architecture supports asynchronous invocation. However, we finetune the 7B-parameter model based on GPT-4 output data only, potentially introducing biases specific to GPT-4’s outputs. Consequently, it is essential for practitioners employing our framework to acknowledge this limitation. When adapting smaller-scale models, careful consideration should be given to dataset construction. Depending on the application’s requirements and desired outcomes, practitioners may select alternative data sources beyond GPT-4’s generated outputs, such as utilizing large-scale open-source models or manually curated datasets. Diversifying training data sources in this manner can mitigate the risk of embedding specific biases inherent to any single model or data generation method.

Dialogue and Role-Playing. The use of human-AI dialogue is a prevalent approach for leveraging LLMs in role-playing scenarios, but it represents only one of many possible modalities. The ZH-4O dataset, as constructed, is limited to text-based, two-party human-AI dialogues, which restricts its scope. It is possible to consider integrating multimodal elements, such as images or audio, or sup-

port multi-party role-playing scenarios involving multiple characters.

In future work, we aim to address these constraints by exploring more flexible and diverse roleplaying frameworks, incorporating multimodal inputs and multi-agent interactions to enhance the immersive quality and applicability of the ZH-4O dataset.

# References

Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774.   
Michael C Anderson. 2003. Rethinking interference theory: Executive control and the mechanisms of forgetting. Journal of memory and language, 49(4):415– 445.   
Michael C Anderson, Robert A Bjork, and Elizabeth L Bjork. 1994. Remembering can cause forgetting: retrieval dynamics in long-term memory. Journal of Experimental Psychology: Learning, Memory, and Cognition, 20(5):1063.   
Sanghwan Bae, Donghyun Kwak, Soyoung Kang, Min Young Lee, Sungdong Kim, Yuin Jeong, Hyeri Kim, Sang-Woo Lee, Woomyoung Park, and Nako Sung. 2022. Keep me updated! memory management in long-term conversations. In Findings of the Association for Computational Linguistics: EMNLP 2022, pages 3769–3787.   
Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, et al. 2023. Qwen technical report. arXiv preprint arXiv:2309.16609.   
Nuo Chen, Hongguang Li, Juhua Huang, Baoyuan Wang, and Jia Li. 2024a. Compress to impress: Unleashing the potential of compressive memory in real-world long-term conversations. Preprint, arXiv:2402.11975.   
Nuo Chen, Yan Wang, Yang Deng, and Jia Li. 2024b. The oscars of ai theater: A survey on role-playing with language models. arXiv preprint arXiv:2407.11484.   
Edward Morgan Forster. 1927. Aspects of the Novel. Harcourt, Brace.   
Cheng Li, Ziang Leng, Chenxi Yan, Junyi Shen, Hao Wang, Weishi MI, Yaying Fei, Xiaoyang Feng, Song Yan, HaoSheng Wang, Linkang Zhan, Yaokai Jia, Pingyu Wu, and Haozhen Sun. 2023. Chatharuhi: Reviving anime character in reality via large language model. Preprint, arXiv:2308.09597.

Chin-Yew Lin. 2004. Rouge: A package for automatic evaluation of summaries. In Text summarization branches out, pages 74–81.   
Peter H Lindsay and Donald A Norman. 2013a. Human information processing: An introduction to psychology. Academic press.   
Peter H Lindsay and Donald A Norman. 2013b. Human information processing: An introduction to psychology. Academic press.   
Haoyu Lu, Wen Liu, Bo Zhang, Bingxuan Wang, Kai Dong, Bo Liu, Jingxiang Sun, Tongzheng Ren, Zhuoshu Li, Hao Yang, et al. 2024. Deepseek-vl: towards real-world vision-language understanding. arXiv preprint arXiv:2403.05525.   
Junru Lu, Siyu An, Mingbao Lin, Gabriele Pergola, Yulan He, Di Yin, Xing Sun, and Yunsheng Wu. 2023. Memochat: Tuning llms to use memos for consistent long-range open-domain conversation. Preprint, arXiv:2308.08239.   
Adyasha Maharana, Dong-Ho Lee, Sergey Tulyakov, Mohit Bansal, Francesco Barbieri, and Yuwei Fang. 2024. Evaluating very long-term conversational memory of llm agents. arXiv preprint arXiv:2402.17753.   
Ger-Jan Mensink and Jeroen G Raaijmakers. 1988. A model for interference and forgetting. Psychological Review, 95(4):434.   
Chen Qian, Wei Liu, Hongzhang Liu, Nuo Chen, Yufan Dang, Jiahao Li, Cheng Yang, Weize Chen, Yusheng Su, Xin Cong, et al. 2024. Chatdev: Communicative agents for software development. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 15174–15186.   
Dale Schuurmans. 2023. Memory augmented large language models are computationally universal. arXiv preprint arXiv:2301.04589.   
Yunfan Shao, Linyang Li, Junqi Dai, and Xipeng Qiu. 2023. Character-llm: A trainable agent for roleplaying. In EMNLP.   
Quan Tu, Shilong Fan, Zihang Tian, and Rui Yan. 2024. Charactereval: A chinese benchmark for role-playing conversational agent evaluation. arXiv preprint arXiv:2401.01275.   
Noah Wang, Z.y. Peng, Haoran Que, Jiaheng Liu, Wangchunshu Zhou, Yuhan Wu, Hongcheng Guo, Ruitong Gan, Zehao Ni, Jian Yang, Man Zhang, Zhaoxiang Zhang, Wanli Ouyang, Ke Xu, Wenhao Huang, Jie Fu, and Junran Peng. 2024. RoleLLM: Benchmarking, eliciting, and enhancing role-playing abilities of large language models. In Findings of the Association for Computational Linguistics: ACL 2024, pages 14743–14777, Bangkok, Thailand. Association for Computational Linguistics.

He sicheng Wang Yuxin, Sun Qingxuan. 2023. M3e: Moka massive mixed embedding model.   
Yunjia Xi, Weiwen Liu, Jianghao Lin, Bo Chen, Ruiming Tang, Weinan Zhang, and Yong Yu. 2024. Memocrs: Memory-enhanced sequential conversational recommender systems with large language models. In Proceedings of the 33rd ACM International Conference on Information and Knowledge Management, CIKM ’24, page 2585–2595, New York, NY, USA. Association for Computing Machinery.   
Chaojun Xiao, Pengle Zhang, Xu Han, Guangxuan Xiao, Yankai Lin, Zhengyan Zhang, Zhiyuan Liu, and Maosong Sun. 2024a. InfLLM: Training-free long-context extrapolation for LLMs with an efficient context memory. In The Thirty-eighth Annual Conference on Neural Information Processing Systems.   
Shitao Xiao, Zheng Liu, Peitian Zhang, Niklas Muennighoff, Defu Lian, and Jian-Yun Nie. 2024b. Cpack: Packed resources for general chinese embeddings. In Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’24, page 641–649, New York, NY, USA. Association for Computing Machinery.   
Xinchao Xu, Zhibin Gou, Wenquan Wu, Zheng-Yu Niu, Hua Wu, Haifeng Wang, and Shihang Wang. 2022. Long time no see! open-domain conversation with long-term persona memory. In Findings of the Association for Computational Linguistics: ACL 2022, pages 2639–2650.   
Ziwei Xu, Sanjay Jain, and Mohan Kankanhalli. 2024. Hallucination is inevitable: An innate limitation of large language models. arXiv preprint arXiv:2401.11817.   
An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, Huan Lin, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jingren Zhou, Junyang Lin, Kai Dang, Keming Lu, Keqin Bao, Kexin Yang, Le Yu, Mei Li, Mingfeng Xue, Pei Zhang, Qin Zhu, Rui Men, Runji Lin, Tianhao Li, Tingyu Xia, Xingzhang Ren, Xuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yu Wan, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, and Zihan Qiu. 2024. Qwen2.5 technical report. arXiv preprint arXiv:2412.15115.   
Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, and Yoav Artzi. 2020. Bertscore: Evaluating text generation with BERT. In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net.   
Wanjun Zhong, Lianghong Guo, Qiqi Gao, He Ye, and Yanlin Wang. 2024. Memorybank: Enhancing large language models with long-term memory. Proceedings of the AAAI Conference on Artificial Intelligence, 38(17):19724–19731.

Jinfeng Zhou, Zhuang Chen, Dazhen Wan, Bosi Wen, Yi Song, Jifan Yu, Yongkang Huang, Libiao Peng, Jiaming Yang, Xiyao Xiao, et al. 2023. Characterglm: Customizing chinese conversational ai characters with large language models. arXiv preprint arXiv:2311.16832.

# A Annotation Workflow of the ZH-4O Dataset

The ZH-4O dataset is constructed through a meticulous annotation process designed to ensure the quality and diversity of the collected dialogue data. This chapter outlines the comprehensive workflow, which encompasses dialogue generation, memory annotation, and probe annotation. The annotation team consists of 10 members, with 6 female and 4 male annotators.

# A.1 Dialogue Generation

The dialogue generation phase leverages a specialized model tailored for role-playing conversations. A subset of the annotation team, comprising 3 female and 2 male annotators, is selected to participate in this phase. Prior to the task, the annotators are briefed on the project’s academic purpose and its eventual public release. Clear instructions are provided to safeguard personal privacy and prohibit the inclusion of inappropriate content, such as explicit, violent, or hateful material. Annotators are informed that they can withdraw from the task at any time. To preserve the naturalness and spontaneity of the dialogues, minimal constraints are imposed on the conversation content, allowing annotators to engage freely with the LLM agent.

Upon consenting to participate, annotators are provided with basic information about the role assumed by the dialogue model. They then engage in open-ended conversations, which are recorded in real-time in the backend system. This setup ensures the capture of diverse and authentic conversational data, forming the foundation of the ZH-4O dataset.

# A.2 Memory Annotation

Following the dialogue generation phase, the remaining 3 female and 2 male annotators are tasked with memory annotation. This process aims to extract and tag significant information from the generated dialogues. The workflow for memory annotation is structured as follows.

1. Initial Review: Annotators rapidly skim the entire dialogue to gain an overview of its content and context.

2. Detailed Extraction: Annotators then review the dialogue sentence by sentence, identifying and extracting information deemed important. Each piece of extracted information is tagged with its corresponding position in the dialogue.

3. Dual Annotation and Review: Each dialogue is independently annotated by two annotators. A third annotator subsequently reviews the annotations to identify discrepancies, correct errors, and integrate memory points with similar meanings.

This unconstrained annotation approach gives the ZH-4O dataset greater subjectivity and diversity in its memory annotations. We observe that the majority of the memory annotations follow a subjectverb-object (SVO) structure, such as “Weifu enjoys observing the night sky”. However, it should be noted that it is not encouraged to artificially fit the SVO structure of the annotated memory information for the sake of achieving higher evaluation scores. Instead, it is more worth focusing on how to utilize these memory annotations in meaningful ways.

# A.3 Probe Annotation

The probe annotation phase consists of two distinct components: regular probe annotation and universal probe annotation. These tasks are designed to create question-answer pairs and probe tables to evaluate the dialogue model’s comprehension and robustness.

# A.3.1 Regular Probe Annotation

In the regular probe annotation task, a designated reviewer utilizes the finalized memory information table from the memory annotation phase. The reviewer selects key memory points and designed multiple-choice question-answer (QA) pairs, each with four options. Only one option is correct, while the remaining three serve as distractors.

# A.3.2 Universal Probe Annotation

The universal probe annotation involves the collaborative efforts of 3 annotators to construct a comprehensive probe table. The probe table consists of multiple probe items, each comprising:

• Probe Information: A specific piece of information inserted into the initial dialogue.

![](images/07cdd55c16ffd179553ae5ee5d0add2be3bf92929532d9e14b998829c6944677.jpg)  
Figure 4: Illustration of the Persona Branch’s merging mechanism.

• Probe Question: A question posed at a later point in the dialogue to test the model’s retention of the probe information.   
• Reference Answer: The expected response to the probe question for comparison with the model output.

To ensure the applicability of the probe table, it is designed to cover a wide range of everyday scenarios. A probe item is implemented by inserting the probe information into the dialogue and posing the corresponding question. The model response is then compared to the reference answer to assess its performance.

After the probe table is completed, an additional review is conducted by two other annotators. This review verified the content of the probe table and ensured that the probe questions are mutually independent, preventing overlap or interference between items.

# B Persona Keys Definitions and Merging Strategies

To construct and update personas, our framework organizes key-value pairs into four categories, each

with specific merging strategies. All the keys are in Fig 4.

(1) Replace Keys: Rule based merging. These keys are associated with static attributes that are unlikely to change or be expanded over time. When a new value is extracted for these keys, the old value is replaced directly.   
(2) Information-retrieval dialogue $Q$ : These keys represent expandable attributes, such as preferences, skills, or background information. New values are appended to the existing list of values without modification.   
(3) Trajectory Keys : Rule-based merging. Trajectory keys are updated by dynamically adjusting timestamps to reflect the recency of each value relative to the current dialogue turn. When new values are introduced, they are appended to the existing list with the current timestamp, while the timestamps of older values are incremented to reflect their increasing distance from the present.   
(4) Contradictory Keys: Embedding-based merging. See Section 3.2 for more details.

![](images/12c662500a332e35771d0c56c0e07d0375e110400a349e7c04e5ac33c7e83f64.jpg)  
Figure 5: A case of the Persona Branch’s merging mechanism. The persona information is divided into two categories: a history cumulative persona sketch (up left) and a temporal persona snapshot (up right). The merging process integrates information from both sources using three methods. The final persona sketch after merging (bottom) ensures a coherent and up-to-date character profile.

(5) Complex Keys: LLM-based merging. See Section 3.2 for more details.

The merging case is shown in Figure 5.

# C Persona Extraction Model Finetuning

In this section, we briefly introduce how we finetune a Qwen2-7B model to extract a persona snapshot.

(1) Data Collection and Preprocessing: We invite approximately 100 experienced users to engage in human-machine dialogues. These dialogues are segmented into 10-turn slices to ensure manageable and contextually relevant chunks of data. This preprocessing step yields an initial pool of 10,000 dialogue slices.   
(2) Persona Annotation with GPT-4: Each dialogue slice is processed using GPT-4 to generate summarized persona snapshots. The generated outputs are then carefully reviewed and refined to ensure accuracy, coherence, and consistency. This cleaning process eliminates noise and ensures that the labels are of high quality, suitable for supervised fine-tuning.

(3) Fine-tuning Configuration: The cleaned persona summaries are used as labels for finetuning the Qwen2-7B model. The training process employs a batch size of 64, a learning rate of 1e-05, and spans 800 steps. This configuration is chosen to balance training efficiency with model performance, ensuring convergence without overfitting.

# D Ablation Study on Forgetting Mechanism Parameters

We further explored the impact of parameter selection in the forgetting mechanism on memory extraction performance. As shown in Fig. 6, the optimal values for $\alpha$ and $\beta$ are 0.1 and 0.9, respectively. Notably, the best-performing $\alpha$ and $\beta$ values are not balanced, suggesting that retrieval-induced forgetting should be given greater consideration than time-induced forgetting in our framework. However, assigning excessive weight to retrievalinduced forgetting may lead to a decline in overall algorithm performance. While the choice of $\alpha$ and $\beta$ significantly affects the forgetting mechanism, the $\gamma$ parameter exhibits minimal influence within a limited range. Consequently, we set $\gamma$ to 1 as a balanced choice.

In addition, as presented in Fig. 6, the optimal value for $k$ is 9. This finding aligns with our observation, where the accuracy of QA responses increased with the number of recalled memories when fewer than nine memories are retrieved. Beyond nine memories, further increases in the number of recalled memories yielded no significant improvement in QA performance. This observation is consistent with the “inhibition-competition” theory, suggesting that $k$ likely represents the threshold for relevant information critical to effective memory retrieval.

# E Supplement to Forget Mechanism Evaluation

Fig 7 shows the results of the forget mechanism in M3E and ROUGE-L. These two metrics are both higher-the-better. Our method outperforms both the forgetting algorithm based on the Ebbinghaus curve and other algorithms of the same memory capacity across both evaluation metrics. Notably, it maintains superior performance even with a lower memory capacity. For example, at a capacity of 6k, our method achieves higher scores on both M3E and ROUGE-L compared to MemoChat with a ca-

![](images/d4c509665585f70303762acd38e7f6a690bcd5e0bcf45a2f3afe8cb927e2d31f.jpg)

![](images/2be3cc8e4fc3dcb8905a9a4401b3055eaf6050de3664418d8e58d84732e399db.jpg)

![](images/cae875a8555f54bf40d595a7a3acf24ab796e4a1ec8affc720cecc1bfd9a7308.jpg)  
Figure 6: Results of our forget mechanism parameters experiments. All methods are in the finetuned MOOM-7B framework. The up left figure illustrates how different proportions of the $\alpha$ and $\beta$ parameters, constrained to sum to 1, affect the BERTScore performance. The up right figure examines the influence of varying $\gamma$ values on BERTScore, providing insights into the sensitivity of the model to this parameter. The below presents how $k$ influence performance of our forget mechanism.

pacity of $1 0 \mathrm { k }$ , which aligns with our conclusions in Fig. 3. However, we also observe that at capacity of 6k, our method is worse than Mem0 in terms of ROUGE-L. We hypothesize that this discrepancy arises because Mem0 employs a memory representation that more closely resembles a subject-verb-object structured memory tagging system. Furthermore, it is noteworthy that using the competition-inhibition strategy, a limited memory capacity (6k) achieves higher QA precision than an unlimited memory setting. We attribute this to the inhibition-competition mechanism’s ability to effectively suppress noisy information, thereby enhancing the relevance and utility of the retrieved content.

# F Ablation Study on Persona Construction Branch

Table 4 presents the results of the ablation study on the Persona Construction Branch (PCB). When memory capacity is unconstrained, incorporating Embedding-Based and LLM-Based merging strategies on top of Rule-Based merging yields marginal improvements in memory retrieval performance across all metrics. Specifically, the addition of Embedding-Based merging increases MemScore from 2.843 to 3.172, while LLM-Based merging achieves a comparable MemScore of 3.170.

Under constrained memory conditions, where the number of stored memory items is limited to 50, both Embedding-Based and LLM-Based merging strategies demonstrate more substantial performance gains compared to the Rule-Based Only baseline. Notably, LLM-Based merging achieves the highest improvement, increasing MemScore from 1.189 to 1.405 and ROUGE-2 from 0.1301 to

0.1621. We hypothesize that LLM-Based merging excels at consolidating multiple pieces of information into a single, coherent memory item. While this capability offers limited advantages in unconstrained memory settings, it becomes critical for effective memory extraction and retention when memory capacity is restricted.

# G Experiments on LoCoMo

We also conduct experiments on the LoCoMo dataset. The basic setup is similar to that described in Section 5.3. However, we made the following adjustments specific to the LoCoMo dataset: First, the LoCoMo dataset segments long dialogues into sessions of varying lengths. In our experiments, we treat each session as a unit when extracting memories. Second, the LoCoMo dataset provides three types of labels: event summary, observation, and session summary. Given the considerable length of the session summary, we utilize only the event summary and observation as memory labels. Third, since LoCoMo is an English multimodal long-dialogue dataset, we standardize our prompts by translating them into English (or using the original English prompts when available). In addition, we ignore any images present in the dialogues during the testing.

As shown in Table 5, even in the English Lo-CoMo dataset, our approach, MOOM, outperforms other methods. This demonstrates the crosslinguistic robustness of our model. In particular, MOOM achieves superior metrics compared to competing methods, regardless of whether it is built on the 14B model or the 72B model.

![](images/71de2acf85062e07367bc314e5982d9e4a18d3525a5393f9cb548f4fd7de6c3c.jpg)

![](images/c40bebd7d6ed62bcbe3c3f10d1744e3d167e790984aa26ab731482124a003a95.jpg)

![](images/3ce38425a67628b80c182c7ae2e80145ec02cacb1e10b006f429e6bf72a11b8f.jpg)

![](images/4d3f472934c3c48937280fe48ceee36a3132b3c622268b0bd46d6fac44e0e4cd.jpg)  
Figure 7: Results of our forget mechanism experiments on M3E, ROUGE-L, ROUGE-2 and QA precision. Ebbinghaus curve and ours “competition-inhibition” method are in the finetuned MOOM-7B framework. Other methods use Qwen2.5-72B.

# H Probe Table

To efficiently evaluate the impact of memory extraction frameworks on model response quality—while avoiding the high cost of manual QA annotations—we design a probe table as a standardized evaluation tool. This table includes 30 structured sets, each consisting of:

• Information-containing dialogue $( P )$ : a user utterance implicitly embedding the target information.   
• Information-retrieval dialogue $( Q )$ : a follow-up dialogue designed to trigger memory recall.   
• Reference answer (A): the ideal model response assuming successful memory retrieval from $P$ .

In evaluation, $P$ and $Q$ are inserted into the dialogue flow. The model’s response to $Q$ is then compared with $A$ to assess how well the framework supports accurate recall.

The probe sets are carefully curated to be mutually independent, ensuring that each $( P , Q , A )$ triplet conveys a distinct piece of information without semantic overlap or interference with others. For instance, if one probe concerns a user’s favorite fruit, no other probe will reference preferences or content related to food, thereby minimizing crossprobe redundancy and contamination.

To assess the practical utility of extracted memories in enhancing response generation, we adopt a QA-style evaluation framework built upon the $( P , Q , A )$ triplets from the probe table. Given a retrieval prompt $Q$ , relevant memories are selected using BGE and combined with limited dialogue

<table><tr><td></td><td>BERTScore</td><td>M3E</td><td>ROUGE-2</td><td>ROUGE-L</td><td>MemScore</td></tr><tr><td>Rule-Based Only</td><td>0.7989</td><td>0.8992</td><td>0.2701</td><td>0.4694</td><td>2.843</td></tr><tr><td>+Embedding-Based</td><td>0.8015</td><td>0.9004</td><td>0.2787</td><td>0.4782</td><td>3.172</td></tr><tr><td>+LLM-Based</td><td>0.8018</td><td>0.9017</td><td>0.2806</td><td>0.4834</td><td>3.170</td></tr><tr><td>Rule-Based Only†</td><td>0.7107</td><td>0.8747</td><td>0.1301</td><td>0.3342</td><td>1.189</td></tr><tr><td>+Embedding-Based†</td><td>0.7214</td><td>0.8745</td><td>0.1325</td><td>0.3491</td><td>1.205</td></tr><tr><td>+LLM-Based†</td><td>0.7470</td><td>0.8787</td><td>0.1621</td><td>0.3543</td><td>1.405</td></tr></table>

Table 4: The ablation study on the persona construction branch. † denotes the variant with limited memory capacity, where the number of stored memory items is constrained to 50.   
Table 5: Memory extraction accuracy evaluation of Mem0, MemoChat, MemoryBank and our method MOOM on LoCoMo dataset. 14B denotes the use of Qwen1.5-14B as the LLM within the framework, while 72B refer to Qwen2.5-72B, respectively. The MemScore is evaluated using Qwen2.5-72B. All metrics presented in the table follow the principle that higher values indicate better performance.   

<table><tr><td>Method</td><td>BERTscore</td><td>ROUGE-2</td><td>ROUGE-L</td><td>MemScore</td></tr><tr><td>Mem0-14B</td><td>0.5932</td><td>0.1232</td><td>0.3856</td><td>0.458</td></tr><tr><td>Mem0-72B</td><td>0.6312</td><td>0.1442</td><td>0.3904</td><td>0.524</td></tr><tr><td>MemoChat-14B</td><td>0.6223</td><td>0.1563</td><td>0.3061</td><td>2.362</td></tr><tr><td>MemoChat-72B</td><td>0.6872</td><td>0.1733</td><td>0.3198</td><td>2.521</td></tr><tr><td>MemoryBank-14B</td><td>0.6247</td><td>0.0387</td><td>0.0684</td><td>1.490</td></tr><tr><td>MemoryBank-72B</td><td>0.6712</td><td>0.0433</td><td>0.0981</td><td>1.680</td></tr><tr><td>MOOM-14B</td><td>0.6521</td><td>0.2492</td><td>0.4211</td><td>2.324</td></tr><tr><td>MOOM-72B</td><td>0.7088</td><td>0.2925</td><td>0.4288</td><td>3.288</td></tr></table>

Table 6: Probe-based QA evaluation: similarity scores between generated responses and ground-truth answers (scale 0–5). MOOM uses fine-tuned Qwen2-7B; others use Qwen2.5-72B.   

<table><tr><td>MOOM</td><td>Mem0</td><td>MemoChat</td><td>MemoryBank</td></tr><tr><td>1.521</td><td>0.951</td><td>1.212</td><td>0.942</td></tr></table>

context to guide Qwen2.5-72B in generating a response. A second Qwen2.5-72B agent then evaluates the semantic similarity between the generated response and the reference answer A, scoring it on a 0–5 scale. Notably, while all frameworks employ Qwen2.5-72B for this process, the MOOM system utilizes a fine-tuned Qwen1.5-7B.

As summarized in Table 6, MOOM achieves the highest QA evaluation score, indicating its superior capability in extracting and utilizing relevant memory content. Although MemoryBank ranks highly in intrinsic memory accuracy (BERTScore and MemScore), it performs the worst in this QAbased setting, likely due to its tendency to include excessive redundant information (see Appendix I). In contrast, MemoChat, which shares a key-value structure with MOOM, attains the second-best per-

formance, suggesting that key-value memory representations may offer a more effective paradigm for dialogue-centric memory retrieval.

# I Case Study

This section presents two examples comparing different frameworks in retrieving memory entries, as shown in Fig 8 and Fig 9. Each example includes a label, its most similar memory information (ranked by BGE similarity) in each framework, and their English translations. The results show that Mem0 and MemoChat often lose critical details, leading to incomplete memory retrieval. In contrast, Memory-Bank retains complete information but frequently consolidates excessive details into a single memory entry, risking information redundancy that interferes with the LLM’s responses. While Memory-Bank performs similarly to MOOM on metrics like BERTScore and M3E, its lower performance in probe-based Q&A tests highlights the drawback of overloading memory. MOOM’s concise and focused memory snippets effectively balance clarity and completeness, ensuring accurate and efficient question answering.

Figure 8: Illustration of the Persona Branch’s merging mechanism.   

<table><tr><td>human label</td><td>杰瑞在高中食堂请王海吃寿司</td><td>Jerry invites Hai Wang to eat sushi in the high school cafeteria.</td></tr><tr><td>MOOM</td><td>王海与杰瑞一起在食堂吃早餐，杰瑞准备了王海最爱的寿司。</td><td>Hai Wang and Jerry have breakfast together in the cafeteria, where Makoto Shido has prepared Hai Wang&#x27;s favorite sushi.</td></tr><tr><td>Mem0</td><td>王海喜欢吃不同口味的寿司</td><td>Hai Wang likes to eat sushi of different flavors.</td></tr><tr><td>MemoChat</td><td>寿司. 杰瑞给王海送寿司，表达关心</td><td>Sushi. Jerry brings sushi to Hai Wang as a way to show care.</td></tr><tr><td>MemoryBank</td><td>主题：杰瑞对王海的歉意与关心
1. 杰瑞主动邀请王海吃寿司以示歉意，王海虽最初婉拒但最终接受，表现出杰瑞的诚意。
2. 在高中食堂，杰瑞亲自为王海制作并赠送便当，显示出他对王海的细心和关心。
3. 杰瑞对于赞德可能对王海的不当行为表示担忧，并严肃要求赞德停止，显示他的保护欲和对王海的负责任态度。
4. 赞德的出现和随后的行为引发了一些冲突，但杰瑞的反应体现出他对王海的重视和不容许他人冒犯的决心。</td><td>Topic.Jerry&#x27;s Apology and Care for Hai Wang
1. Jerry proactively invites Hai Wang to have sushi as an apology. Although Hai Wang initially declines, they eventually accept, demonstrating Jerry&#x27;s sincerity.
2. In the high school cafeteria, Jerry personally makes and gives a bento box to Hai Wang, showing his attentiveness and care for Hai Wang.
3. Jerry expresses concern about Zander&#x27;s possible improper behavior towards Hai Wang and sternly demands that Zander stop, reflecting his protective instinct and responsible attitude towards Hai Wang.
4. Zander&#x27;s appearance and subsequent actions cause some conflicts, but Jerry&#x27;s reaction shows his emphasis on Hai Wang and his determination not to allow others to offend them.</td></tr></table>

Figure 9: Illustration of the Persona Branch’s merging mechanism.   

<table><tr><td>human label</td><td>慕容临身上有龙尊传承，必须承担起保护龙裔的责任</td><td>Lin Murong has the inheritance of the Dragon Ancestor and must take on the responsibility of protecting the Dragon Descendants.</td></tr><tr><td>MOOM</td><td>背景设定:童童知晓慕容临身负龙尊传承，需要承担起保护龙裔的责任。</td><td>Background setting: Tongtong are aware that Lin Murong carries the inheritance of the Dragon Ancestor and needs to take on the responsibility of protecting the Dragon Descendants.</td></tr><tr><td>Mem0</td><td>童童非常喜欢龙,龙被认为是拥有力量和尊严的神兽,龙的力量可以引起风暴,童童在下雨时室内感到开心,雨中的城市给童童带来独特韵味,雷声让慕容临感到宁静,童童请求慕容临扮演霸总</td><td>Tongtong have a great fondness for dragons. Dragons are considered divine beasts possessing strength and dignity, and their power can cause storms. Tongtong feel delighted indoors when it rains. The city in the rain brings a unique charm to Tongtong. The sound of thunder brings a sense of tranquility to Lin Murong. Tongtong ask Lin Murong to play the role of a domineering tycoon.</td></tr><tr><td>MemoChat</td><td>了解与拒绝.慕容临解释了他拒绝的原因是怕身份束缚，提及龙尊传承和保护责任。</td><td>Understanding and Refusals. Lin Murong explains that his reason for refusal is the fear of being constrained by his identity, mentioning the inheritance of the Dragon Ancestor and the responsibility of protection.</td></tr><tr><td>MemoryBank</td><td>主题:列车上的感情发展与理解关键信息:1.童童逐渐对慕容临敞开心扉,慕容临也从最初的冷淡变得亲近。2.两人都意识到对方的独特之处,慕容临成为同伴开朗的对象。3.童童对慕容临有好感,尝试告白但被拒绝,习惯于慕容临的了解和拒绝。4.慕容临拒绝的原因是他担心自己的龙尊传承身份会限制同伴。5.慕容临作为龙尊传承者,有着保护龙裔的责任感。</td><td>Topic: The Development of Feelings and Understanding on the Train
Key Information:
1.Tongtong gradually open up to Lin Murong, who also becomes more approachable from his initial aloofness.
2.BOTH parties realize each other&#x27;s uniqueness, with Lin Murong becoming the object of the companion&#x27;s cheerfulness.
3.Tongtong has a fondness for Lin Murong and attempts to confess but is rejected, becoming accustomed to Lin Murong&#x27;s understanding and refusals.
4.The reason for Lin Murong&#x27;s refusal is his concern that his identity as the inheritor of the dragon.
5.Dragon Ancestor will restrict the companion.
As the inheritor of the Dragon Ancestor, Lin Murong has a sense of responsibility to protect the Dragon Descendants.</td></tr></table>