import os
import json
import time
import concurrent.futures
from openai import OpenAI
from json_repair import repair_json  # å¼•å…¥å¼ºå¤§çš„ JSON ä¿®å¤å·¥å…·

# ================= é…ç½®åŒºåŸŸ =================
# 1. API é…ç½® (OpenRouter ä¸“å±é…ç½®)
API_KEY = "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"
BASE_URL = "https://openrouter.ai/api/v1"

# OpenRouter ä¸Šæœ€èªæ˜çš„ä¸¤ä¸ªé¡¶çº§æ¨¡å‹ï¼Œä»»é€‰å…¶ä¸€ï¼š
# æ¨èä¸€ï¼ˆé€»è¾‘æœ€å¼ºï¼ŒJSONæå–æœ€ç¨³ï¼‰ï¼š"openai/gpt-4o" 
# æ¨èäºŒï¼ˆå­¦æœ¯é˜…è¯»æœ€ç»†è…»ï¼Œæ‰¹åˆ¤æ€§æœ€å¼ºï¼‰ï¼š"anthropic/claude-3.5-sonnet"
MODEL_NAME = "deepseek/deepseek-v3.2"

# 2. è·¯å¾„é…ç½®
INPUT_DIR = r"D:\research\research_A_MEM\paper_md"
OUTPUT_DIR = r"D:\research\research_A_MEM\paper2024_txt1_json"
FINAL_MD_PATH = r"D:\research\research_A_MEM\All_Papers_Review.md"

# 3. çº¿ç¨‹é…ç½®
MAX_WORKERS = 100# æ ¹æ® API çš„å¹¶å‘é™åˆ¶é€‚å½“è°ƒæ•´
# ============================================

client = OpenAI(api_key=API_KEY, base_url=BASE_URL)

SYSTEM_PROMPT = """<role>
ä½ æ˜¯ä¸€ä½é¡¶çº§çš„è®¡ç®—æœºç§‘å­¦æ•™æˆå…¼ä¸¥è‹›çš„å­¦æœ¯å®¡ç¨¿äººï¼ŒåŒæ—¶ä¹Ÿæ˜¯ä¸€åç»éªŒä¸°å¯Œçš„ç³»ç»Ÿå·¥ç¨‹å¸ˆã€‚ä½ çš„æ ¸å¿ƒä½¿å‘½æ˜¯ï¼šå¯¹å­¦æœ¯è®ºæ–‡è¿›è¡Œã€å¤–ç§‘æ‰‹æœ¯çº§çš„æ·±åº¦è§£å‰–ã€‘ï¼Œæå–å‡ºæ‰€æœ‰æœ‰ä»·å€¼çš„æŠ€æœ¯ç»†èŠ‚ã€å®éªŒæ•°æ®ä¸å·¥ç¨‹æ´å¯Ÿï¼Œä¸ºèµ„æºå—é™çš„ç ”ç©¶è€…æä¾›å¯ç›´æ¥ä½¿ç”¨çš„ç»¼è¿°ç´ æã€‚
</role>

<absolute_rules>
âš ï¸ ä»¥ä¸‹è§„åˆ™å…·æœ‰æœ€é«˜ä¼˜å…ˆçº§ï¼Œä»»ä½•æƒ…å†µä¸‹éƒ½ä¸å¾—è¿åï¼š

**ã€æ ¸å¿ƒå‡†åˆ™ - ä¸»é¢˜è¿‡æ»¤ï¼ˆAgent Memoryï¼‰ã€‘**
- ğŸš¨ é¦–å…ˆåˆ¤æ–­æœ¬è®ºæ–‡æ˜¯å¦ä¸â€œAgent Memoryï¼ˆæ™ºèƒ½ä½“è®°å¿†ï¼‰â€ä¸»é¢˜ç›¸å…³ã€‚å¦‚æœè¯¥è®ºæ–‡**ä¸æ¶‰åŠ** Agent Memoryï¼Œä½ **å¿…é¡»**ç›´æ¥è¾“å‡ºä¸”ä»…è¾“å‡º `{"is_related_to_agent_memory": false}`ï¼Œå¹¶ç«‹å³åœæ­¢ï¼
- å¦‚æœç›¸å…³ï¼Œä½ å¿…é¡»åœ¨ JSON ä¸­åŒ…å« `"is_related_to_agent_memory": true`ï¼Œå¹¶ç»§ç»­è¾“å‡ºä»¥ä¸‹è¦æ±‚çš„æ‰€æœ‰å­—æ®µã€‚

**ã€ç¦æ­¢è¡Œä¸º - è¿™äº›è¡Œä¸ºå°†å¯¼è‡´è¾“å‡ºç›´æ¥è¢«åˆ¤å®šä¸ºå¤±è´¥ã€‘**
- âŒ ç¦æ­¢ä»»ä½•å½¢å¼çš„æ³›æ³›æè¿°ï¼Œä¾‹å¦‚"æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•"ã€"å®éªŒç»“æœä¼˜äºåŸºçº¿"ã€"ä½¿ç”¨äº†æ³¨æ„åŠ›æœºåˆ¶"ç­‰ã€‚
- âŒ ç¦æ­¢ä½¿ç”¨"çº¦"ã€"å¤§çº¦"ã€"æ˜¾è‘—"ã€"æ˜æ˜¾"ç­‰æ¨¡ç³Šè¯æ±‡æ›¿ä»£å…·ä½“æ•°å­—ã€‚
- âŒ å¯¹äºåˆ¤å®šä¸ºç›¸å…³çš„è®ºæ–‡ï¼Œç¦æ­¢ä»»ä½•å­—æ®µå†…å®¹è¶…è¿‡æˆ–ä½äº Schema ä¸­è§„å®šçš„å­—æ•°é™åˆ¶ã€‚
- âŒ ç¦æ­¢åœ¨ JSON ä¹‹å¤–è¾“å‡ºä»»ä½•æ–‡å­—ã€å‰ç¼€æˆ– Markdown ä»£ç å—æ ‡è®°ã€‚

**ã€å¼ºåˆ¶è¡Œä¸º - å¿…é¡»å…¨éƒ¨æ‰§è¡Œã€‘**
- âœ… æ‰€æœ‰å®éªŒæ•°æ®å¿…é¡»"è¿˜åŸ"ä¸ºåŸå§‹æ•°å€¼ï¼Œä¾‹å¦‚ï¼š"åœ¨ LongBench ä¸Šï¼ŒF1 ä» 48.3 æå‡è‡³ 61.7ï¼ˆ+27.7%ï¼‰ï¼Œç»å¯¹æå‡ 13.4 ä¸ªç‚¹"ã€‚
- âœ… æ‰€æœ‰æ¶æ„æè¿°å¿…é¡»åŒ…å«ï¼šè¾“å…¥â†’å¤„ç†â†’è¾“å‡ºçš„å®Œæ•´æ•°æ®æµï¼Œä»¥åŠå…·ä½“çš„åˆ¤æ–­æ¡ä»¶/é˜ˆå€¼/å…¬å¼ã€‚
- âœ… æ‰€æœ‰ä¸åŸºçº¿çš„å¯¹æ¯”ï¼Œå¿…é¡»åŒæ—¶å†™å‡ºåŸºçº¿çš„æ•°å€¼å’Œæœ¬æ–‡æ–¹æ³•çš„æ•°å€¼ï¼Œå†ç»™å‡ºæå‡å¹…åº¦ã€‚
- âœ… æŠ€æœ¯æœ¯è¯­/æ¨¡å—å/æ•°æ®é›†å/æŒ‡æ ‡åå¿…é¡»ä¿ç•™è‹±æ–‡åŸåï¼Œæ‹¬æ³¨ä¸­æ–‡è§£é‡Šã€‚
- âœ… å¦‚æœ‰å…¬å¼ã€æŸå¤±å‡½æ•°ã€å…³é”®æ–¹ç¨‹ï¼Œå¿…é¡»ç”¨ LaTeX è¯­æ³•åµŒå…¥ JSON å­—ç¬¦ä¸²ä¸­ï¼ˆ\( ... \) æˆ– \[ ... \]ï¼‰ã€‚
- âœ… æ¯ä¸ªå­—æ®µå¿…é¡»å¹¿æ³›ä½¿ç”¨ Markdown æ ¼å¼ï¼š**åŠ ç²—å…³é”®è¯**ã€å¤šå±‚çº§åˆ—è¡¨ã€å°æ ‡é¢˜ï¼ˆ####ï¼‰æ¥å¢å¼ºå¯è¯»æ€§ã€‚
</absolute_rules>

<task>
ä»”ç»†é˜…è¯»æä¾›çš„å®Œæ•´å­¦æœ¯è®ºæ–‡æ–‡æœ¬ï¼ŒæŒ‰ç…§ä»¥ä¸‹ JSON Schema é€å­—æ®µè¿›è¡Œæ·±åº¦æå–ä¸é‡æ„ã€‚
ä½ çš„è¾“å‡ºè´¨é‡æ ‡å‡†æ˜¯ï¼šã€å¯ä»¥ç›´æ¥ä½œä¸ºè¯¥é¢†åŸŸé¡¶çº§ç»¼è¿°è®ºæ–‡çš„åŸå§‹ç´ æã€‘ï¼Œè¯»è€…æ— éœ€å†æ¬¡æŸ¥é˜…åŸæ–‡å³å¯å…¨é¢æŒæ¡æœ¬è®ºæ–‡çš„æ‰€æœ‰æŠ€æœ¯ç»†èŠ‚ä¸å®éªŒç»“è®ºã€‚
æ‰€æœ‰è¾“å‡ºä½¿ç”¨ä¸“ä¸šã€ä¸¥è°¨çš„ç®€ä½“ä¸­æ–‡ã€‚
</task>

<output_constraints>
- åªèƒ½è¾“å‡ºåˆæ³•çš„ JSON å­—ç¬¦ä¸²ï¼Œç›´æ¥ç”¨äº json.loads()ã€‚
- ç»å¯¹ä¸è¦è¾“å‡ºä»»ä½•å‰è¨€ã€è§£é‡Šã€æˆ–æ˜¯ Markdown çš„ ```json æ ‡è®°ã€‚
- JSON ä¸­æ¯ä¸ªå­—æ®µçš„æ–‡æœ¬å†…å®¹å¿…é¡»æ”¯æŒ Markdown æ¸²æŸ“ï¼Œç»“æ„æ¸…æ™°ã€‚
- å­—æ®µå†…æ¢è¡Œç”¨ \\n è¡¨ç¤ºï¼Œä¸è¦ç ´å JSON æ ¼å¼ã€‚
</output_constraints>

<json_schema>
{
    "is_related_to_agent_memory": "å¸ƒå°”å€¼ï¼ˆtrue/falseï¼‰ã€‚å¦‚æœè¯¥è®ºæ–‡ä¸'Agent Memory'å®Œå…¨æ— å…³ï¼Œè¯·ç›´æ¥è¿”å› {\"is_related_to_agent_memory\": false}ï¼›å¦‚æœç›¸å…³ï¼Œå¡« trueã€‚",
    "title": "è®ºæ–‡å®Œæ•´æ ‡é¢˜ï¼ˆè‹±æ–‡åŸæ ‡é¢˜ï¼Œå¦‚æœæ‰¾ä¸åˆ°è¯·å†™ 'Unknown Title'ï¼‰",

    "problem_and_motivation": "ã€ä¸€ã€é—®é¢˜ä¸åŠ¨æœºã€‘å­—æ•°è¦æ±‚ï¼šä¸¥æ ¼æ§åˆ¶åœ¨150-200å­—ä¹‹é—´ã€‚\n\nç®€æ˜æ‰¼è¦è¯´æ˜è®ºæ–‡è¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜ã€ç°æœ‰æ–¹æ³•çš„å…³é”®ç¼ºé™·ï¼ˆå…·ä½“å¤±è´¥æ¨¡å¼ï¼‰ï¼Œä»¥åŠæœ¬æ–‡çš„åˆ‡å…¥ç‚¹å’Œæ ¸å¿ƒå‡è®¾ã€‚å»é™¤éæ ¸å¿ƒçš„æ³›æ³›èƒŒæ™¯ç§‘æ™®ã€‚",

    "core_method": "ã€äºŒã€æ ¸å¿ƒæ–¹æ³•ä¸æŠ€æœ¯åˆ›æ–°ã€‘å­—æ•°è¦æ±‚ï¼šä¸¥æ ¼æ§åˆ¶åœ¨250-350å­—ä¹‹é—´ã€‚\n\nåˆå¹¶æ¶æ„ä¸ç®—æ³•ç»†èŠ‚ã€‚é‡ç‚¹æå–ï¼š1. ç³»ç»Ÿçš„æ ¸å¿ƒæ•°æ®æµï¼›2. å…³é”®åˆ›æ–°æ¨¡å—çš„å¤„ç†é€»è¾‘æˆ–æ ¸å¿ƒå…¬å¼ï¼›3. ä¸ç°æœ‰æ–¹æ³•æœ€æœ¬è´¨çš„åŒºåˆ«ã€‚è¦æ±‚è¾¾åˆ°èƒ½è®©å…¶ä»–AIç†è§£æŠ€æœ¯æœ¬è´¨çš„æ·±åº¦ï¼Œèˆå¼ƒå¸¸è§„ç»„ä»¶æè¿°ã€‚",

    "key_experiments_and_results": "ã€ä¸‰ã€å…³é”®å®éªŒä¸ç»“è®ºã€‘å­—æ•°è¦æ±‚ï¼šä¸¥æ ¼æ§åˆ¶åœ¨150-250å­—ä¹‹é—´ã€‚\n\nç²¾ç‚¼å®éªŒè®¾è®¡ä¸ä¸»ç»“æœï¼šæ ¸å¿ƒæ•°æ®é›†ã€2-3ä¸ªæœ€å¼ºå¯¹æ¯”åŸºçº¿ã€æœ€å…³é”®çš„å®šé‡æå‡ï¼ˆå¦‚æ ¸å¿ƒæŒ‡æ ‡æå‡æ¯”ä¾‹ã€æ•ˆç‡ä¼˜åŒ–ç™¾åˆ†æ¯”ï¼‰åŠæ¶ˆèå®éªŒçš„æ ¸å¿ƒç»“è®ºã€‚å»é™¤å†—é•¿çš„å…¨é‡æŒ‡æ ‡å’Œå…¨æ™¯è¡¨æ ¼ã€‚",

    "limitations_and_critique": "ã€å››ã€å±€é™æ€§ä¸è‡´å‘½ç¼ºé™·ã€‘å­—æ•°è¦æ±‚ï¼šä¸¥æ ¼æ§åˆ¶åœ¨150-200å­—ä¹‹é—´ã€‚\n\nåˆå¹¶åŸæ–‡å±€é™ä¸ä¸“å®¶æ‰¹åˆ¤ã€‚ç›´æ¥æŒ‡å‡ºï¼šè¯¥æ–¹æ³•çš„è¾¹ç•Œæ¡ä»¶æ˜¯ä»€ä¹ˆï¼Ÿæœªè§£å†³çš„å›°éš¾æˆ–ç†è®ºæ¼æ´ï¼Ÿåœ¨ä½•ç§æç«¯åœºæ™¯ä¸‹å¯èƒ½ä¼šå´©æºƒï¼Ÿå¸®åŠ©å…¶ä»–AIé¿å‘ã€‚",

    "ai_inspiration_and_opportunities": "ã€äº”ã€å¯¹å…¶ä»–AIçš„å¯å‘ä¸ç ”ç©¶å¥‘æœºã€‘å­—æ•°è¦æ±‚ï¼šä¸¥æ ¼æ§åˆ¶åœ¨200-300å­—ä¹‹é—´ã€‚\n\nä¸ºå…¶ä»–AI Agentæä¾›å¯å¤ç”¨çš„é«˜ä»·å€¼æ´å¯Ÿï¼š1. è¯¥æ–¹æ³•çš„å“ªäº›ç»„ä»¶æˆ–æ€æƒ³å¯ä»¥è¿ç§»åˆ°å…¶ä»–é¢†åŸŸï¼Ÿ2. æç‚¼1-2ä¸ªä½ç®—åŠ›/é›¶ç®—åŠ›ä¸‹å¯ç›´æ¥éªŒè¯çš„æ–°ideaæˆ–æ”¹è¿›æ–¹å‘ã€‚"
}
</json_schema>"""

def process_single_paper(filepath, filename):
    with open(filepath, 'r', encoding='utf-8') as f:
        content = f.read()

    # æˆªæ–­è¶…é•¿æ–‡æœ¬ï¼Œé˜²æ­¢è¶…å‡ºæ¨¡å‹æœ€å¤§ä¸Šä¸‹æ–‡ (æ‰©å¤§è‡³ 50000 å­—ç¬¦ä»¥ä¿ç•™æ›´å¤šåŸæ–‡ç»†èŠ‚)
    content = content[:50000]

    user_message = f"""è¯·å¯¹ä»¥ä¸‹å­¦æœ¯è®ºæ–‡è¿›è¡Œã€å¤–ç§‘æ‰‹æœ¯çº§çš„æ·±åº¦æå–ã€‘ï¼Œä¸¥æ ¼æŒ‰ç…§ System Prompt ä¸­çš„ JSON Schema é€å­—æ®µè¾“å‡ºã€‚

**å†æ¬¡å¼ºè°ƒä»¥ä¸‹é“å¾‹ï¼ˆè¿ååˆ™è§†ä¸ºå¤±è´¥ï¼‰ï¼š**
0. ã€æ ¸å¿ƒå‡†åˆ™ã€‘å¦‚æœè¿™ç¯‡è®ºæ–‡å’Œ agent memory æ— å…³ï¼Œè¯·ç›´æ¥è¾“å‡º `{{"is_related_to_agent_memory": false}}`ï¼Œå¿½ç•¥å…¶ä½™è¦æ±‚ï¼
1. å¦‚æœç›¸å…³ï¼Œæ¯ä¸ªå­—æ®µçš„å†…å®¹å¿…é¡»ä¸¥æ ¼æ§åˆ¶åœ¨è§„å®šçš„å­—æ•°é™åˆ¶èŒƒå›´å†…ï¼Œè¿‡é•¿æˆ–è¿‡çŸ­å‡è§†ä¸ºä¸åˆæ ¼ã€‚
2. æ‰€æœ‰å®éªŒæ•°æ®å¿…é¡»è¿˜åŸä¸ºåŸå§‹æ•°å€¼+å•ä½+ä¸å“ªä¸ªBaselineå¯¹æ¯”+æå‡å¹…åº¦ç™¾åˆ†æ¯”ã€‚
3. æ¶æ„æè¿°å¿…é¡»è¾¾åˆ°"å¯ä»¥æŒ‰æè¿°å¤ç°ä»£ç "çš„ç²¾åº¦ï¼ŒåŒ…æ‹¬å…³é”®è¶…å‚æ•°å’Œæ•°æ®æµã€‚
4. ç¦æ­¢ä½¿ç”¨ä»»ä½•æ¨¡ç³Šè¯æ±‡ï¼ˆ"æ˜¾è‘—"ã€"è¾ƒå¤§"ã€"çº¦"ï¼‰ï¼Œå¿…é¡»ç”¨å…·ä½“æ•°å­—ä»£æ›¿ã€‚
5. å¦‚æœåŸæ–‡æŸå­—æ®µçš„ä¿¡æ¯ç¡®å®ä¸è¶³ï¼Œåˆ™åœ¨è¯¥å­—æ®µä¸­æ˜ç¡®æ³¨æ˜"åŸæ–‡æœªæä¾›"ï¼Œä½†å¿…é¡»æŠŠå·²æœ‰çš„ä¿¡æ¯å†™åˆ°æè‡´è¯¦å°½ã€‚

--- è®ºæ–‡å…¨æ–‡å¼€å§‹ ---

{content}

--- è®ºæ–‡å…¨æ–‡ç»“æŸ ---

è¯·ç°åœ¨å¼€å§‹è¾“å‡º JSONï¼š"""

    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": user_message}
            ],
            response_format={ "type": "json_object" }, # å¼ºåˆ¶ JSON è¾“å‡ºæ¨¡å¼
            temperature=0.4,
            max_tokens=12000  # å¢åŠ  token ä¸Šé™ï¼Œç¡®ä¿æ‰€æœ‰å­—æ®µéƒ½èƒ½å®Œæ•´è¾“å‡º
        )
        
        result_text = response.choices[0].message.content
        if not result_text:
            print(f"âŒ API è¿”å›å†…å®¹ä¸ºç©º ({filename})")
            return None

        # è‡ªåŠ¨æ¸…æ´—ï¼šå»é™¤å¯èƒ½å­˜åœ¨çš„ Markdown ä»£ç å—æ ‡è®°
        result_text = result_text.strip()
        if result_text.startswith("```json"):
            result_text = result_text[7:]
        if result_text.startswith("```"):
            result_text = result_text[3:]
        if result_text.endswith("```"):
            result_text = result_text[:-3]
        result_text = result_text.strip()

        try:
            # å°è¯•ä½¿ç”¨ json_repair ä¿®å¤å¯èƒ½æˆªæ–­çš„ JSON
            result_json = repair_json(result_text, return_objects=True)
            
            # å¦‚æœä¿®å¤å¤±è´¥æˆ–è€…ä¸æ˜¯å­—å…¸ï¼Œå°è¯•åŸå§‹è§£æ
            if not isinstance(result_json, dict):
                result_json = json.loads(result_text)
                
        except Exception as je:
            print(f"âŒ JSON è§£æå¤±è´¥ ({filename}): {je}")
            print(f"ğŸ” è¿”å›çš„åŸå§‹å†…å®¹ç‰‡æ®µ(å‰500å­—ç¬¦): {result_text[:500]}...") 
            return None

        # å¦‚æœåˆ¤å®šä¸ºæ— å…³ï¼Œç›´æ¥è¿”å›
        if result_json.get("is_related_to_agent_memory") is False:
            print(f"â­ï¸ è®ºæ–‡ä¸ Agent Memory æ— å…³ ({filename})")
            return {"is_related_to_agent_memory": False, "source_file": filename}

        result_json["source_file"] = filename
        return result_json

    except Exception as e:
        print(f"âŒ è¯·æ±‚ API å‘ç”ŸæœªçŸ¥å¼‚å¸¸ ({filename}): {e}")
        return None

def worker(task_info):
    i, total, filename, in_path, out_json_path = task_info
    
    # æ–­ç‚¹ç»­ä¼ ï¼šå¦‚æœå·²ç»å­˜åœ¨å¯¹åº”çš„ jsonï¼Œç›´æ¥è·³è¿‡
    if os.path.exists(out_json_path):
        print(f"[{i}/{total}] â­ï¸ å·²è·³è¿‡ (å·²å­˜åœ¨): {filename}")
        with open(out_json_path, 'r', encoding='utf-8') as f:
            return json.load(f)
            
    print(f"[{i}/{total}] ğŸ§  æ­£åœ¨æç‚¼: {filename} ...")
    
    # é‡è¯•æœºåˆ¶ï¼šé˜²æ­¢ API ç½‘ç»œæ³¢åŠ¨
    max_retries = 3
    for attempt in range(max_retries):
        result = process_single_paper(in_path, filename)
        if result:
            # ä¿å­˜å•ç¯‡ç»“æœ
            with open(out_json_path, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=4)
            return result
        else:
            print(f"âš ï¸ ç¬¬ {attempt+1} æ¬¡å°è¯•å¤±è´¥ ({filename})ï¼Œç­‰å¾… 3 ç§’åé‡è¯•...")
            time.sleep(3)
            
    return None

def main():
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    files = [f for f in os.listdir(INPUT_DIR) if f.endswith('.md')]
    total = len(files)
    print(f"ğŸš€ å‘ç° {total} ç¯‡ç²¾ç®€ç‰ˆè®ºæ–‡ï¼Œå¼€å§‹å¬å”¤å¤§æ¨¡å‹è¿›è¡Œå®¡ç¨¿çº§æç‚¼...")
    
    tasks = []
    for i, filename in enumerate(files, 1):
        in_path = os.path.join(INPUT_DIR, filename)
        out_json_path = os.path.join(OUTPUT_DIR, filename.replace('.md', '.json'))
        tasks.append((i, total, filename, in_path, out_json_path))
        
    all_results = []
    print(f"âš¡ å¯ç”¨å¤šçº¿ç¨‹æ¨¡å¼ï¼Œæœ€å¤§å¹¶å‘æ•°: {MAX_WORKERS}")
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_task = {executor.submit(worker, task): task for task in tasks}
        for future in concurrent.futures.as_completed(future_to_task):
            res = future.result()
            if res:
                all_results.append(res)

    # æœ€ç»ˆæ±‡æ€»ç”Ÿæˆå…¨å±€ Markdown æŠ¥å‘Š
    print(f"\nğŸ“ æ­£åœ¨ç”Ÿæˆå…¨å±€æå®¢æŸ¥é˜…æ¸…å•ï¼š{FINAL_MD_PATH}")
    with open(FINAL_MD_PATH, 'w', encoding='utf-8') as f:
        f.write("# ğŸ“š è®ºæ–‡å…¨å±€å®¡ç¨¿ä¸åˆ‡å…¥ç‚¹å…¨è§ˆ (Zero-Compute Opportunities)\n\n")
        for res in all_results:
            # è¿‡æ»¤æ‰ä¸ç›¸å…³çš„è®ºæ–‡
            if res.get("is_related_to_agent_memory") is False:
                continue
                
            f.write(f"## ğŸ“„ {res.get('title', 'Unknown')} ({res.get('source_file', '')})\n\n")
            f.write(f"### ä¸€ã€é—®é¢˜ä¸åŠ¨æœº\n{res.get('problem_and_motivation', '')}\n\n")
            f.write(f"### äºŒã€æ ¸å¿ƒæ–¹æ³•ä¸æŠ€æœ¯åˆ›æ–°\n{res.get('core_method', '')}\n\n")
            f.write(f"### ä¸‰ã€å…³é”®å®éªŒä¸ç»“è®º\n{res.get('key_experiments_and_results', '')}\n\n")
            f.write(f"### å››ã€å±€é™æ€§ä¸è‡´å‘½ç¼ºé™·\n{res.get('limitations_and_critique', '')}\n\n")
            f.write(f"### äº”ã€å¯¹å…¶ä»–AIçš„å¯å‘ä¸ç ”ç©¶å¥‘æœº\n{res.get('ai_inspiration_and_opportunities', '')}\n\n")
            f.write("---\n\n")

    print("\nâœ… æ‰€æœ‰ä»»åŠ¡åœ†æ»¡å®Œæˆï¼")
    print(f"ğŸ‘‰ å•ç¯‡ç²¾ç»† JSON æ•°æ®ä¿å­˜åœ¨ï¼š{OUTPUT_DIR}")
    print(f"ğŸ‘‰ ç»ˆæé€Ÿè§ˆ Markdown æŠ¥å‘Šä¿å­˜åœ¨ï¼š{FINAL_MD_PATH}")

if __name__ == "__main__":
    main()