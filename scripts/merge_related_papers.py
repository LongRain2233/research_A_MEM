"""
å°†ä¸¤ä¸ªæ–‡ä»¶å¤¹ä¸­ is_related_to_agent_memory: true çš„è®ºæ–‡åˆå¹¶ä¸ºå•ä¸ª Markdown æ–‡æ¡£
"""
import os
import json
import sys
from pathlib import Path

# è§£å†³ Windows æ§åˆ¶å°ä¸­æ–‡è¾“å‡ºé—®é¢˜
if sys.platform == "win32":
    sys.stdout.reconfigure(encoding='utf-8')

# ================= é…ç½®åŒºåŸŸ =================
DIR1 = r"D:\research\research_A_MEM\paper2024_txt1_json"
DIR2 = r"D:\research\research_A_MEM\533_md_json"
OUTPUT_PATH = r"D:\research\research_A_MEM\docs\All_Papers_Review_with_github.md"
# ============================================

def load_json_file(filepath):
    """åŠ è½½å•ä¸ª JSON æ–‡ä»¶"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"âŒ åŠ è½½å¤±è´¥ {filepath}: {e}")
        return None

def is_agent_memory_related(data):
    """æ£€æŸ¥æ˜¯å¦ä¸ºæ™ºèƒ½ä½“è®°å¿†ç›¸å…³è®ºæ–‡"""
    return data.get("is_related_to_agent_memory") is True

def format_paper_as_markdown(data, source_dir):
    """å°†è®ºæ–‡æ•°æ®æ ¼å¼åŒ–ä¸º Markdown"""
    title = data.get("title", "Unknown Title")
    source_file = data.get("source_file", "Unknown")
    has_github = data.get("has_github_link", False)

    # æ·»åŠ æ¥æºç›®å½•æ ‡è¯†
    dir_name = os.path.basename(source_dir)

    # GitHub é“¾æ¥çŠ¶æ€æ˜¾ç¤º
    github_status = "ğŸ”— æœ‰ GitHub" if has_github else "âŒ æ—  GitHub"

    md = f"## ğŸ“„ {title}\n"
    md += f"**æ¥æº**: `{dir_name}` | **æ–‡ä»¶**: {source_file} | **{github_status}**\n\n"

    md += "### ä¸€ã€é—®é¢˜ä¸åŠ¨æœº\n"
    md += f"{data.get('problem_and_motivation', '')}\n\n"

    md += "### äºŒã€æ ¸å¿ƒæ–¹æ³•ä¸æŠ€æœ¯åˆ›æ–°\n"
    md += f"{data.get('core_method', '')}\n\n"

    md += "### ä¸‰ã€å…³é”®å®éªŒä¸ç»“è®º\n"
    md += f"{data.get('key_experiments_and_results', '')}\n\n"

    md += "### å››ã€å±€é™æ€§ä¸è‡´å‘½ç¼ºé™·\n"
    md += f"{data.get('limitations_and_critique', '')}\n\n"

    md += "### äº”ã€å¯¹å…¶ä»–AIçš„å¯å‘ä¸ç ”ç©¶å¥‘æœº\n"
    md += f"{data.get('ai_inspiration_and_opportunities', '')}\n\n"

    md += "---\n\n"
    return md

def main():
    all_papers = []

    # å¤„ç†ä¸¤ä¸ªç›®å½•
    for dir_path in [DIR1, DIR2]:
        print(f"\nğŸ“‚ æ­£åœ¨æ‰«æ: {dir_path}")
        dir_path = Path(dir_path)

        if not dir_path.exists():
            print(f"âš ï¸ ç›®å½•ä¸å­˜åœ¨: {dir_path}")
            continue

        json_files = list(dir_path.glob("*.json"))
        print(f"   å‘ç° {len(json_files)} ä¸ª JSON æ–‡ä»¶")

        related_count = 0
        for json_file in json_files:
            data = load_json_file(json_file)
            if data and is_agent_memory_related(data):
                all_papers.append((data, str(dir_path)))
                related_count += 1

        print(f"   âœ… å…¶ä¸­ {related_count} ç¯‡ä¸ Agent Memory ç›¸å…³")

    # æŒ‰æ ‡é¢˜æ’åº
    all_papers.sort(key=lambda x: x[0].get("title", ""))

    print(f"\nğŸ“Š æ€»è®¡æ‰¾åˆ° {len(all_papers)} ç¯‡ç›¸å…³è®ºæ–‡")

    # ç”Ÿæˆ Markdown
    output_dir = os.path.dirname(OUTPUT_PATH)
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)

    with open(OUTPUT_PATH, 'w', encoding='utf-8') as f:
        f.write("# ğŸ“š Agent Memory è®ºæ–‡ç»¼è¿°\n\n")
        f.write(f"å…± {len(all_papers)} ç¯‡ç›¸å…³è®ºæ–‡\n\n")
        f.write("---\n\n")

        for data, source_dir in all_papers:
            md = format_paper_as_markdown(data, source_dir)
            f.write(md)

    print(f"\nâœ… å·²ç”Ÿæˆåˆå¹¶æ–‡æ¡£: {OUTPUT_PATH}")

if __name__ == "__main__":
    main()