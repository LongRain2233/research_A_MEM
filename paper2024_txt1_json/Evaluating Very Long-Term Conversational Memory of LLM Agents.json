{
    "is_related_to_agent_memory": true,
    "has_github_link": false,
    "title": "Evaluating Very Long-Term Conversational Memory of LLM Agents",
    "problem_and_motivation": "现有长时开放域对话研究局限于评估不超过5个会话、约1K token的上下文，无法衡量模型在**极长对话（数百轮、数千token）**中的记忆与理解能力。现有长上下文LLM和RAG技术在此场景下的有效性未被充分探索。本文核心切入点是：构建一个**极长时、多模态对话数据集LOCOMO**，并设计一套评估基准，以系统性评测LLM智能体在长程对话中的**记忆保持、因果与时间关系理解**能力。核心假设是：现有方法在极长对话中会因上下文截断或幻觉而表现不佳。",
    "core_method": "本文提出一个**人机协作的LOCOMO数据集生成与评估框架**。\n\n**1. 数据集生成：** 构建两个基于LLM的虚拟智能体（\\(\\mathcal{L}_1, \\mathcal{L}_2\\)），每个智能体配备：\n- **独特人设（Persona）**：从MSC数据集扩展而来，包含目标、习惯、关系等。\n- **时序事件图（Temporal Event Graph \\(\\mathcal{G}\\)）**：包含最多25个因果关联的生活事件，时间跨度6-12个月。\n- **智能体架构**：采用生成式智能体架构（Park et al., 2023），具备**记忆与反射模块**。具体流程：\n    - **记忆写入**：每轮对话 \\(h_{k_j}\\) 转化为观察 \\(o_{k_j}\\) 存入**长期记忆 \\(\\mathcal{H}_l\\)**；每个会话 \\(k\\) 后生成摘要 \\(w_k\\) 存入**短期记忆 \\(\\mathcal{H}_s\\)**。\n    - **响应生成**：在会话 \\(k+1\\) 生成响应时，基于最新摘要 \\(w_k\\)、从 \\(\\mathcal{H}_l\\) 检索的相关观察、当前会话历史 \\(h_{k+1}\\)、人设 \\(p\\) 以及发生在两次会话之间的事件子集 \\(\\  e \\in \\mathcal{G",
    "source_file": "Evaluating Very Long-Term Conversational Memory of LLM Agents.md"
}