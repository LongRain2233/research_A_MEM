{
    "title": "AGENT KB: LEVERAGING CROSS-DOMAIN EXPERIENCE FOR AGENTIC PROBLEM SOLVING",
    "background_and_problem": "**§1 领域背景与研究动机（150字以上）**\n本文研究领域为**AI智能体（AI Agent）**，特别是多智能体框架的**跨框架知识共享**问题。当前，以smolagents、OpenHands、OWL为代表的智能体框架在解决复杂推理和工具使用任务上取得了显著进展，但它们各自为政，形成了**知识孤岛**。每个框架内的智能体都在重复解决相似的问题、重复犯同样的错误，导致宝贵的**问题解决经验**无法在异构框架之间传递和复用。这种碎片化阻碍了**集体智能（Collective Intelligence）** 的涌现。本文旨在解决的核心应用场景是**跨异构智能体框架的通用、无需重训练的经验共享**，其动机在于构建一个统一的记忆层，使不同架构的智能体能够相互学习，避免重复劳动，加速整个生态系统的能力进化。\n\n**§2 现有技术的核心短板——具体失败模式（250字以上）**\n现有方法主要分为两类，均无法实现跨框架知识共享：\n1.  **单智能体记忆系统**：如A-Mem (Xu et al., 2025)、MemoryBank (Zhong et al., 2024)。这些系统专注于**强化单个智能体的内部记忆**，但记忆存储是分离的，无法共享。当智能体A在框架X中解决了问题P，智能体B在框架Y中遇到相同问题时，无法利用A的经验，必须从头开始。\n2.  **框架特定的演示合成**：如Learn-by-Interact (Su et al., 2025)、Templating pipelines (Tan et al., 2025)。这些方法虽然能在**单一框架内**通过检索或模板复用经验，但由于其经验表示（如轨迹编码、抽象方式）与特定框架的工具集、API和推理协议深度绑定，导致**无法移植到其他框架**。例如，一个为smolagents设计的PDB文件解析工作流，因其依赖smolagents特定的原子操作，无法直接用于OWL框架。\n3.  **知识干扰问题**：即使能够检索到外部经验，**简单注入**（naive injection）会破坏智能体自身的推理流，产生不连贯的计划或导致错误累积。例如，当从SWE-Agent检索到一个代码修复模式并直接应用于OpenHands时，由于工具API不匹配，可能生成无效或破坏性的代码更改。\n\n**§3 问题的根本难点与挑战（200字以上）**\n实现跨框架知识共享面临三个根本性挑战：\n1.  **表示异构性（Representation Heterogeneity）**：不同框架以**不兼容的方式**组织、编码和抽象经验。例如，smolagents可能将经验表示为一系列工具调用序列，而OWL可能使用分层状态机。这种根本性的差异使得经验无法直接转移或复用。\n2.  **上下文不匹配（Context Mismatch）**：在一个工具生态系统中有效的解决方案，移植到另一个系统时可能**无效或不完整**。这源于可用API、推理协议或执行环境的差异。例如，一个依赖特定网络浏览工具的经验，在另一个禁用网络访问的框架（如SWE-bench环境）中完全失效。\n3.  **知识干扰（Knowledge Interference）**：外部经验的**盲目注入**会**破坏智能体自身推理的稳定性**，产生不连贯的计划或错误叠加。这是因为不同框架生成的计划在逻辑结构、步骤粒度上存在差异，强行融合会导致逻辑冲突。\n\n**§4 本文的切入点与核心假设（200字以上）**\n本文的突破口在于提出了一个**框架无关的经验抽象层**和**选择性集成机制**。其核心假设是：尽管智能体框架在实现上异构，但它们的**问题解决模式（Problem-Solving Patterns）** 可以在更高层次上被抽象和标准化。具体而言，作者假设：\n1.  通过**少量人工引导的抽象**（10-15个示例）和**标准化的动作词汇表**，可以将异构的执行轨迹转化为统一的、结构化的经验单元（Experience Unit）。\n2.  通过一个**两阶段的混合检索（Hybrid Retrieval）** 系统（规划阶段+反馈阶段）和一个**分歧门控（Disagreement Gate）** 机制，可以安全、有效地将外部经验适配到当前框架的上下文中，避免知识干扰。\n该假设的理论依据源于**案例推理（Case-Based Reasoning, CBR）** 和**信息检索**理论，但本文将其重构为一个适用于LLM智能体的 **“Reason-Retrieve-Refine”循环**，并特别强调了跨框架兼容性。",
    "core_architecture": "**§1 系统整体架构概览（200字以上）**\nAGENT KB是一个**插件式、无需训练**的跨框架知识库基础设施。系统整体数据流如下：\n1.  **输入**：来自异构智能体框架（如smolagents, OWL, SWE-Agent, OpenHands）的**原始执行轨迹（Raw Execution Traces）**，包括成功和失败的运行记录。\n2.  **构造阶段（Construction）**：轨迹通过**人工引导的抽象（Few-shot Prompting）** 被转化为结构化经验单元 \\(E = \\langle \\pi, \\gamma, S, \\mathcal{C} \\rangle\\)，并索引到AGENT KB中。\n3.  **演化阶段（Evolution）**：知识库通过**添加（Addition）、去重（Deduplication）、驱逐（Eviction）** 策略动态增长和更新，维护一个高质量、跨领域的经验集合。\n4.  **解决问题阶段（Solving Tasks）**：当智能体遇到新任务时，触发两阶段**Reason-Retrieve-Refine循环**：\n    -   **规划阶段（Planning Stage）**：输入任务描述 → Reason模块分析需求 → Retrieve模块从KB中检索相关经验 → Refine模块将经验适配为可执行计划 → 输出计划给原生框架执行。\n    -   **反馈阶段（Feedback Stage）**：输入初始执行的错误/反馈 → Reason模块分析失败原因 → Retrieve模块检索针对类似错误的修正经验 → Refine模块生成修正方案 → 通过**分歧门控（Disagreement Gate）** 检查一致性 → 输出修正后的计划。\n5.  **输出**：增强后的、可在原生框架中执行的**行动计划**。\n\n**§2 各核心模块深度拆解（每个模块100字以上，共至少3个模块）**\n#### 模块一：经验表示与抽象（Experience Representation & Abstraction）\n-   **输入**：原始智能体执行日志（JSON格式的轨迹），包含动作序列、观察、推理步骤和最终结果。\n-   **核心处理逻辑**：使用**少量提示（10-15个人工标注示例/领域）** 和**跨框架标准化的动作词汇表**，引导LLM（如GPT-4）将轨迹抽象为结构化四元组 \\(E = \\langle \\pi, \\gamma, S, \\mathcal{C} \\rangle\\)。其中：\n    -   \\(\\pi\\)：任务嵌入（使用all-MiniLM-L6-v2编码）。\n    -   \\(\\gamma\\)：目标约束的结构化谓词。\n    -   \\(S = \\{ (a_i, r_i) \\}\\)：动作-推理对序列。\n    -   \\(\\mathcal{C}\\)：跨框架兼容性元数据（如工具映射表）。\n-   **输出**：标准化的**结构化经验单元**，用于后续索引和检索。\n-   **设计理由**：采用人工引导的抽象而非完全自动化，是为了确保经验的质量和跨框架的可移植性。标准化表示是解决“表示异构性”挑战的关键。\n\n#### 模块二：混合检索管道（Hybrid Retrieval Pipeline）\n-   **输入**：查询（在规划阶段是任务描述，在反馈阶段是执行错误模式）。\n-   **核心处理逻辑**：采用**两阶段过滤**：\n    1.  **词法检索（Lexical Retrieval）**：使用BM25算法，基于领域/工具兼容性快速筛选候选经验。\n    2.  **语义排序（Semantic Ranking）**：使用all-MiniLM-L6-v2嵌入计算查询与经验任务嵌入\\(\\pi\\)的余弦相似度。\n    3.  **混合融合**：对两个分数进行校准融合，公式为 \\(\\sigma_i^{\\mathrm{hyb}} \\leftarrow \\alpha \\cdot \\tilde{\\sigma}_i^{\\text{text}} + (1 - \\alpha) \\cdot \\tilde{\\sigma}_i^{\\text{sem}}, \\quad \\alpha \\in [0, 1]\\)，默认 \\(\\alpha = 0.5\\)。\n    4.  **重排序与去重**：对Top-\\(k\\)（默认\\(k=3\\)）候选进行去重后输出。\n-   **输出**：Top-\\(k\\)个最相关的结构化经验单元。\n-   **设计理由**：混合检索结合了BM25的**精确匹配**优势和语义检索的**概念相似性**覆盖，以应对不同框架可能需要的精确工具匹配或抽象模式匹配，这是解决“上下文不匹配”的关键。\n\n#### 模块三：分歧门控（Disagreement Gate）\n-   **输入**：原始计划\\(\\rho\\)和经过Refine模块修正后的新计划\\(\\rho^{\\prime}\\)。\n-   **核心处理逻辑**：计算两个计划嵌入的余弦相似度，并与阈值\\(\\beta\\)比较。公式为：\n    \\(\\mathcal{G}(\\rho, \\rho^{\\prime}) = \\mathbb{1} \\big[ \\cos \\big(\\phi(\\rho), \\phi(\\rho^{\\prime}) \\big) \\geq \\beta \\big]\\)\n    其中，\\(\\phi\\)是使用all-MiniLM-L6-v2的嵌入函数，默认阈值\\(\\beta = 0.8\\)。仅当\\(\\mathcal{G} = 1\\)（即相似度≥0.8）时，修正后的计划才会被应用。\n-   **输出**：布尔值，指示是否采纳修正计划。\n-   **设计理由**：该机制是解决“知识干扰”挑战的核心。它防止检索到的外部经验产生**过于激进或不连贯**的修改，从而破坏智能体自身推理的稳定性，确保集成过程的安全性和一致性。\n\n**§3 关键公式与算法（如有）**\n1.  **经验表示**：\\(E = \\langle \\pi , \\gamma , S, \\mathcal {C} \\rangle\\)\n2.  **混合检索分数融合**：\\(\\sigma_ {i} ^ {\\mathrm {h y b}} \\leftarrow \\alpha \\cdot \\tilde {\\sigma} _ {i} ^ {\\text {t e x t}} + (1 - \\alpha) \\cdot \\tilde {\\sigma} _ {i} ^ {\\text {s e m}}, \\quad \\alpha \\in [ 0, 1 ]\\)\n3.  **分歧门控函数**：\\(\\mathcal {G} (\\rho , \\rho^ {\\prime}) = \\mathbb {1} \\big [ \\cos \\big (\\phi (\\rho), \\phi (\\rho^ {\\prime}) \\big ) \\geq \\beta \\big ]\\)\n4.  **经验效用更新（用于内存驱逐）**：\\(u _ { j } \\gets u _ { j } + \\eta \\big ( r _ { j } - { u } _ { j } \\big )\\)，其中\\(r_j\\)是奖励信号（如检索成功或执行收益），\\(\\eta\\)是学习率。\n\n**§4 方法变体对比（如有多个变体/消融组件）**\n论文进行了系统的消融实验，对比了以下变体与完整AGENT KB（smolagents + AGENT KB）的性能差异：\n-   **w/o Planning Step**：移除规划阶段的Reason-Retrieve-Refine循环。\n-   **w/o Feedback Step**：移除反馈阶段的Reason-Retrieve-Refine循环。\n-   **w/o Reason Module**：移除Reason步骤，直接使用原始查询进行检索。\n-   **w/o Retrieve Module**：移除Retrieve步骤，不进行任何经验检索。\n-   **w/o Refine Module**：移除Refine步骤，直接复用检索到的原始工作流。\n-   **w/ Raw Workflow**：使用原始的、未抽象的工作流日志代替结构化的经验单元。\n\n**§5 与已有方法的核心技术差异（200字以上）**\n本文方法与代表性相关工作在技术实现上的本质区别如下：\n1.  **与A-Mem (Xu et al., 2025)等单智能体记忆系统相比**：A-Mem专注于**单个智能体内部**的记忆增强和检索，其记忆存储与特定智能体实例绑定。AGENT KB则构建了一个**全局共享的、框架无关的知识库**，任何接入的智能体框架都可以贡献和消费经验，实现了真正的跨框架知识转移。\n2.  **与Learn-by-Interact (Su et al., 2025)等框架特定演示合成方法相比**：这些方法生成的演示或模板**深度依赖原框架的工具集和API**，无法迁移。AGENT KB通过**框架无关的经验抽象**和**元数据\\(\\mathcal{C}\\)** 来实现跨框架兼容，在Refine步骤中进行工具映射和步骤重排序。\n3.  **与传统的案例推理（CBR）系统相比**：经典CBR遵循Retrieve–Reuse–Revise–Retain循环。AGENT KB将其重构为**Reason-Retrieve-Refine循环**，并特别加入了**分歧门控机制**，以应对LLM智能体场景中因框架异构性导致的**知识干扰**风险，这是传统CBR未专门处理的问题。",
    "methodology_and_formulas": "**§1 完整算法流程（伪代码级描述）**\n**AGENT KB 增强的智能体执行流程（针对一个新任务）**：\nStep 1: **任务输入**。智能体框架接收用户查询 \\(q\\)。\nStep 2: **规划阶段 - Reason**。分析\\(q\\)，提取关键需求、潜在挑战，生成结构化的检索查询\\(q_{plan}\\)，目标为寻找可复用的子流程或成功完成模式。\nStep 3: **规划阶段 - Retrieve**。使用混合检索管道（BM25 + 语义相似度，\\(\\alpha=0.5\\)）从AGENT KB中检索Top-\\(k\\)（默认\\(k=3\\)）个相关经验\\(\\{E_1, ..., E_k\\}\\)。\nStep 4: **规划阶段 - Refine**。将检索到的经验\\(E_i\\)适配到当前框架：利用元数据\\(\\mathcal{C}\\)进行实体映射、工具替换、步骤重排序，生成一个可执行的初步计划\\(\\rho\\)。如果检索到多个经验，则进行合成。\nStep 5: **原生执行**。将计划\\(\\rho\\)交给底层智能体框架在其原生环境中执行，产生初始结果和可能的错误/反馈信号\\(f\\)。\nStep 6: **反馈阶段 - Reason**。分析执行轨迹和反馈\\(f\\)，识别错误类型、瓶颈或意外结果，生成针对错误修正的检索查询\\(q_{feedback}\\)。\nStep 7: **反馈阶段 - Retrieve**。使用\\(q_{feedback}\\)从AGENT KB中检索Top-\\(k\\)个包含成功修正案例的经验。\nStep 8: **反馈阶段 - Refine**。将检索到的修正经验适配到当前执行上下文，生成修正后的计划\\(\\rho^{\\prime}\\)。\nStep 9: **分歧门控检查**。计算\\(\\cos(\\phi(\\rho), \\phi(\\rho^{\\prime}))\\)。如果相似度 \\(\\geq \\beta\\)（默认\\(\\beta=0.8\\)），则采纳\\(\\rho^{\\prime}\\)；否则，保留原始计划\\(\\rho\\)。\nStep 10: **最终输出**。执行通过门控检查的最终计划，输出结果。\nStep 11: **经验回写（可选）**。将本次成功或失败的执行轨迹抽象为新的经验单元\\(E_{new}\\)，通过去重检查（与现有经验最大余弦相似度> \\(\\tau=0.8\\)则触发LLM质量排名）后，添加到AGENT KB中。\n\n**§2 关键超参数与配置**\n-   **检索Top-\\(k\\)**：默认\\(k=3\\)。通过实验（图5b）确定，在GAIA Level 1任务上达到峰值性能（83.0%），在软件工程任务上保持有效。\n-   **混合检索权重\\(\\alpha\\)**：默认\\(\\alpha=0.5\\)，平衡词法（BM25）和语义（嵌入）相似度。\n-   **分歧门控阈值\\(\\beta\\)**：默认\\(\\beta=0.8\\)。图5a显示，阈值在0.8附近时，反馈集成的收益最大。\n-   **经验去重阈值\\(\\tau\\)**：默认\\(\\tau=0.8\\)。当新经验与现有经验的最大余弦相似度超过此值时，触发LLM排名器进行质量比较，保留更优者。\n-   **效用学习率\\(\\eta\\)**：用于经验效用更新公式\\(u_j \\gets u_j + \\eta (r_j - u_j)\\)，具体数值原文未提供，但用于动态内存驱逐策略。\n-   **温度系数（Temperature）**：在所有实验中被固定为1.0。\n-   **基础模型**：在主实验中固定为GPT-4.1，以控制变量。\n\n**§3 训练/微调设置（如有）**\nAGENT KB是**无需训练（Training-Free）** 的。其知识库通过以下方式构建：\n1.  **种子轨迹（Seed Trajectories）**：由5名计算机科学研究生手工编写80条种子轨迹（60条BrowseComp/HopRAG风格的浏览轨迹，20条SWE-Gym风格的编码日志）。\n2.  **自动扩展（Automatic Rollouts）**：使用smolagents、OWL、SWE-Agent、OpenHands等框架在多个数据集（BrowseComp, HopRAG, HLE2, WebWalkerQA, RepoClassBench, SWE-Gym-Raw, RepoEval）上执行自动 rollout，生成成功和失败的运行记录。\n3.  **经验抽象**：使用**少量提示（10-15个手工标注示例/领域）** 引导LLM（如GPT-4）将上述轨迹抽象为结构化经验单元。\n4.  **最终规模**：在评估前，AGENT KB包含了大约**9k个工作流摘要**和**7k个执行片段**。\n\n**§4 推理阶段的工程细节**\n-   **集成方式**：通过**轻量级RPC调用**将同一个AGENT KB实例附加到所有规划器（planner）上，确保在一个框架中收集的经验立即可用于其他框架。\n-   **检索后端**：使用BM25进行词法检索，使用sentence-transformers的all-MiniLM-L6-v2模型进行语义嵌入和相似度计算。\n-   **并行化**：原文未明确说明，但鉴于其轻量级API设计，可推测检索和推理步骤可以并行处理多个查询。\n-   **缓存机制**：原文未提供具体缓存策略细节。\n-   **向量数据库**：未指定具体向量数据库产品，但使用了余弦相似度进行语义检索，暗示可能使用了FAISS、Chroma等库或自定义索引。\n-   **延迟与内存开销**：如图4所示，AGENT KB在扩展知识库大小时，保持了与A-Mem、MemoryBank等基线可比的检索延迟和内存占用。",
    "experimental_design": "**§1 数据集详情（每个数据集单独列出）**\n1.  **GAIA (Mialon et al., 2023)**\n    -   **规模**：165个任务。\n    -   **细分**：53个Level 1（事实查找），86个Level 2（多步推理），26个Level 3（分析与综合）。\n    -   **领域/类型**：通用推理任务，需要网络浏览、文件I/O和工具使用。\n    -   **评测指标**：pass@1, pass@2, pass@3准确率。\n2.  **Humanity’s Last Exam (HLE) Bio/Chem子集 (Skarlinski et al., 2025)**\n    -   **规模**：149个任务。\n    -   **领域/类型**：生物和化学领域的科学推理，涉及科学图像和多模态工具。\n    -   **评测指标**：pass@1, pass@2, pass@3准确率。\n3.  **GPQA (Rein et al., 2024)**\n    -   **规模**：198道多项选择题。\n    -   **领域/类型**：物理、化学、生物领域的博士水平问答，**纯推理任务，不使用外部工具**。\n    -   **评测指标**：准确率（Accuracy）。\n4.  **SWE-bench Lite (Jimenez et al., 2023)**\n    -   **规模**：300个GitHub issue，来自Python仓库。\n    -   **领域/类型**：软件工程，代码修复任务。限制网络访问，操作仅限于仓库内。\n    -   **评测指标**：在最大迭代次数为50和100下的成功率（Success Rate）。\n    -   **预算限制**：假设OpenAI定价（提示令牌$1.36/M，完成令牌$5.44/M）估算预算上限。\n\n**§2 评估指标体系（全量列出）**\n-   **准确性指标**：\n    -   **pass@k准确率**：在k次尝试中至少成功一次的概率。用于GAIA、HLE、SWE-bench（报告pass@1, pass@2, pass@3）。\n    -   **成功率（Success Rate）**：在给定最大迭代次数（50或100）内成功解决任务的比例。用于SWE-bench Lite。\n    -   **准确率（Accuracy）**：正确回答问题的比例。用于GPQA。\n-   **效率/部署指标**：\n    -   **检索延迟（Retrieval Latency）**：如图4所示，对比了AGENT KB与基线在不同知识库大小下的查找延迟。\n    -   **内存占用（Memory Footprint）**：如图4所示，对比了不同知识库大小下的内存占用。\n    -   **预算成本（Budget Cost）**：基于OpenAI定价估算的API调用成本（见附录D）。例如，SWE-Agent (GPT-4.1) 预算上限为$3.0，OpenHands (GPT-4.1) 为$4.5。\n-   **错误分析指标**：将错误手动分类为6类：检索错误、规划错误、推理错误、格式错误、感知错误、执行错误，并统计各类错误数量。\n\n**§3 对比基线（完整枚举）**\n1.  **GAIA基准上的基线**：\n    -   **Search-o1-32B (Li et al., 2025a)**：开源智能体模型，使用Qwen-3。\n    -   **WebThinker-32B-RL (Li et al., 2025b)**：开源智能体模型，使用Qwen-3。\n    -   **TraseAgent (Trase, 2024)**：闭源框架，使用Claude-3.5。\n    -   **Deep Research (OpenAI, 2024)**：闭源框架，模型未知。\n    -   **h2oGPTe (H2O.ai, 2024)**：闭源框架，使用Claude-3.5。\n    -   **Desearch (AI, 2024)**：闭源框架，使用GPT-4o。\n    -   **Alita (Qiu et al., 2025)**：闭源框架，使用Claude-3.7。\n    -   **OWL (Hu et al., 2025)**：开源框架，使用o3-mini。\n    -   **TapeAgents (Bahdanau et al., 2024)**：开源框架，使用Claude-3.7。\n    -   **AutoAgent (Tang et al., 2025)**：开源框架，使用Claude-3.5。\n    -   **Magnetic-1 (Fourney et al., 2024)**：开源框架，使用o1。\n    -   **FRIDAY (Wu et al., 2024b)**：开源框架，使用GPT-4 turbo。\n    -   **smolagents (Roucher et al., 2025)**：开源框架，使用GPT-4o/GPT-4.1/Claude-3.7。\n    -   **A-MEM (Xu et al., 2025)**：单智能体记忆增强方法，作为smolagents的增强变体进行比较。\n2.  **SWE-bench Lite上的基线**：\n    -   **SWE-agent (Yang et al., 2024)**：开源框架，使用GPT-4.1。\n    -   **OpenHands (Wang et al., 2024a)**：开源框架，使用GPT-4.1/Claude-3.7。\n3.  **HLE上的基线**：\n    -   **AutoGen (Wu et al., 2024a)**：多智能体框架。\n    -   **SciMaster (Chai et al., 2025)**：科学智能体。\n    -   **Biomni (Huang et al., 2025a)**：生物医学智能体。\n4.  **GPQA上的基线**：\n    -   **Direct Reasoning**：直接使用o3-mini、Claude-3.7、GPT-4.1进行推理（无智能体框架）。\n    -   **OpenHands (Wang et al., 2024a)**：开源框架，使用GPT-4.1。\n\n**§4 实验控制变量与消融设计**\n-   **控制变量**：在所有主实验中，**固定基础模型为GPT-4.1**，**温度固定为1.0**，**检索Top-k固定为3**，以进行公平比较。\n-   **消融设计**：系统性地移除AGENT KB的各个组件，以评估其贡献：\n    1.  **移除规划阶段**：评估规划阶段（检索工作流）的必要性。\n    2.  **移除反馈阶段**：评估反馈阶段（检索修正）的必要性。\n    3.  **移除Reason模块**：评估结构化查询生成的作用。\n    4.  **移除Retrieve模块**：评估知识检索本身的作用。\n    5.  **移除Refine模块**：评估经验适配（而非直接复用）的重要性。\n    6.  **使用原始工作流**：对比结构化经验与原始日志的性能差异。\n-   **超参数消融**：对分歧门控阈值\\(\\beta\\)（图5a）和检索Top-\\(k\\)（图5b）进行消融，以确定最优值。\n-   **知识库规模影响**：测试不同知识库大小（100, 500, 完整规模）对性能的影响（图5c）。\n-   **知识来源对比**：对比自动构建的经验与手工标注经验（HAND CRAFTED）的性能（表4）。",
    "core_results": "**§1 主实验结果全景（表格式呈现）**\n**GAIA (val set) - smolagents (GPT-4.1)**\n`方法 | 平均准确率 | Level 1 | Level 2 | Level 3`\n`smolagents (基线) | 55.15% | 67.92% | 53.49% | 34.62%`\n`smolagents +AGENT KB (pass@1) | 61.21% (+6.06pp) | 79.25% (+11.33pp) | 58.14% (+4.65pp) | 34.62% (+0.00pp)`\n`smolagents +AGENT KB (pass@2) | 67.27% (+12.12pp) | 83.02% (+15.10pp) | 67.44% (+13.95pp) | 34.62% (+0.00pp)`\n`smolagents +AGENT KB (pass@3) | 73.94% (+18.79pp) | 84.91% (+16.99pp) | 73.26% (+19.77pp) | 53.85% (+19.23pp)`\n\n**GAIA - smolagents (Claude-3.7)**\n`方法 | 平均准确率 | Level 1 | Level 2 | Level 3`\n`smolagents (基线) | 58.79% | 64.15% | 61.63% | 38.46%`\n`smolagents +AGENT KB (pass@1) | 65.45% (+6.66pp) | 75.47% (+11.32pp) | 66.28% (+4.65pp) | 38.46% (+0.00pp)`\n`smolagents +AGENT KB (pass@2) | 69.70% (+10.91pp) | 79.25% (+15.10pp) | 69.77% (+8.14pp) | 50.00% (+11.54pp)`\n`smolagents +AGENT KB (pass@3) | 75.15% (+16.36pp) | 84.91% (+20.76pp) | 74.42% (+12.79pp) | 57.69% (+19.23pp)`\n\n**GAIA - OWL (GPT-4o)**\n`方法 | 平均准确率 | Level 1 | Level 2 | Level 3`\n`OWL (基线) | 43.64% | 52.83% | 41.86% | 30.77%`\n`OWL +AGENT KB (pass@1) | 52.73% (+9.09pp) | 64.15% (+11.32pp) | 54.65% (+12.79pp) | 23.08% (-7.69pp)`\n`OWL +AGENT KB (pass@2) | 60.61% (+16.97pp) | 75.47% (+22.64pp) | 61.63% (+19.77pp) | 26.92% (-3.85pp)`\n`OWL +AGENT KB (pass@3) | 63.64% (+20.00pp) | 79.25% (+26.42pp) | 61.63% (+19.77pp) | 38.46% (+7.69pp)`\n\n**SWE-bench Lite (Max Iter 50) - OpenHands (GPT-4.1)**\n`方法 | 成功率 (Iter 50)`\n`OpenHands (基线) | 24.33%`\n`OpenHands +AGENT KB (pass#1) | 28.33% (+4.00pp)`\n`OpenHands +AGENT KB (pass#2) | 37.33% (+13.00pp)`\n`OpenHands +AGENT KB (pass#3) | 38.67% (+14.34pp)`\n\n**SWE-bench Lite (Max Iter 100) - OpenHands (Claude-3.7)**\n`方法 | 成功率 (Iter 100)`\n`OpenHands (基线) | 41.33%`\n`OpenHands +AGENT KB (pass#1) | 48.33% (+7.00pp)`\n`OpenHands +AGENT KB (pass#2) | 51.67% (+10.34pp)`\n`OpenHands +AGENT KB (pass#3) | 53.33% (+12.00pp)`\n\n**HLE (Bio/Chem) - OpenHands (GPT-4.1)**\n`方法 | 准确率`\n`AutoGen | 7.4%`\n`SciMaster | 9.5%`\n`Biomni | 10.7%`\n`OpenHands (基线) | 9.5%`\n`OpenHands +AGENT KB (pass@1) | 10.1% (+0.6pp)`\n`OpenHands +AGENT KB (pass@2) | 12.1% (+2.6pp)`\n`OpenHands +AGENT KB (pass@3) | 14.1% (+4.6pp)`\n\n**GPQA - OpenHands (GPT-4.1)**\n`方法 | 准确率`\n`Direct Reasoning (o3-mini) | 75.0%`\n`Direct Reasoning (Claude-3.7) | 67.4%`\n`Direct Reasoning (GPT-4.1) | 64.6%`\n`OpenHands (基线) | 62.6%`\n`OpenHands +AGENT KB (pass@1) | 67.2% (+4.6pp)`\n`OpenHands +AGENT KB (pass@2) | 70.7% (+8.1pp)`\n`OpenHands +AGENT KB (pass@3) | 72.7% (+10.1pp)`\n\n**§2 分任务/分场景深度分析（每个维度100字以上）**\n-   **GAIA - 难度分级**：在**Level 2（多步推理）** 任务上提升最大（smolagents+GPT-4.1从53.49%提升至73.26%，+19.77pp），这表明AGENT KB对于需要复杂规划和多步工具调用的任务特别有效。在**Level 3（分析与综合）** 任务上，Claude-3.7获得了最大绝对提升（从38.46%到57.69%，+19.23pp），说明更强的模型能更好地利用跨领域经验解决开放性问题。**Level 1（事实查找）** 提升相对较小但依然显著，表明即使对于简单任务，经验也能提供更高效的搜索策略。\n-   **SWE-bench Lite - 迭代次数**：在最大迭代次数为**100**时，OpenHands+Claude-3.7达到了最高的绝对成功率53.33%，且提升幅度（+12.00pp）高于GPT-4.1版本（+14.34pp at Iter 50，但基线更低）。这表明Claude-3.7在更长的执行窗口中能更好地利用AGENT KB提供的修正经验。\n-   **跨领域知识转移的不对称性**（图6）：**软件工程（SWE）经验**在SWE-bench上表现最佳（42.3%成功率），但迁移到GAIA时性能下降至56.4%。相反，**通用推理经验**在GAIA上表现最佳（73.9%准确率），迁移到SWE-bench仍有37.0%成功率。这表明推理经验具有更好的**泛化性**，而SWE经验更**专业化**，跨领域迁移效果有限。\n-   **模型家族对比**：**Claude-3.7**在多个基准上表现出最大的性能提升潜力（如SWE-bench Lite +21.0pp at Iter 50），而**GPT-4.1**在GAIA Level 2上提升显著。**GPT-4o**在OWL框架上也获得了稳定提升。这表明AGENT KB能**互补不同模型的长处**，例如Claude-3.7在推理鲁棒性上受益更多，GPT-4.1在感知对齐上受益更多。\n\n**§3 效率与开销的定量对比**\n-   **检索延迟**：如图4所示，AGENT KB在不同知识库大小下的检索延迟与A-Mem、MemoryBank、ReadAgent等基线**处于同一水平**，表明其混合检索管道没有引入显著的额外延迟开销。\n-   **内存占用**：如图4所示，AGENT KB的内存占用随知识库规模增长，但与同类系统相比**没有显著增加**。\n-   **预算成本**：实验在固定预算上限下进行（SWE-Agent $3.0, OpenHands $4.5）。AGENT KB在**不增加额外API成本**的情况下（通过共享经验减少重复试错），实现了性能提升。\n-   **Token消耗**：原文未提供具体Token消耗对比数据。\n\n**§4 消融实验结果详解**\n（基于表3，smolagents+GPT-4.1在GAIA上的结果）\n-   **完整AGENT KB**：平均准确率61.21%。\n-   **移除Refine模块**：性能下降最大，至55.15%（-6.06pp）。Level 3从34.62%降至30.77%（-3.85pp）。这证明**直接复用检索到的原始工作流是低效的**，必须进行适配。\n-   **移除Retrieve模块**：降至57.58%（-3.63pp）。Level 1从79.25%降至73.58%（-5.67pp）。这表明**知识检索本身是性能增益的主要来源**。\n-   **移除Reason模块**：降至60.00%（-1.21pp）。影响较小，说明结构化查询生成有一定帮助，但非绝对必要。\n-   **移除Planning Step**：降至59.39%（-1.82pp）。Level 1从79.25%降至75.47%（-3.78pp）。\n-   **移除Feedback Step**：降至59.39%（-1.82pp）。Level 1从79.25%降至73.58%（-5.67pp）。\n-   **使用原始工作流**：降至58.18%（-3.03pp）。证明**结构化经验抽象**比原始日志更有效。\n\n**§5 案例分析/定性分析（如有）**\n-   **成功案例（图1）**：在蛋白质距离计算任务中，基线智能体盲目读取PDB文件的前两行（可能是溶剂记录），错误报告O-H距离（0.961 Å）。AGENT KB增强的智能体应用了经验驱动的规则：过滤掉所有ANISOU/HETATM行，仅按文件顺序使用真正的ATOM条目，并与已知的N-CA键长范围进行合理性检查，从而正确提取了骨架N-CA对并报告了正确距离（1.456 Å）。\n-   **错误分析（图7）**：对GPT-4.1，AGENT KB将**检索错误**从24个减少到20个，**规划错误**从13个减少到10个。对Claude-3.7，**推理错误**从13个减少到8个，**检索错误**从19个减少到16个。这表明AGENT KB通过提供经过验证的搜索协议、规划模板和格式约定，帮助智能体减少了即兴发挥导致的错误。\n-   **失败案例**：尽管错误总数减少，但AGENT KB也引入了**新的错误**（GPT-4.1: 15个，Claude-3.7: 11个）。这些新错误可能源于**检索到的不相关或低质量经验**，或**Refine过程中的错误适配**。感知错误（依赖于工具能力）和格式错误（输出模式违反）的减少幅度较小，表明这些错误类型更难以通过经验共享来纠正。",
    "conclusion_and_future_work": "**§1 本文核心贡献总结**\n1.  **首个跨框架即插即用知识库**：提出了AGENT KB，一个无需重训练或架构修改即可与四个代表性开源智能体框架（smolagents, OWL, SWE-Agent, OpenHands）集成的通用记忆层，实现了**真正的跨框架知识共享**。\n2.  **分歧门控机制**：引入了一种新颖的**分歧门控（Disagreement Gate）** 机制，有效解决了跨框架知识转移中的**知识干扰**关键挑战，确保了外部经验集成的稳定性和安全性。\n3.  **两阶段混合检索系统**：开发了一个结合**规划引导**和**反馈驱动修正**的两阶段检索系统，同时保持了框架兼容性，在多个基准上实现了**一致的性能提升**（如GAIA上+18.7pp，SWE-bench上+14.4pp）。\n4.  **经验抽象与自动构建**：证明了通过少量人工引导的抽象，**自动构建的经验**在性能上可以媲美甚至在某些困难任务上**超越手工标注的经验**（如GAIA Level 3，57.69% vs. 53.85%），为可扩展的集体智能提供了路径。\n\n**§2 局限性（作者自述）**\n原文中作者**未明确列出局限性**。基于实验设计和结论部分，可以推断出以下隐含局限性：\n1.  **模态限制**：当前工作主要集中于文本和代码任务，未涉及**多模态（如图像、音频）** 或**具身（Embodied）** 智能体场景。\n2.  **任务范围**：实验仅在四个基准（GAIA, HLE, GPQA, SWE-bench）上进行，涵盖通用推理和软件工程，但未测试更**开放域、创造性或长视界规划**任务。\n3.  **经验质量依赖**：知识库的初始构建依赖于**少量人工种子**和**特定数据集的自动rollout**，其质量和覆盖范围可能影响泛化能力。\n4.  **计算开销**：虽然延迟和内存开销可控，但**检索和Refine步骤**仍会增加每次推理的延迟，对于实时性要求极高的应用可能构成挑战。\n\n**§3 未来研究方向（全量提取）**\n原文在结论中仅提到一句未来方向：“...with future work aimed at richer modalities and longer-horizon reasoning.” 据此可推导出：\n1.  **支持更丰富的模态**：将AGENT KB扩展到支持图像、视频、音频等多模态输入的经验表示和检索，以服务于视觉问答、机器人操作等场景。\n2.  **处理更长视界的推理**：探索如何存储和复用涉及**多轮对话、复杂决策序列、长期目标追踪**的跨会话经验，以解决更复杂的规划问题。\n3.  **知识库的持续学习与演化**：研究更高效的经验去重、质量评估和淘汰策略，以应对知识库规模无限增长带来的管理和检索挑战。\n4.  **理论分析**：对跨框架知识转移的有效性条件、知识干扰的数学形式化以及分歧门控的理论保证进行更深入的分析。",
    "research_contributions": "**§1 核心学术贡献（按重要性排序）**\n1.  **提出了首个跨框架智能体经验共享基础设施**：\n    -   **理论新颖性**：首次系统性地定义并解决了智能体领域的“知识孤岛”问题，提出了“框架无关的经验抽象”这一核心概念，为构建集体智能体智能奠定了基础。\n    -   **实验验证充分性**：在四个异构基准、多个智能体框架和模型家族上进行了全面验证，证明了方法的普遍有效性和稳健性。\n    -   **对领域的影响**：为智能体社区提供了一个可复用的开源组件，可能推动智能体系统从孤立进化走向协同进化。\n2.  **设计了分歧门控机制以解决知识干扰**：\n    -   **理论新颖性**：明确识别并形式化了跨框架知识转移中的“知识干扰”问题，并提出了一个基于相似度阈值的简单而有效的解决方案。\n    -   **实验验证充分性**：通过消融实验（图5a）验证了该机制的有效性，并确定了最优阈值。\n    -   **对领域的影响**：为安全地集成外部知识提供了一个通用模式，可被其他需要知识融合的研究借鉴。\n3.  **证明了自动构建的经验可与人工标注经验媲美**：\n    -   **理论新颖性**：挑战了高质量经验必须依赖大量人工标注的传统观念，展示了少量引导下自动化流程的潜力。\n    -   **实验验证充分性**：通过对比实验（表4）显示，自动经验在GAIA Level 3任务上甚至超越了手工经验。\n    -   **对领域的影响**：大幅降低了构建大规模共享记忆库的工程成本，使该方法更具可扩展性。\n\n**§2 工程与实践贡献**\n-   **开源实现**：提供了完整的代码和脚本（https://github.com/OPPO-PersonalAI/Agent-KB），确保研究的可复现性。\n-   **轻量级API设计**：通过REST端点实现与异构框架的集成，无需修改框架底层代码，降低了部署门槛。\n-   **系统化的评测基准**：在GAIA、HLE、GPQA、SWE-bench上建立了跨框架知识转移有效性的首个系统研究，为后续研究设立了基线。\n\n**§3 与相关工作的定位**\n本文位于**智能体记忆（Agentic Memory）** 和**经验复用（Experience Reuse）** 研究路线的交叉点。它不同于专注于单智能体内部记忆增强的A-Mem，也不同于局限于特定框架内演示合成的Learn-by-Interact。AGENT KB开辟了一条**新的技术路线**：构建一个**全局的、框架无关的、可演化的共享记忆层**，作为所有智能体框架的“公共知识库”。它是对现有案例推理（CBR）和检索增强生成（RAG）范式的扩展，特别针对LLM智能体的异构性和知识干扰问题进行了定制化设计。",
    "professor_critique": "**§1 实验设计与评估体系的缺陷**\n1.  **Baseline选择的全面性不足**：虽然对比了多个开源和闭源框架，但**未与最新的、专门针对跨任务知识迁移的方法进行对比**，例如一些基于强化学习或元学习的经验复用方法。这削弱了AGENT KB在“跨框架”这一核心主张上的说服力。\n2.  **评估指标存在“指标幸运”风险**：主要依赖pass@k准确率和成功率。这些指标**未能捕捉到任务解决的效率**（如步骤数、Token消耗）和**计划质量**（如可读性、可解释性）。在SWE-bench中，更高的成功率可能源于AGENT KB提供了更“投机取巧”的代码片段，而非真正的理解。\n3.  **数据集覆盖的局限性**：所有测试数据集（GAIA, HLE, GPQA, SWE-bench）均属于**相对结构化的、有明确答案的封闭领域任务**。未在**开放域对话、创造性写作、复杂多模态交互**等更贴近现实应用的场景中进行测试，其泛化能力存疑。\n\n**§2 方法论的理论漏洞或工程局限**\n1.  **经验抽象过程的脆弱性**：依赖**10-15个/领域的人工示例**进行Few-shot抽象。当遇到全新领域或工具集时，抽象质量可能急剧下降，导致生成无效或误导性的经验表示。这本质上是将泛化能力**外包给了黑盒的LLM**，缺乏理论保证。\n2.  **知识库规模扩展的潜在瓶颈**：当前知识库规模约16k条目（9k摘要+7k片段）。当规模扩展到百万级别时，**混合检索的精度和延迟**可能成为瓶颈。论文中的延迟测试规模有限，未进行极端压力测试。\n3.  **分歧门控阈值的启发式选择**：阈值\\(\\beta=0.8\\)是通过实验确定的，但**缺乏理论依据**。对于不同类型的任务或框架，最优阈值可能不同。一个固定的阈值可能过于僵化，导致在某些场景下过度保守（拒绝有益修正）或过于激进（接受有害修正）。\n4.  **跨领域知识转移的不对称性未被深入解释**：图6显示软件工程经验向推理任务迁移效果差，但作者未深入分析其原因。这可能是由于**经验表示的粒度不匹配**或**Refine模块的适配能力有限**，这是一个重要的未解问题。\n\n**§3 未经验证的边界场景**\n1.  **多语言混合输入**：当前经验抽象和检索基于英文。当任务描述或工具API包含中文、代码注释混合其他语言时，检索和适配机制可能失效。\n2.  **领域外知识冲突**：当AGENT KB中存储的经验与智能体自身知识或当前上下文**存在冲突**时（例如，过时的API用法 vs 最新文档），系统缺乏冲突检测与消解机制，可能引入错误。\n3.  **对抗性输入或噪声经验注入**：如果恶意用户或有缺陷的智能体向KB中注入了**错误或对抗性的经验**，当前的去重和排名机制（基于LLM质量比较）可能无法完全过滤，导致知识污染和性能下降。\n4.  **实时流式任务**：对于需要极低延迟的流式交互任务（如实时对话），两阶段的检索-Refine循环可能引入不可接受的延迟。\n\n**§4 可复现性与公平性问题**\n1.  **对昂贵API的依赖**：实验大量使用了GPT-4.1、Claude-3.7、GPT-4o等**闭源、高成本的商业模型**。这使得资源有限的研究者难以完全复现所有实验结果，降低了研究的可及性。\n2.  **超参数调优的不对称性**：AGENT KB的关键超参数（如\\(\\beta=0.8, k=3, \\alpha=0.5\\)）都经过了调优以达到最佳性能，但**对比的基线方法是否也经过了同等的、针对每个数据集的超参数优化**？如果基线使用的是默认参数，则对比可能不公平。\n3.  **种子经验的不可复现性**：初始的80条手工种子轨迹由5名CS研究生编写，这部分数据**未公开**。不同的种子可能导致最终知识库质量和性能的差异，影响了严格的可复现性。",
    "zero_compute_opportunity": "#### 蓝图一：探究轻量级嵌入模型对AGENT KB性能与效率的影响\n-   **核心假设**：使用更小、更快的句子嵌入模型（如all-MiniLM-L6-v2的蒸馏版本或MobileBERT）替代默认的all-MiniLM-L6-v2，可以在保持AGENT KB性能基本不变的前提下，显著降低检索延迟和内存占用，使其更适合边缘设备部署。\n-   **与本文的关联**：本文使用all-MiniLM-L6-v2进行语义检索和分歧门控计算，但其开销未被详细分析。本蓝图旨在验证在资源受限场景下，牺牲少量精度换取大幅效率提升的可行性。\n-   **所需资源**：\n    1.  免费嵌入模型：从Hugging Face获取`paraphrase-MiniLM-L3-v2`、`all-mpnet-base-v2`（作为更强基线）、`MobileBERT`。\n    2.  公开数据集：使用GAIA或SWE-bench Lite的公开测试集子集（例如50个样本）。\n    3.  低成本API：使用OpenAI的GPT-3.5-turbo或Claude Haiku作为基础智能体模型，以控制成本（预计API调用费用<$20）。\n    4.  计算资源：个人笔记本电脑（CPU）或免费Colab GPU。\n-   **执行步骤**：\n    1.  复现AGENT KB的核心检索与Refine模块，但将语义嵌入模型替换为上述候选轻量模型。\n    2.  在选定的数据集子集上，使用固定的智能体框架（如smolagents）和基础模型（GPT-3.5-turbo），分别运行原始AGENT KB和轻量嵌入变体。\n    3.  记录并对比：a) 任务成功率/准确率；b) 平均检索延迟（从查询到返回Top-k经验）；c) 嵌入模型的内存占用和加载时间。\n    4.  进行消融实验：分析不同嵌入维度、池化方法对性能的影响。\n-   **预期产出**：一篇短论文或",
    "source_file": "Agent KB Leveraging Cross-Domain Experience for Agentic Problem Solving.md"
}