{
    "title": "MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations",
    "background_and_problem": "**§1 领域背景与研究动机（150字以上）**\n本文研究领域是**大型语言模型（LLM）智能体（Agent）的动态工具调用**。随着LLM Agent能力的增强，它们能够像人类一样动态搜索、发现并集成外部工具或MCP（Model Context Protocol）服务器，突破了初始化时固定工具集的限制。然而，在**多轮对话（Multi-Turn Conversations）** 场景中，LLM Agent需要反复、独立地使用工具，而模型的**固定上下文窗口（Fixed Context Window）** 成为主要瓶颈。当前，LLM Agent被越来越多地嵌入到基于会话（如聊天、语音、视频）的应用中，如何高效管理其有限的上下文窗口，以支持持续的多轮交互，成为一个亟待解决的关键工程问题。本文的动机正是在于填补LLM Agent在**动态工具检索**场景下，如何管理其**短期工具记忆（Short-Term Tool Memory）** 的研究空白。\n\n**§2 现有技术的核心短板——具体失败模式（250字以上）**\n现有方法主要分为两类，均在多轮动态工具检索场景中存在具体失败模式：\n1.  **对话记忆管理方法**：如**总结（Summarization）** 和**截断（Truncation）** 技术（Wu et al., 2025b; Breunig, 2025）。这些方法主要针对**用户与助手之间的对话消息**进行压缩。**失败模式**：当输入是多轮动态工具调用任务时，这些方法**完全不处理Agent上下文窗口中工具（Tools）或MCP服务器的动态检索与管理**，导致工具数量在会话中持续累积，最终超出API调用限制（如128-512个工具），引发错误或性能下降。\n2.  **动态工具检索方法**：如基于**检索增强生成（RAG）** 的工具检索系统（Lumer et al., 2025c; Chen et al., 2024）和**Agentic RAG框架**（Singh et al., 2025; Li et al., 2023）。这些方法能够动态地将相关工具注入Agent的上下文窗口。**失败模式**：当输入是**超过100轮（100+）的连续用户查询会话**时，现有方法**只关注工具的添加，而缺乏对已添加但不再相关工具的移除和管理机制**。这导致工具列表不断膨胀，占用宝贵的上下文空间，并可能引入无关工具的干扰。\n3.  **长期记忆与个性化工具使用方法**（Zhang et al., 2025; Hao et al., 2025; Cheng et al., 2025）。这些工作关注跨会话的**工具使用偏好**。**失败模式**：它们**不解决单一会话内（Short-Term）的工具记忆管理问题**，无法应对单次长时间对话中工具上下文的动态变化需求。\n\n**§3 问题的根本难点与挑战（200字以上）**\n该问题的根本难点源于LLM Agent的**固有架构限制**与**任务复杂性**之间的冲突：\n1.  **上下文窗口的硬性限制**：主流LLM API对单次请求可携带的工具数量有严格上限（128-512个）。在多轮对话中，如果不移除过时工具，工具数量会线性增长，迅速触及此上限，导致后续请求失败。\n2.  **Agent自主决策的不可预测性**：赋予Agent自主管理工具（添加/移除）的能力，要求模型具备**高级推理和规划能力**。然而，现有研究表明，许多模型（特别是中小型模型）在**同时执行用户任务和进行上下文管理**时表现不佳，它们倾向于专注于回答用户问题而“忘记”移除无关工具。\n3.  **评估的复杂性**：衡量短期工具记忆管理的有效性需要设计新的评估指标，如**工具移除率（Removal Ratio）** 和**平均残余工具数（Average Residual）**，这些指标需要跟踪整个多轮会话的动态变化，评估成本高且复杂。\n\n**§4 本文的切入点与核心假设（200字以上）**\n本文的切入点是**将短期工具记忆管理视为一个独立的、可优化的系统组件**，而非依赖LLM Agent自身的隐式能力。其核心假设是：**通过设计不同的架构模式（Autonomous/Workflow/Hybrid），在工具管理的“自主性（Autonomy）”与“确定性（Determinism）”之间进行权衡，可以适应不同能力水平的LLM模型，并实现高效的多轮工具上下文管理。**\n具体来说，作者观察到：\n1.  **某些强大的推理模型（如GPT-o3, Gemini 2.5 Pro）有能力自主管理工具上下文**，但中小型模型则表现糟糕。\n2.  **将工具移除（Pruning）步骤抽象为一个独立的、确定性的LLM调用**，可以强制所有模型保持精简的工具上下文，但牺牲了Agent在回答问题时动态重新搜索工具的能力。\n3.  **混合模式（Hybrid Mode）** 结合了两者的优点：用确定性步骤处理困难的“移除”任务，同时保留Agent自主“搜索添加”工具的灵活性。\n本文的假设基于一个工程观察：**工具“移除”比“添加”对模型能力的要求更高**，因此可以通过架构设计来弥补模型能力的不足。",
    "core_architecture": "**§1 系统整体架构概览（200字以上）**\nMemTool系统整体上是一个**包裹在LLM Agent外部的短期记忆管理框架**。其输入是**用户查询（User Query）**、**先前的对话消息（Prior Messages）** 和**先前的工具集（Prior Tool Set）**。核心是一个**工具知识库（VectorDB）**，存储了5000个MCP服务器的描述。系统提供三种运行模式，每种模式定义了不同的数据流：\n- **Autonomous Agent Mode**：用户查询 → LLM Agent（配备`Search_Tools`和`Remove_Tools`两个工具）→ Agent自主决定调用`Remove_Tools`移除无关工具或调用`Search_Tools`添加新工具 → 使用更新后的工具集回答用户问题 → 输出最终答案，并将更新后的消息和工具集持久化到下一轮。\n- **Workflow Mode**：用户查询 → 独立的`LLM_prune`调用（输入：当前消息和工具集，输出：待移除工具列表）→ 从工具集中移除指定工具 → 独立的`LLM_search`调用（输入：用户查询，输出：搜索关键词）→ 使用关键词在VectorDB中检索Top-K个新工具并添加 → LLM Agent（仅使用最终工具集）进入循环回答用户问题 → 输出最终答案。\n- **Hybrid Mode**：用户查询 → 独立的`LLM_prune`调用移除无关工具（与Workflow Mode相同）→ LLM Agent（仅配备`Search_Tools`工具）进入循环 → Agent可自主调用`Search_Tools`添加工具并使用它们回答问题 → 输出最终答案。\n所有模式共享一个**历史管理器（History Manager）**，用于在每轮开始前对先前的对话消息进行**截断（TRUNCATEHISTORY）** 或**总结（SUMMARIZEHISTORY）**，以控制对话token的消耗。\n\n**§2 各核心模块深度拆解（每个模块100字以上，共至少3个模块）**\n#### 模块一：LLM_prune（工具修剪模块）\n- **模块名**：`LLM_prune`\n- **输入**：当前轮次的**对话消息（messages）** 和**当前可用的工具集（T）**。\n- **核心处理逻辑**：这是一个独立的LLM调用（非Agent循环内）。系统提示词（原文未提供具体内容，但根据上下文推断）指示该LLM**仅根据当前用户查询和对话历史，判断当前工具集中哪些工具已不再相关**。LLM输出一个待移除的工具名称列表`R`。**关键超参数**：无特定超参数，其行为完全由提示词控制。\n- **输出**：一个待移除的工具名称列表`R`。\n- **设计理由**：将“判断工具相关性”这一认知负担较高的任务从主Agent中剥离出来，交由一个专门的、提示词优化的LLM调用完成。这确保了**工具移除行为的确定性和可靠性**，尤其适用于那些在自主模式下不擅长移除工具的中小型模型。\n\n#### 模块二：Search_Tools（工具搜索模块）\n- **模块名**：`Search_Tools`\n- **输入**：由LLM Agent（在Autonomous/Hybrid模式中）或`LLM_search`（在Workflow模式中）生成的**关键词列表（Keywords: List[str]）**。\n- **核心处理逻辑**：使用输入的关键词，在**向量数据库（VectorDB）** 中进行语义/词汇搜索，返回与查询最相关的Top-K个工具。**关键超参数**：`top-k = 5`，即每次搜索返回最多5个工具。\n- **输出**：一个工具子集`S`，将被添加到Agent的当前工具集中。\n- **设计理由**：基于**检索增强生成（RAG）** 的思想，避免将全部5000个工具一次性加载到上下文窗口中，而是动态检索最相关的子集。这突破了LLM API对工具数量的硬性限制（`L=128`），并减少了无关工具带来的噪声。\n\n#### 模块三：历史管理器（History Manager）\n- **模块名**：`H` (属于 {TRUNCATEHISTORY, SUMMARIZEHISTORY})\n- **输入**：先前的对话消息列表`msgs_prev`。\n- **核心处理逻辑**：在每轮对话开始前，对历史消息进行处理，以防止对话token累积超出模型上下文窗口。提供两种策略：1) **TRUNCATEHISTORY**：直接截断最早的消息。2) **SUMMARIZEHISTORY**：使用一个LLM对历史消息进行总结，用总结文本替代原始长消息。\n- **输出**：处理后的（截断或总结后的）对话消息列表，将与当前用户查询拼接，作为本轮LLM调用的输入。\n- **设计理由**：管理**对话工作记忆（Working Memory）** 的token消耗，这是短期记忆管理的另一个重要维度。MemTool专注于工具记忆，但对话记忆的管理也是确保系统长期运行的必要组件。\n\n**§3 关键公式与算法（如有）**\n论文定义了三个核心评估指标公式：\n1.  **移除率（Removal Ratio）**：衡量在整个会话中成功移除的工具比例。\n   \\( \\text{Removal Ratio} = \\frac{\\sum_{t=1}^{T} R_{t}}{\\sum_{t=1}^{T} A_{t}} \\leq 1 \\)\n   其中，\\(R_t\\)是第t轮移除的工具数，\\(A_t\\)是第t轮添加的工具数。\n2.  **3轮平均移除率（Avg Removal Ratio 3T）**：使用滑动窗口平滑移除行为，反映模型在短期窗口内的记忆管理效率。\n   \\( \\text{Avg Removal Ratio}_{3T} = \\frac{1}{T-2} \\sum_{t=3}^{T} \\frac{\\sum_{i=t-2}^{t} R_{i}}{\\sum_{i=t-2}^{t} A_{i}} \\)\n3.  **3轮后平均残余工具数（Avg Residual 3T）**：衡量工具添加峰值后，经过3轮对话仍残留在上下文中的工具数量，反映工具累积行为。\n   \\( \\text{Avg Residual}_{3T} = \\frac{1}{K} \\sum_{k=1}^{K} \\left(\\frac{1}{3} \\sum_{i=1}^{3} T_{, p_{k} + i}\\right) \\)\n   其中，\\(p_k\\)是第k个工具添加峰值出现的轮次，\\(T_{, p_k + i}\\)是峰值后第i轮的工具数量。\n\n**§4 方法变体对比（如有多个变体/消融组件）**\n本文提出了三种核心模式变体，其差异在于工具管理的“自主性”与“确定性”的分配：\n1.  **Autonomous Agent Mode（完全自主模式）**：Agent拥有`Search_Tools`和`Remove_Tools`两个工具，可完全自主决定何时添加、何时移除。**优势**：灵活性高，可在回答过程中动态重新搜索工具。**劣势**：对模型能力要求极高，中小型模型表现差。\n2.  **Workflow Mode（工作流模式）**：Agent**没有任何**工具管理能力。工具移除和添加由两个独立的、确定性的LLM调用（`LLM_prune`和`LLM_search`）在Agent运行前完成。Agent仅使用处理后的固定工具集回答问题。**优势**：确定性高，所有模型都能有效管理工具数量，成本可控。**劣势**：Agent一旦开始运行，无法再检索新工具，缺乏自我纠正能力。\n3.  **Hybrid Mode（混合模式）**：工具移除由独立的`LLM_prune`调用（确定性）完成，工具添加则由配备了`Search_Tools`的Agent自主完成。**优势**：平衡了可靠性和灵活性，既保证了工具的有效移除，又允许Agent在需要时动态扩展工具集。**劣势**：如果Agent添加过多工具，仍可能触发工具数量上限错误。\n\n**§5 与已有方法的核心技术差异（200字以上）**\n本文方法与已有代表性工作的核心技术差异在于：\n1.  **与对话记忆管理方法（如Summarization/Truncation）的差异**：现有方法（Wu et al., 2025b; Breunig, 2025）**压缩的是对话消息（Messages）**，而MemTool**管理的是工具上下文（Tool Context）**。这是两个正交但互补的维度。MemTool首次系统性地研究并评估了在多轮对话中动态工具上下文的生命周期管理。\n2.  **与动态工具检索RAG方法（如Lumer et al., 2025d; Chen et al., 2024）的差异**：现有RAG-for-Tools方法主要解决**单轮查询下的工具检索问题**，即“如何为当前问题找到最相关的工具”。MemTool在此基础上，增加了**跨轮次工具状态管理**的维度，解决了“如何清理上一轮已不再相关的工具”的问题。MemTool的Workflow Mode可以看作是这些RAG方法的**多轮会话扩展**，增加了`LLM_prune`步骤。\n3.  **与Agentic RAG框架（如Singh et al., 2025）的差异**：这些框架赋予Agent搜索工具的能力，但**缺乏对工具移除的显式支持和评估**。MemTool不仅提供了移除工具的能力（通过`Remove_Tools`函数或`LLM_prune`），更重要的是**提出了三种架构模式来系统化地管理这一过程**，并提供了**定量评估指标（Avg Removal Ratio 3T, Avg Residual 3T）** 来衡量管理效果。",
    "methodology_and_formulas": "**§1 完整算法流程（伪代码级描述）**\n论文提供了三个算法的伪代码（Algorithm 1, 2, 3），分别对应三种模式。以下是**Autonomous Agent Mode**的完整流程还原：\n**Step 1**：输入LLM模型、用户查询`q`、先前消息`msgs_prev`、先前工具集`T_prev`、向量数据库`V`、top-k参数`k=5`、工具上限`L=128`、历史管理器`H`。\n**Step 2**：使用历史管理器处理先前消息：`messages ← H(msgs_prev) + q`。\n**Step 3**：初始化当前工具集：`T ← T_prev ∪ {Search_Tools(keywords: List[str]), Remove_Tools(tool_names: List[str])}`。将搜索和移除工具作为基础工具赋予Agent。\n**Step 4**：进入主循环`while true`：\n    - **Step 4.1**：调用LLM，输入`messages`和当前工具集`T`，得到回复`reply`。\n    - **Step 4.2**：判断`reply.type`：\n        - **如果`reply.type == tool_call`（工具调用）**：\n            - **Case `Remove_Tools`**：提取参数`R`（待移除工具列表），从`T`中移除这些工具（但保留`Search_Tools`和`Remove_Tools`自身）。\n            - **Case `Search_Tools`**：提取参数`Q`（搜索关键词列表），在向量数据库`V`中搜索Top-5相关工具得到`S`，将`S`加入`T`。如果`|T| ≥ L`（达到128上限），则抛出错误并提示Agent移除工具。\n            - **Otherwise（其他工具调用）**：执行该工具，得到`result`。\n            - 将`(reply_tool, result)`附加到`messages`中。\n        - **否则（非工具调用，即最终答案）**：将`reply`附加到`messages`，并将`reply.content`作为最终答案`a`返回，循环结束。\n**Step 5**：返回最终答案`a`。\n\n**§2 关键超参数与配置**\n- **`top-k = 5`**：每次调用`Search_Tools`或`VectorSearch`时，从知识库中返回的最相关工具数量。作者选择5是基于ScaleMCP基准数据集中平均每轮5.0个工具调用的统计结果（Lumer et al., 2025b），旨在匹配典型需求。\n- **`tool-limit L = 128`**：LLM API单次请求允许的最大工具数量。此值被设定为**所有测试模型（包括支持256-512工具的Gemini和Claude）的统一上限**，以确保实验的公平性和标准化。当工具集大小达到此限制时，系统会抛出错误提示Agent移除工具。\n- **历史管理器策略 `H ∈ {TRUNCATEHISTORY, SUMMARIZEHISTORY}`**：用于控制对话历史token消耗的策略选择。论文未说明具体选择哪种策略进行实验，但将其作为可配置组件。\n- **嵌入模型**：使用**Azure OpenAI的text-embedding-ada-002**。选择理由：ScaleMCP基准已广泛测试了5种嵌入模型、3种重排序模型和5种检索器类型，发现不同嵌入模型之间差异极小，因此选用此标准模型。\n\n**§3 训练/微调设置（如有）**\n本文**未进行任何模型训练或微调**。作者明确强调其采用**即插即用（Plug-and-Play）** 的方法论，与现成的商业LLM（OpenAI, Google, Anthropic, Meta）和标准嵌入解决方案兼容。所有实验均使用这些模型的API进行零样本（Zero-Shot）评估。\n\n**§4 推理阶段的工程细节**\n- **并行化策略**：原文未提及。\n- **缓存机制**：原文未提及。\n- **向量数据库选型**：使用**向量数据库（VectorDB）** 存储5000个MCP服务器的工具描述，用于语义检索。具体向量数据库产品未指明。\n- **错误处理**：当工具数量达到上限`L=128`时，系统会**抛出错误（Raise Error）**，并提示Agent移除工具。这是一个关键的工程设计，用于强制模型进行工具管理。\n- **系统提示词优化**：实验发现，在系统提示词中**动态包含当前工具数量（`len(T)`）** 对提高工具移除率至关重要。当不包含此信息时，LLM Agent无法感知其上下文窗口中的工具数量，导致移除失败。",
    "experimental_design": "**§1 数据集详情（每个数据集单独列出）**\n- **数据集名称**：ScaleMCP Benchmark（Lumer et al., 2025b）。\n- **规模**：包含**5000个工具或MCP服务器**。\n- **领域类型**：通用工具调用，覆盖多种API和功能。\n- **评测问题类型**：多轮动态工具调用对话。从数据集中**分层抽样（Stratified Sample）** 了**100个实例**，用于构建100轮的多轮工具使用对话。抽样依据是**每轮的工具调用数量**。\n- **特殊数据标准**：ScaleMCP数据集的平均工具调用数为**每轮5.0个**，这影响了实验设计中`top-k=5`的参数选择。\n\n**§2 评估指标体系（全量列出）**\n#### 准确性指标\n1.  **任务完成度（Task Completion）**：使用**LLM-as-a-Judge**方法评估。具体计算方式：\\( \\text{Task Completion} = \\text{Alignment}(\\text{Task}, \\text{Output}) \\)。使用**OpenAI GPT-4o mini**作为评判模型，比较Agent的最终回复与基准数据集中预期答案的对齐程度。\n2.  **工具正确性（Tool Correctness）**：评估工具调用的准确性。计算方式：\\( \\text{Tool Correctness} = \\frac{\\text{Num. Correct Calls}}{\\text{Total Calls}} \\)。同样使用Confident AI的评估框架进行对比。\n#### 效率/部署指标（短期记忆管理效率）\n1.  **移除率（Removal Ratio）**：定义见公式(1)，衡量整个会话中移除工具数与添加工具数的比例。\n2.  **3轮平均移除率（Avg Removal Ratio 3T）**：定义见公式(2)，使用滑动窗口平滑后的移除率，是论文的核心指标。\n3.  **3轮后平均残余工具数（Avg Residual 3T）**：定义见公式(3)，衡量工具添加峰值后残留的工具数量，反映工具累积情况。\n4.  **工具数量动态图**：绘制每轮对话后Agent上下文窗口中的工具数量变化曲线，直观展示管理效果（见图2,3,4）。\n#### 其他自定义指标\n- **工具数量上限触及情况**：记录模型是否在100轮对话中触及了128的工具上限，并因此触发错误。\n\n**§3 对比基线（完整枚举）**\n本文没有设置传统的、独立的Baseline系统进行对比。**其对比是在三种MemTool模式（Autonomous, Workflow, Hybrid）之间，以及在不同LLM模型（共13个）在同一模式下的表现之间进行的。** 这13个模型构成了事实上的Baseline集合，用于评估不同模型在相同架构下的能力差异。模型列表如下：\n- **推理能力强的闭源模型**：GPT-o3, Gemini 2.5 Pro, Gemini 2.5 Flash, Claude Opus 4, Claude Sonnet 4, GPT-4.1, GPT-4.1 Mini, GPT-4o, Claude 3.5 Sonnet, GPT-4.1 Nano。\n- **开源模型**：LLaMA 3 70B。\n**代表性**：这些模型覆盖了当前主流的商业和开源LLM，在工具调用能力上具有代表性，其性能差异可以揭示模型能力对短期记忆管理的影响。\n\n**§4 实验控制变量与消融设计**\n- **控制变量**：\n    1.  **数据集**：所有实验使用相同的ScaleMCP数据集和100个实例的抽样。\n    2.  **嵌入模型**：统一使用text-embedding-ada-002。\n    3.  **工具数量上限**：统一设置为`L=128`。\n    4.  **检索Top-K**：统一设置为`k=5`。\n    5.  **评估指标与评判模型**：统一使用GPT-4o mini作为LLM-as-a-Judge。\n- **消融设计**：\n    论文的核心消融实验体现在**三种模式的对比**上，这本质上是对“自主性”程度的消融：\n    1.  **Autonomous Mode**：消融了确定性的工具移除步骤，完全依赖模型自主性。\n    2.  **Workflow Mode**：消融了模型在回答问题时的工具搜索自主性，完全依赖确定性流程。\n    3.  **Hybrid Mode**：消融了模型自主移除工具的能力，但保留了自主搜索工具的能力。\n    此外，文中提到了一个关键的**提示词消融**：发现**在系统提示词中包含当前工具数量动态变量**对Autonomous Agent Mode的性能有显著影响，当不包含时工具移除率极低。",
    "core_results": "**§1 主实验结果全景（表格式呈现）**\n论文主结果表格（Table 1）的完整还原如下（数值为原文表格中的小数，代表比例或数量）：\n`模式 | LLM模型 | Avg Removal Ratio 3T | Avg Residual 3T | Tool Correctness | Task Completion`\n`Autonomous Agent | GPT-o3 | 0.941 | 7.44 | 0.75 | 0.90`\n`Autonomous Agent | Gemini 2.5 Pro | 0.924 | 6.51 | 0.81 | 0.80`\n`Autonomous Agent | Gemini 2.5 Flash | 0.905 | 5.08 | 0.74 | 0.65`\n`Autonomous Agent | Claude Opus 4 | 0.878 | 13.85 | 0.86 | 0.84`\n`Autonomous Agent | Claude Sonnet 4 | 0.840 | 24.44 | 0.80 | 0.83`\n`Autonomous Agent | GPT-4.1 | 0.834 | 48.12 | 0.86 | 0.88`\n`Autonomous Agent | GPT-4.1 Mini | 0.733 | 58.93 | 0.78 | 0.80`\n`Autonomous Agent | GPT-4o | 0.713 | 37.48 | 0.68 | 0.76`\n`Autonomous Agent | LLaMA 3 70B | 0.244 | 123.33 | 0.42 | 0.72`\n`Autonomous Agent | Claude 3.5 Sonnet | 0.062 | 124.00 | 0.38 | 0.59`\n`Autonomous Agent | GPT-4.1 Nano | 0.000 | 0.00 | 0.13 | 0.60`\n`Workflow | GPT-4o | 0.938 | 7.19 | 0.71 | 0.70`\n`Workflow | GPT-4.1 | 0.934 | 7.48 | 0.82 | 0.83`\n`Workflow | LLaMA 3 70B | 0.932 | 8.64 | 0.51 | 0.71`\n`Workflow | Gemini 2.5 Pro | 0.929 | 6.90 | 0.69 | 0.66`\n`Workflow | Gemini 2.5 Flash | 0.928 | 6.60 | 0.50 | 0.60`\n`Workflow | GPT-o3 | 0.925 | 7.59 | 0.88 | 0.84`\n`Workflow | GPT-4.1 Mini | 0.922 | 7.72 | 0.72 | 0.81`\n`Workflow | Claude 3.5 Sonnet | 0.917 | 7.83 | 0.82 | 0.82`\n`Workflow | Claude Opus 4 | 0.917 | 7.92 | 0.71 | 0.78`\n`Workflow | Claude Sonnet 4 | 0.917 | 8.00 | 0.77 | 0.81`\n`Workflow | GPT-4.1 Nano | 0.904 | 8.96 | 0.64 | 0.66`\n`Hybrid | GPT-4o | 0.943 | 7.15 | 0.77 | 0.76`\n`Hybrid | GPT-4.1 | 0.941 | 7.29 | 0.82 | 0.80`\n`Hybrid | LLaMA 3 70B | 0.938 | 7.52 | 0.60 | 0.76`\n`Hybrid | Gemini 2.5 Pro | 0.938 | 6.52 | 0.74 | 0.75`\n`Hybrid | Claude 3.5 Sonnet | 0.935 | 7.32 | 0.81 | 0.83`\n`Hybrid | GPT-o3 | 0.932 | 9.33 | 0.82 | 0.87`\n`Hybrid | Gemini 2.5 Flash | 0.932 | 6.15 | 0.59 | 0.66`\n`Hybrid | GPT-4.1 Mini | 0.929 | 7.26 | 0.81 | 0.79`\n`Hybrid | Claude Opus 4 | 0.920 | 10.46 | 0.82 | 0.81`\n`Hybrid | Claude Sonnet 4 | 0.912 | 10.27 | 0.82 | 0.81`\n`Hybrid | GPT-4.1 Nano | 0.869 | 6.94 | 0.48 | 0.63`\n\n**§2 分任务/分场景深度分析（每个维度100字以上）**\n#### 按模式分析：\n- **Autonomous Agent Mode（自主模式）**：**性能两极分化严重**。顶级推理模型（GPT-o3, Gemini 2.5 Pro/Flash, Claude Opus 4）的3轮平均移除率高达**87.8% - 94.1%**，任务完成度也高（**80% - 90%**）。然而，中小型模型（GPT-4.1 Mini, GPT-4o, LLaMA 3 70B, Claude 3.5 Sonnet, GPT-4.1 Nano）的移除率暴跌至**0% - 73.3%**，工具累积严重（Avg Residual 3T高达**37.48 - 124.00**），甚至触及128上限。这表明**完全自主的模式高度依赖模型本身的强大推理和规划能力**。\n- **Workflow Mode（工作流模式）**：**性能高度一致且优秀**。所有13个模型的3轮平均移除率都集中在**90.4% - 93.8%** 的狭窄区间内，平均残余工具数也稳定在**6.60 - 8.96**的低水平。这表明**确定性架构有效抹平了模型能力的差异**，即使是最弱的GPT-4.1 Nano也能达到90.4%的移除率。然而，任务完成度和工具正确性指标仍存在差异，反映了模型在**工具使用推理**上的能力差别。\n- **Hybrid Mode（混合模式）**：**在保持高移除率的同时，恢复了部分自主性**。所有模型的移除率依然很高（**86.9% - 94.3%**），且任务完成度相对于Workflow模式有轻微提升或保持。例如，GPT-o3在Hybrid模式下的任务完成度为0.87，高于Workflow模式的0.84。这表明将困难的“移除”任务外包后，Agent可以更专注于利用自主搜索能力来完成任务。\n\n**§3 效率与开销的定量对比**\n论文**未提供传统的效率指标**（如延迟、Token消耗、显存占用）的定量对比。其“效率”主要体现在**短期记忆管理效率**上，通过以下指标定量对比：\n- **工具移除效率**：在Autonomous模式下，顶级模型（如GPT-o3）的移除率（94.1%）远高于中小型模型（如Claude 3.5 Sonnet的6.2%），**绝对差距高达87.9个百分点**。\n- **工具累积控制**：在Autonomous模式下，表现差的模型（LLaMA 3 70B, Claude 3.5 Sonnet）在20轮内工具数量就**触及或接近128的上限**（见图2），而Workflow和Hybrid模式下所有模型的工具数量都**稳定维持在远低于128的水平**（见图3,4）。\n- **与基线（不同模式）对比**：对于同一个模型（如GPT-4.1），从Autonomous模式切换到Workflow模式，其Avg Removal Ratio 3T从**0.834提升至0.934**，提升幅度为**12.0%**；Avg Residual 3T从**48.12大幅下降至7.48**，下降了**84.5%**。这证明了确定性架构在控制工具累积方面的巨大优势。\n\n**§4 消融实验结果详解**\n论文的核心消融实验即三种模式的对比，结果已在上文分析。此外，文中提及了一个关键的**提示词消融实验**：\n- **消融组件**：在Autonomous Agent Mode的**系统提示词中移除“当前工具数量”动态变量**。\n- **影响**：导致LLM Agent**完全无法有效移除工具**，移除率极低。作者发现，当系统提示不包含当前工具计数时，LLM无法感知其上下文窗口中有多少工具，因此“忘记”移除。**加入此动态变量后，顶级模型的移除率从接近0%提升到90%以上**。这凸显了**环境状态感知**对自主工具管理的关键作用。\n\n**§5 案例分析/定性分析（如有）**\n论文通过图表（Figure 2, 3, 4）展示了典型成功与失败案例：\n- **成功案例（Autonomous Mode下的GPT-o3, Gemini 2.5 Pro）**：工具数量曲线呈现**“尖峰-快速下降”模式**。每当因回答查询而添加一批工具后，在后续轮次中能迅速移除大部分无关工具，使工具数量回落到低基线水平（约5-10个）。这体现了模型优秀的**短期工作记忆清理能力**。\n- **失败案例（Autonomous Mode下的LLaMA 3 70B, Claude 3.5 Sonnet）**：工具数量曲线呈现**“阶梯式上升”或“高位震荡”模式**。模型添加工具后很少移除，导致工具数量在20轮内**飙升至128上限**并触发错误。这表明这些模型**缺乏同时进行任务推理和上下文管理的多任务处理能力**，或者其系统提示词未能有效引导移除行为。\n- **一致性案例（所有模型在Workflow/Hybrid模式下）**：工具数量曲线**始终保持平稳且低位运行**，没有出现剧烈的累积现象。这证明了**架构设计对性能的决定性影响**，能够补偿模型能力的不足。",
    "conclusion_and_future_work": "**§1 本文核心贡献总结**\n1.  **提出了MemTool框架**：首个专门针对LLM Agent多轮动态工具调用的**短期记忆管理框架**，系统化地解决了工具上下文的添加与移除问题。\n2.  **定义了三种架构模式**：提供了**Autonomous（全自主）、Workflow（确定性）、Hybrid（混合）** 三种模式，在工具管理的“自主性”与“可控性”之间提供了可配置的权衡选项。\n3.  **进行了大规模实证评估**：在**13个以上**的主流LLM上系统评估了三种模式，揭示了**模型能力与架构选择之间的相互作用**：强大推理模型适合Autonomous模式，而Workflow/Hybrid模式能显著提升中小型模型的记忆管理效率。\n4.  **引入了新的评估指标**：提出了**Avg Removal Ratio 3T（3轮平均移除率）** 和**Avg Residual 3T（3轮后平均残余工具数）** 等定量指标，用于衡量短期工具记忆管理的效率。\n5.  **发现了关键工程洞察**：揭示了**在系统提示词中动态包含当前工具数量**对自主模式性能的**关键影响**，为提示工程设计提供了重要指导。\n\n**§2 局限性（作者自述）**\n1.  **Autonomous Agent Mode的可靠性问题**：当使用**非推理模型（Non-Reasoning Models）** 时，该模式在可靠移除工具方面存在困难。\n2.  **Workflow Mode的灵活性限制**：该模式**限制了Agent回溯和探索额外工具的能力**，一旦Agent开始运行，就无法再检索新工具，缺乏自我纠正循环。\n3.  **Hybrid Mode的潜在风险**：如果Agent探索过多工具并**突破预定义的限制（如128）**，可能会引发错误。一种缓解策略是调用专用的修剪LLM，但这可能**无意中移除必要的上下文**。\n4.  **模型选择依赖性**：Workflow和Hybrid模式需要**谨慎选择执行`LLM_prune`步骤的LLM模型**。不同的模型在工具正确性和任务完成度上表现不同。\n\n**§3 未来研究方向（全量提取）**\n1.  **与长期记忆结合**：作者提出MemTool可以与**工具使用的长期记忆（Long-Term Memory）** 方面的进展相结合。这意味着未来工作可以探索如何将短期工具记忆管理与跨会话的用户工具偏好个性化统一起来。\n2.  **更复杂的缓解策略**：针对Hybrid模式中工具过多的问题，作者提到可以探索**调用专用修剪LLM**的策略，但这需要解决可能误删必要上下文的问题。这指向了更精细化的、基于重要性评分的工具保留机制的研究。\n3.  **模式间的动态切换**：作者暗示，随着LLM模型或提示技术的进步，**Hybrid模式可以过渡到Autonomous Agent模式**。未来的系统可能具备根据模型置信度或任务复杂度在模式间动态切换的能力。\n4.  **基于模型优势的混合使用**：作者建议可以根据不同LLM在**工具移除、搜索 vs. 实际工具使用**方面的各自优势，**选择或混合使用不同的LLM**。例如，用低成本模型负责记忆管理（Workflow模式中的`LLM_prune`），用高性能模型负责最终的任务回答。",
    "research_contributions": "**§1 核心学术贡献（按重要性排序）**\n1.  **架构创新与系统化框架**：\n    - **理论新颖性**：首次将LLM Agent的**短期工具记忆管理**作为一个独立的、可系统化优化的研究方向提出，填补了该领域的空白。以往工作或关注对话记忆，或关注单轮工具检索，而未系统研究跨轮次的工具状态管理。\n    - **实验验证充分性**：在包含13个主流LLM的大规模实验上验证了三种架构的有效性，提供了丰富的定量数据（移除率、残余工具数、任务完成度）和定性分析（工具数量变化曲线）。\n    - **对领域的影响**：为构建**可持续运行的多轮工具调用Agent**提供了可直接部署的架构蓝图和模式选择指南，推动了LLM Agent从“单轮任务”向“持续会话”的演进。\n2.  **揭示了模型能力与架构的相互作用**：\n    - **理论新颖性**：实证研究表明，**工具移除（Pruning）比工具添加（Searching）对模型推理能力的要求更高**。这一发现解释了为何中小型模型在自主模式下失败，并为通过架构设计（Workflow/Hybrid）补偿模型短板提供了理论依据。\n    - **实验验证充分性**：通过对比不同模型在三种模式下的性能差异，清晰展示了“强大模型+自主架构”与“普通模型+确定性架构”可以达到相近的记忆管理效果，但任务性能仍有差距。\n    - **对领域的影响**：提醒研究者和工程师不应盲目追求完全自主的Agent，而应根据可用模型的能力选择合适的架构，这对资源受限的部署具有重要实践意义。\n3.  **提出了新的评估范式与指标**：\n    - **理论新颖性**：提出了**Avg Removal Ratio 3T**和**Avg Residual 3T**等指标，专注于衡量**跨轮次的、动态的工具上下文管理效率**，而非单轮的工具调用准确性。\n    - **实验验证充分性**：这些指标成功区分了不同模型和模式在记忆管理上的优劣，并与任务完成度等传统指标形成互补。\n    - **对领域的影响**：为未来研究多轮工具调用Agent的性能提供了新的、更细粒度的评估维度。\n\n**§2 工程与实践贡献**\n1.  **开源代码与算法**：论文提供了三种模式（Autonomous, Workflow, Hybrid）的完整算法伪代码（Algorithm 1,2,3），具备高度的**可复现性和可工程化**。研究者可以据此快速实现MemTool框架。\n2.  **实用的部署指南**：论文为每种模式提供了具体的**使用建议（Recommendations）**，例如在Autonomous模式下应在系统提示中包含动态工具数量、Workflow模式适合成本优先的场景等，这些是基于大量实验得出的经验总结。\n3.  **提示词工程的关键发现**：明确了**动态环境状态信息（当前工具数）** 对自主模式性能的**决定性影响**，这一发现可直接应用于其他需要Agent管理内部状态的场景。\n\n**§3 与相关工作的定位**\n本文在当前LLM Agent技术路线图中，处于**动态工具调用（Dynamic Tool Calling）** 与**Agent记忆管理（Agent Memory Management）** 的交叉点。它并非开辟了一条全新的路线，而是**在已有的动态工具检索RAG路线上，增加了“跨轮次状态管理”这一关键维度**。具体定位如下：\n- 它**延伸了**像ScaleMCP（Lumer et al., 2025b）这样的动态工具检索工作，从单轮检索扩展到多轮会话下的生命周期管理。\n- 它**补充了**像MemGPT、Letta等长期记忆框架，后者关注跨会话的用户偏好记忆，而MemTool关注单次会话内的工具上下文记忆。\n- 它**提供了一种架构解决方案**，以应对像API-Bank（Li et al., 2023）等基准中隐含但未解决的“工具膨胀”问题。因此，MemTool是构建**健壮、可持续多轮工具调用Agent**的必要组件。",
    "professor_critique": "**§1 实验设计与评估体系的缺陷**\n1.  **Baseline对比不充分**：论文仅对比了**不同LLM在MemTool框架下的表现**，而**没有与任何现有的、非MemTool的多轮工具调用系统进行对比**。例如，没有设置一个“Baseline系统”：即一个简单的、每轮都重新从零开始检索工具的RAG Agent（即不保留任何工具记忆）。这样的对比才能证明MemTool管理的“跨轮次工具持久化”是否真的带来了性能提升（如更高的任务完成率、更低的延迟/Token消耗）。当前的实验只能证明不同模式/模型间的相对优劣，无法证明MemTool相对于朴素方法的绝对优势。\n2.  **评估指标存在“幸运”可能**：“3轮平均移除率（Avg Removal Ratio 3T）”指标依赖于滑动窗口，如果模型在某一轮大量添加工具后紧接着大量移除，可能会产生很高的移除率，但这未必代表稳定的记忆管理。需要结合**工具数量的方差（Variance）** 或**最大连续未移除轮次**等指标来更全面地评估稳定性。\n3.  **任务完成度评估可能过于宽松**：使用**GPT-4o mini作为LLM-as-a-Judge**进行评估，其评判标准未详细说明，可能存在主观偏差。应补充**人工评估**或**基于精确匹配（Exact Match）** 的客观指标作为补充。\n\n**§2 方法论的理论漏洞或工程局限**\n1.  **`LLM_prune`模块的脆弱性**：在Workflow和Hybrid模式中，工具移除完全依赖于一个独立的`LLM_prune`调用。如果这个LLM调用**错误地移除了当前或未来轮次仍然需要的工具**，系统将无法恢复，除非重新检索。论文未评估这种“误删”发生的频率及其对任务完成度的负面影响。\n2.  **对系统提示词的强依赖**：Autonomous模式的成功极度依赖精心设计的系统提示词（包含动态工具计数）。这意味着MemTool的鲁棒性**高度受限于提示词工程的质量**，在不同领域或任务表述变化时可能失效。论文未进行提示词鲁棒性（Prompt Robustness）的消融实验。\n3.  **工具表征的局限性**：MemTool仅通过工具名称和描述进行检索和移除决策。在真实场景中，工具的“相关性”可能更复杂，涉及**功能相似性、输入输出格式、调用代价**等。仅基于文本描述的简单检索可能无法做出最优的保留/移除决策。\n\n**§3 未经验证的边界场景**\n1.  **工具功能重叠与冲突**：当知识库中存在**功能高度重叠或相互冲突的工具**时，MemTool的移除逻辑可能失效。例如，两个工具都能完成相似任务，`LLM_prune`可能随机移除一个，但后续查询可能需要被移除的那个。\n2.  **极端长的对话序列（>1000轮）**：实验仅在100轮对话上进行。在**极端长对话**中，即使有高效的移除机制，**对话历史本身的Token管理（History Manager）** 可能成为新的瓶颈。论文未测试TRUNCATE与SUMMARIZE两种策略在长对话下的优劣。\n3.  **工具知识库动态更新**：实验假设工具知识库（5000个MCP服务器）是静态的。在真实生产环境中，工具库可能**频繁增删改**。MemTool框架未考虑如何**增量更新Agent上下文中的工具描述**，或处理已移除工具在新版本中功能发生变化的情况。\n4.  **恶意或对抗性用户查询**：用户可能故意提出**模糊、矛盾或诱导性**的问题，导致Agent频繁添加大量无关工具，或`LLM_prune`错误移除核心工具。论文未测试系统在对抗性输入下的鲁棒性。\n\n**§4 可复现性与公平性问题**\n1.  **依赖昂贵的商业API**：实验评估的13个模型中，12个是闭源的商业API（OpenAI, Google, Anthropic）。这导致**研究复现成本极高**，普通研究者难以负担。虽然包含了一个开源模型（LLaMA 3 70B），但其在Autonomous模式下表现极差，降低了开源替代方案的可信度。\n2.  **超参数调优不对等**：论文为所有模型设定了统一的工具上限`L=128`和检索数量`k=5`。然而，不同模型的API实际支持的工具上限不同（Gemini/Claude支持256-512）。**强制统一到128可能对支持更多工具的商业模型不公平**，限制了其潜在优势的发挥。\n3.  **缺乏计算开销分析**：MemTool引入了额外的LLM调用（`LLM_prune`, `LLM_search`），但论文**完全没有分析这些额外调用带来的延迟增加和Token消耗**。在Workflow模式下，每轮对话需要3次LLM调用（Prune + Search + Agent），其成本是Autonomous模式（1次调用）的三倍。这种效率-效果的权衡未被量化。",
    "zero_compute_opportunity": "#### 蓝图一：探究轻量级模型在MemTool Workflow模式中的成本-性能帕累托前沿\n- **核心假设**：在MemTool Workflow模式下，使用**极低成本/小规模的开源模型**（如Phi-3 Mini, Gemma 2B）作为`LLM_prune`和`LLM_search`模块，配合一个中等性能的模型作为核心Agent，可以在**大幅降低API成本的同时，保持接近顶级商业模型的短期记忆管理效率**。\n- **与本文的关联**：基于本文发现：Workflow模式能抹平模型差异，使所有模型都获得高移除率。但本文未探索用极小模型承担记忆管理任务的可能性。\n- **所需资源**：\n  1.  **免费API/本地模型**：HuggingFace上的开源小模型（如Phi-3-mini, Gemma-2b, Qwen2.5-Coder-1.5B）。\n  2.  **数据集**：ScaleMCP基准的公开子集或自构建的小型工具调用对话数据集（可基于ToolBench或API-Bank简化）。\n  3.  **费用**：零费用（本地推理）或极低的HuggingFace Inference Endpoint费用（< $10）。\n- **执行步骤**：\n  1.  **复现MemTool Workflow模式**：使用论文中的Algorithm 2，但将`LLM_prune`和`LLM_search`的模型替换为目标小模型。\n  2.  **设计提示词**：为小模型精心设计执行“工具相关性判断”和“搜索关键词生成”任务的提示词，可能需要进行少量提示词迭代优化。\n  3.  **基准测试**：在ScaleMCP的100轮对话子集上运行，记录其Avg Removal Ratio 3T、Avg Residual 3T，并与原文中使用GPT-4o等大型模型的结果对比。\n  4.  **成本分析**：计算使用小模型与大模型在API调用次数和Token消耗上的成本差异。\n  5.  **性能-成本曲线**：尝试不同规模的小模型，绘制“记忆管理效率 vs. 模型大小/成本”的帕累托前沿图。\n- **预期产出**：一篇短论文或技术报告，证明**用极小成本模型处理Agent的“家务管理”任务（如记忆管理）是可行的**，并为构建高性价比的多轮Agent系统提供具体配置建议。可投稿到**EMNLP Workshop on Efficient Natural Language Processing**或**ACL System Demonstrations**。\n- **潜在风险**：小模型可能无法准确理解工具描述，导致错误的移除或低质量的搜索关键词。**应对方案**：采用**检索增强**的方式，为小模型提供更详细的工具文档片段；或使用**思维链（CoT）** 提示来提升其推理能力。\n\n#### 蓝图二：基于工具调用图（Tool Call Graph）的增强型记忆管理策略\n- **核心假设**：在MemTool的移除决策中引入**工具调用图分析**，即分析多轮对话中工具之间的**依赖关系**和**共现模式**，可以比单纯的基于当前查询的语义相关性做出更智能的移除/保留决策，从而提升任务完成度并减少误删。\n- **与本文的关联**：本文的`LLM_prune`仅基于当前查询和工具描述进行决策，是“无记忆”的。本蓝图旨在增强其决策的上下文感知能力，解决教授锐评中提到的“误删”风险。\n- **所需资源**：\n  1.  **代码**：基于NetworkX或类似库构建和分析工具调用图。\n  2.  **数据集**：需要包含工具间依赖关系标注的数据集。可以基于ScaleMCP或ToolBench，通过**轻量级启发式规则**（如：在同一会话中，调用工具A后经常调用工具B，则A和B存在依赖）自动构建伪标签。\n  3.  **计算**：仅需CPU进行图分析，零GPU成本。\n- **执行步骤**：\n  1.  **图构建**：在MemTool运行过程中，实时构建一个**工具共现图**，节点是工具，边的权重是它们在历史对话中在同一轮或相邻轮被调用的频率。\n  2.  **增强决策**：在`LLM_prune`步骤中，除了提供工具描述和当前查询外，额外提供**目标工具的图上下文信息**，例如：“工具X与当前会话中已使用的工具Y和Z有强共现关系”。\n  3.  **设计提示词**：让`LLM_prune`在决定移除工具时，不仅考虑语义相关性，也考虑“保留可能具有依赖关系的工具对后续任务更有益”。\n  4.  **对比实验**：在相同的MemTool Hybrid模式下，对比**基础版**与**图增强版**的性能。评估指标：Avg Removal Ratio 3T（确保移除效率不降）、Task Completion（期望提升）、以及**工具误删率**（新定义：被移除但在后续3轮内又被重新添加的工具比例）。\n- **预期产出**：一篇研究短文，提出并验证**基于图结构的工具记忆管理**能提升多轮工具调用Agent的稳定性和任务性能。可投稿到**COLING**或**EACL**等自然语言处理会议。\n- **潜在风险**：图构建可能引入噪声，错误的依赖关系可能误导移除决策。**应对方案**：设置共现频率阈值，并允许`LLM_prune`忽略不可靠的图信号；或采用更保守的策略，仅将图信息作为参考而非强制规则。\n\n#### 蓝图三：MemTool模式选择器的轻量级学习\n- **核心假设**：可以训练一个**轻量级分类器（如逻辑回归、小型Transformer）**，根据**当前会话状态（如历史工具集、查询复杂度、模型类型）**",
    "source_file": "MemTool Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations.md"
}