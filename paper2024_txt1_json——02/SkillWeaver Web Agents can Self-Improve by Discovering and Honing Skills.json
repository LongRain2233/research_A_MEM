{
    "title": "SkillWeaver: Web Agents can Self-Improve by Discovering and Honing Skills",
    "background_and_problem": "**§1 领域背景与研究动机（150字以上）**\n基于大语言模型（LLM）的AI智能体，能够像人类一样浏览网页或操作计算机，已成为AI研究和应用的新前沿。这类智能体旨在自动化复杂的网页交互任务，以提升人类在多样化数字环境中的生产力。然而，网站环境具有固有的复杂性和多样性，包含大量交互元素，构成了巨大的动作空间。一个更严峻的挑战在于开发能够泛化到分布外任务类型并适应全新网站的通用网页智能体。尽管已有工作尝试利用跨多样网站和任务类型收集的大规模轨迹数据来训练智能体，但这些智能体往往容易过拟合到特定的网站结构和任务分布，从而降低了其有效处理未见环境的能力。因此，研究智能体如何像人类一样，通过自主探索和抽象经验来实现自我改进，成为解决这一挑战的关键切入点。\n\n**§2 现有技术的核心短板——具体失败模式（250字以上）**\n现有方法在实现网页智能体自我改进方面存在具体短板：\n1.  **轨迹隐式存储与微调方法（如 Murty et al., 2024a; Su et al., 2025）**：这些方法将技能隐式存储在动作轨迹中，主要用于上下文学习或模型微调。当面对全新的网站结构时，由于缺乏对可复用程序性知识的显式抽象，智能体需要大量的训练数据来适应，导致**训练开销巨大**。同时，持续用新轨迹更新模型会引入**灾难性遗忘**问题，并且对网站的变化**高度敏感**，一旦网站界面更新，已学习的轨迹可能失效。\n2.  **基于自然语言的工作流抽象方法（如 Agent Workflow Memory (Wang et al., 2024e) 和 ICAL (Sarch et al., 2024)）**：这些方法生成了抽象的、可复用的自然语言工作流。然而，当需要将多个工作流精确组合成新流程，或对工作流逻辑进行形式化验证时，自然语言的**模糊性**和**非结构化**特性带来了巨大挑战，难以保证组合后的正确性和鲁棒性。\n3.  **依赖外部监督的在线/离线学习方法**：上述许多方法要么需要访问测试查询进行在线学习，要么需要高质量的人工标注演示进行离线学习。当**缺乏外部监督（即没有预先给定的任务或演示）**时，这些方法无法启动学习过程，智能体不具备自主探索和发现新技能的能力。\n\n**§3 问题的根本难点与挑战（200字以上）**\n实现网页智能体的自主自我改进面临多重根本性挑战：\n- **探索的复杂性**：网站环境状态空间巨大且部分可观测，智能体需要高效地探索以发现潜在功能，而盲目探索的成本极高。\n- **知识的抽象与泛化**：如何从具体的、低级的交互轨迹中，抽象出高级的、可跨任务和网站复用的程序性知识（技能），是一个核心认知挑战。这要求智能体具备归纳和概括能力。\n- **技能的表示与验证**：抽象出的技能需要一种**结构化、可执行、可验证**的表示形式。自然语言描述不够精确，而直接存储原始轨迹则笨重且难以泛化。同时，需要机制来确保合成技能的**正确性和鲁棒性**，避免错误传播。\n- **技能的可组合性与迁移性**：简单的技能应能组合成复杂技能，且技能库应能**在不同能力的智能体之间迁移**，实现知识蒸馏，而无需重新训练模型参数。\n\n**§4 本文的切入点与核心假设（200字以上）**\n本文的突破口在于借鉴人类通过探索、抽象和协作构建不断增长的技能库来实现自我改进的机制，提出一个以**技能为中心**的框架。其核心假设是：**网页交互中的程序性知识可以被有效地抽象、封装为结构化的、可执行的应用程序接口（API），并且通过迭代的探索-实践-提炼循环，可以自主构建一个不断扩展的、轻量级的、即插即用的API库，从而显著提升智能体的能力。** 这一假设的理论依据源于对**程序性记忆**和**分层强化学习**的认知科学启发，即将复杂任务分解为可复用的子程序（技能）。技术实现上，则依赖于大语言模型在代码生成、规划和对网页结构（如HTML、可访问性树）理解方面的强大能力，将其作为自动课程生成器、技能实践执行者和API合成器。",
    "core_architecture": "**§1 系统整体架构概览（200字以上）**\nSKILLWEAVER框架是一个三阶段的流水线，旨在使智能体通过自主探索网站环境来合成可复用的技能（API）。整体数据流如下：\n1.  **输入**：初始网站环境（提供网页截图、网站名称、URL、可访问性树）。\n2.  **Stage I: Skill Proposal（技能提议）**：基于当前环境观察和现有技能库，LLM作为自动课程生成器，提出新的、可复用的技能描述（如“根据印记和颜色识别药丸”）。输出为技能描述列表。\n3.  **Stage II: Skill Synthesis（技能合成）**：对于每个提议的技能，智能体进行实践以生成动作轨迹。使用基于LLM的奖励模型评估轨迹是否成功。若成功，则将轨迹转化为一个可复用的Python函数（API）。输出为合成的API代码。\n4.  **Stage III: Skill Honing（技能打磨）**：对合成的API进行测试和调试。通过直接执行（无参API）或由LLM生成测试用例（有参API）来验证其鲁棒性，并进行错误修复。输出为经过验证的、可靠的API。\n5.  **最终输出**：一个持续增长的、网站特定的技能（API）库。该库可被集成到智能体的动作空间中，用于后续的任务执行。\n\n**§2 各核心模块深度拆解（每个模块100字以上，共至少3个模块）**\n#### Stage I: Skill Proposal Module\n- **模块名**：Skill Proposal\n- **输入**：详细网页观察（截图、网站名、URL、可访问性树）、当前技能库中的API列表。\n- **核心处理逻辑**：提示LLM（如GPT-4o）提出三种类型的技能任务，旨在实现从简单到复杂的课程式探索：\n  1.  **程序性任务**：需要一系列原子动作来实现高级流程自动化（如“使用筛选器搜索商品”）。\n  2.  **导航性任务**：系统性地探索网站的不同部分或页面，以构建网站的概念地图。\n  3.  **信息寻求任务**：从网页中抓取详细数据（如提取GitHub仓库的所有提交）。\n  关键指令是提出**新颖、可复用、短视界**（可在单个API调用内完成）的技能。\n- **输出**：一个或多个技能的自然语言描述。\n- **设计理由**：与现有方法（如Zhou et al., 2024b）不同，本文**显式强调技能多样性**，并采用课程学习策略，从简单任务开始，为后续合成成功率更高的API奠定基础，避免了直接探索复杂任务的高失败率。\n\n#### Stage II: Skill Synthesis Module\n- **模块名**：Skill Synthesis\n- **输入**：来自Stage I的技能描述。\n- **核心处理逻辑**：该模块包含三个子组件：\n  - **Skill Practice（技能实践）**：使用一个基础智能体（基于Code-Act）根据技能描述生成Playwright代码（点击、输入、滚动等原子动作），并重复尝试执行以完成该技能，生成动作轨迹（包含动作序列、截图、描述）。\n  - **Reward Model（奖励模型）**：提示另一个LLM，根据任务描述、动作轨迹和环境反馈（代码执行结果、网站变化）来判断任务是否成功完成，提供成功/失败的奖励信号。\n  - **API Synthesis（API合成）**：仅针对成功的轨迹，将轨迹中的状态-动作对转换为字符串表示，并提示LLM生成一个Python函数。该函数包含函数签名、文档字符串（含使用日志和前置状态描述）和代码体（Playwright自动化代码）。生成后，会进行静态分析以检测常见生成错误，如有错误则要求模型重新生成。\n- **输出**：一个结构化的Python API函数代码。\n- **设计理由**：将成功经验封装为**结构化代码（API）**，而非自然语言工作流或原始轨迹，确保了技能的**可执行性、可验证性和易共享性**。代码形式便于进行单元测试和组合。\n\n#### Stage III: Skill Honing Module\n- **模块名**：Skill Honing\n- **输入**：Stage II合成的API代码。\n- **核心处理逻辑**：对API进行测试以确保其鲁棒性。\n  - 对于**不需要额外参数**的API（仅默认Playwright页面实例），直接将其作为独立的单元测试执行。\n  - 对于**需要额外参数**的API，则利用LLM生成合适的参数值作为全面的测试用例，然后执行测试。\n  测试过程中发现的任何失败都会触发调试过程（具体调试机制原文未详细说明）。\n- **输出**：经过测试和调试的、更可靠的API。\n- **设计理由**：认识到前序模块可能引入错误，因此增加一个专门的验证阶段。这模仿了软件工程中的**测试驱动开发**理念，确保合成的技能在投入实际使用前具备一定的可靠性，降低了在关键任务中因技能故障导致整体失败的风险。\n\n**§3 关键公式与算法（如有）**\n原文未提供显式的数学公式或损失函数。核心算法流程依赖于LLM的提示工程和基于规则的逻辑。\n\n**§4 方法变体对比（如有多个变体/消融组件）**\n论文中主要对比了使用不同能力底座LLM的智能体变体：\n1.  **Base Agent (GPT-4o)**：使用GPT-4o作为所有模块（提议、实践、奖励、合成）的LLM引擎的基线智能体。\n2.  **Weaker Agent (GPT-4o-mini)**：将Base Agent中的GPT-4o替换为能力较弱的GPT-4o-mini，保持其他设计不变，用于评估技能库对弱智能体的提升效果。\n3.  **Agent with Skills**：在Base Agent或Weaker Agent的基础上，扩展其动作空间，使其能够调用由SKILLWEAVER合成（或人工编写）的API。该变体包含一个**API选择模块**，用于从技能库中过滤出与当前任务相关的、满足前置条件的API。\n\n**§5 与已有方法的核心技术差异（200字以上）**\n本文方法与代表性相关工作在技术实现上存在本质区别：\n- **vs. 轨迹微调/上下文学习方法（如Murty et al., 2024a; Patel et al., 2024）**：这些方法是**参数化**的，通过更新模型权重来隐式地学习技能，面临灾难性遗忘和泛化性差的问题。SKILLWEAVER是**非参数化**的，将技能显式地存储为外部代码（API）库，智能体本身参数不变，通过调用外部API来获得能力，从而避免了遗忘，并实现了技能的即插即用和轻松共享。\n- **vs. 自然语言工作流方法（如Agent Workflow Memory, ICAL）**：这些方法也将知识外部化，但存储形式是**非结构化的自然语言描述**，难以进行精确的自动化组合、验证和调试。SKILLWEAVER将技能存储为**结构化的、可执行的编程代码（Python API）**，支持形式化测试、调试，并能通过函数调用自然地实现技能组合。\n- **vs. 需要外部监督的探索方法**：许多现有方法需要预先给定的任务查询或高质量演示来引导学习。SKILLWEAVER强调**完全自主的探索**，其Skill Proposal模块使智能体能够在没有外部任务指令的情况下，自主发现网站潜在功能并提出技能进行练习，更贴近人类“好奇探索”的学习模式。",
    "methodology_and_formulas": "**§1 完整算法流程（伪代码级描述）**\nSKILLWEAVER的探索流程可以概括为以下步骤：\nStep 1: 初始化。对于目标网站，初始化空技能库 `API_Library = []`。\nStep 2: 开始探索循环（共160次迭代）。每次迭代 `i` 执行以下操作之一：\n  a) **尝试一个提议的技能**：\n     1. **技能提议**：LLM（GPT-4o）观察当前网页（截图、可访问性树等）和现有`API_Library`，提出一个新的程序性或导航性技能描述 `skill_desc`。\n     2. **技能实践**：基础智能体（Code-Act）根据 `skill_desc` 生成并执行Playwright动作代码，产生轨迹 `trajectory`。\n     3. **奖励评估**：奖励模型LLM根据 `skill_desc`, `trajectory` 和环境反馈，判断任务是否成功，得到奖励信号 `reward`（成功/失败）。\n     4. **API合成**：若 `reward == 成功`，则将 `trajectory` 输入给LLM，合成一个Python API函数 `api_code`。对 `api_code` 进行静态分析，如有错误则重生成。\n     5. **技能打磨**：对 `api_code` 进行测试（无参则直接执行，有参则由LLM生成测试用例）。通过测试后，将 `api_code` 加入 `API_Library`。\n  b) **测试一个现有技能**：从 `API_Library` 中选择一个API进行测试，确保其鲁棒性。\nStep 3: 在探索过程中，智能体在实践技能时，可以调用 `API_Library` 中已合成的API来帮助完成更复杂的技能（即技能组合）。\nStep 4: 探索结束后，输出最终的 `API_Library`。\n\n**§2 关键超参数与配置**\n- **LLM选择与温度**：默认使用 **GPT-4o**，温度（temperature）设置为 **0.3**。选择GPT-4o是因其强大的代码生成和推理能力。温度0.3旨在平衡生成的一致性和创造性。\n- **最大步数（Max Steps per Iteration）**：遵循WebArena默认设置，每个任务尝试的**最大动作步数限制为10步**。这是为了控制单次尝试的成本和时长。\n- **探索迭代次数**：在每个网站上执行 **160次** 探索迭代。原文未详细说明选择此数值的理由，可能基于计算成本与收益的权衡。\n- **技能类型偏好**：在Skill Proposal阶段，明确提示LLM提出**短视界、可复用**的技能，以确保技能能在后续被成功实践和合成。\n\n**§3 训练/微调设置（如有）**\nSKILLWEAVER框架本身**不涉及任何模型的训练或微调**。它是一个完全基于提示工程和规则的系统，利用现成的LLM（如GPT-4o）和基础智能体（Code-Act）进行探索和合成。因此，没有优化器、学习率、批次大小等训练配置。\n\n**§4 推理阶段的工程细节**\n- **基础智能体**：采用 **Code-Act** 架构，其动作空间是使用Playwright库的Python代码生成（如 `page.click(\"selector\")`, `page.type(\"selector\", \"text\")`）。观察空间包括网页截图、可访问性树和先前动作的执行结果。\n- **API调用集成**：在“Agent with Skills”变体中，智能体的动作空间被扩展，除了原始原子动作，还可以直接调用技能库中的API函数。这需要智能体能够理解何时以及如何调用合适的API。\n- **API选择模块**：该模块在推理时工作，负责从庞大的技能库中**过滤出与当前任务相关的API**，并**移除那些不满足当前网页前置条件的API**。这通过提示LLM分析当前任务和网页状态与API文档字符串中的描述是否匹配来实现。\n- **向量数据库**：原文未提及使用向量数据库进行技能检索。API筛选可能主要基于语义匹配（通过LLM）和规则判断。",
    "experimental_design": "**§1 数据集详情（每个数据集单独列出）**\n1.  **WebArena**：\n    - **名称**：WebArena\n    - **规模**：包含 **812个** 任务。\n    - **领域类型**：模拟5个常见应用领域的网站：电子商务（Shopping）、社交论坛（Reddit）、协作软件开发（GitLab）、内容管理（CMS）、导航（Map）。\n    - **评测问题类型**：任务基于功能正确性进行自动化评估，涵盖单跳和多跳的网页交互任务。\n    - **特殊处理**：利用其自托管沙箱环境，可以从源代码和官方文档中提取**人工编写的API**，用于与合成API进行质量对比。\n2.  **Real-World Websites (基于Online-Mind2Web)**：\n    - **名称**：Online-Mind2Web\n    - **规模**：从原始300个任务、136个网站中，筛选出**4个网站**（Drugs.com, Flight, Cooking, Car），共**57个**可访问且任务数≥8的任务进行评估。\n    - **领域类型**：真实的、动态的、复杂的商业网站（药品识别、航班预订、食谱、汽车信息）。\n    - **评测问题类型**：由人类标注者提出的真实场景任务，包括信息检索和流程操作。\n    - **特殊处理**：由于是真实网站，**无法进行自动化评估**，因此对智能体轨迹进行**人工手动评估**，验证动作是否满足任务所有要求，以及检索信息是否匹配目标。\n\n**§2 评估指标体系（全量列出）**\n- **准确性指标**：**任务成功率（Success Rate）**，即成功完成的任务数占总任务数的百分比。这是WebArena和真实网站评估的主要指标。评估基于功能正确性（WebArena自动评估，真实网站人工评估）。\n- **效率/部署指标**：原文**未提供**延迟、Token消耗、显存占用等具体效率指标。实验主要关注性能提升的幅度。\n- **其他自定义指标**：**相对改进百分比（Relative Improvement）**，计算公式为 `(有技能的成功率 - 无技能的成功率) / 无技能的成功率 * 100%`。用于量化技能集成带来的提升效果。\n\n**§3 对比基线（完整枚举）**\n1.  **WebArena Baseline**：WebArena基准报告中提供的基线智能体性能（成功率）。\n2.  **AutoEval (Pan et al., 2024)**：一种利用基于LLM的奖励模型来指导推理时探索的方法。类型：推理时搜索/规划方法。使用与本文相同的底座模型（未明确说明，但上下文推测为LLM）。代表性在于它也是一种利用LLM进行自我评估和改进的在线方法。\n3.  **SteP (Sodhi et al., 2024)**：一种结合了领域特定人工编写工作流外部记忆的方法。类型：外部记忆增强方法。其代表性在于使用了**人工精心设计**的技能（工作流）作为对比，可以检验合成技能的质量。\n4.  **Human-Crafted APIs**：从WebArena官方文档和外源网站提取的**人工编写的API**。这不是一个完整的智能体，而是作为技能库质量的对比基准，用于评估SKILLWEAVER合成API与人类专家编写API的差距。\n\n**§4 实验控制变量与消融设计**\n- **核心消融实验**：通过对比 **Baseline Agent (无技能)** 和 **Agent with Skills (有技能)** 在相同网站和任务上的成功率，直接验证集成技能库的有效性。这是最核心的消融设计。\n- **智能体能力消融**：通过将底座LLM从 **GPT-4o** 替换为 **GPT-4o-mini**，创建“Weaker Agent”，并对比其“无技能”和“有技能”版本的表现，验证技能库对不同能力智能体的泛化（知识蒸馏）效果。\n- **技能来源对比**：在相同智能体（Agent with Skills）上，分别使用 **SKILLWEAVER合成API** 和 **Human-Crafted APIs** 作为技能库，对比其性能，以评估合成技能的质量。\n- **探索迭代控制**：所有实验中的技能库都是在固定**160次探索迭代**后构建的，确保了不同实验间技能库获取成本的一致性。",
    "core_results": "**§1 主实验结果全景（表格式呈现）**\n**表1: WebArena任务成功率（%）**\n`方法 | Gitlab | Map | Shopping | CMS | Reddit | AVG.`\n`WebArena Baseline | 15.0 | 15.6 | 13.9 | 10.4 | 6.6 | 12.3`\n`AutoEval | 25.0 | 27.5 | 39.6 | 20.9 | 20.8 | 26.9`\n`*SteP | 32.0 | 30.0 | 37.0 | 24.0 | 59.0 | 33.0`\n`SKILLWEAVER (GPT-4o Baseline) | 17.8 | 27.5 | 19.8 | 18.7 | 37.7 | 22.6`\n`SKILLWEAVER (GPT-4o + Skills) | 22.2 | 33.9 | 27.2 | 25.8 | 50.0 | 29.8`\n`Δ (相对提升) | ↑25% | ↑23% | ↑38% | ↑38% | ↑33% | ↑32%`\n`SKILLWEAVER (GPT-4o-mini Baseline) | 6.1 | 10.3 | 11.8 | 3.3 | 18.9 | 9.2`\n`SKILLWEAVER (GPT-4o-mini + Skills) | 8.9 | 16.7 | 17.1 | 7.7 | 26.4 | 14.1`\n`Δ (相对提升) | ↑46% | ↑62% | ↑46% | ↑133% | ↑40% | ↑45%`\n\n**表2: 真实网站（Online-Mind2Web）任务成功率（%）**\n`方法 | Drug | Flight | Cooking | Car | AVG.`\n`Baseline (GPT-4o) | 65.0 | 11.7 | 62.5 | 11.1 | 40.2`\n`+ Skills | 87.0 | 29.4 | 75.0 | 11.1 | 56.2`\n`Δ (相对提升) | ↑34% | ↑151% | ↑20% | ↑0% | ↑40%`\n\n**§2 分任务/分场景深度分析（每个维度100字以上）**\n- **WebArena整体表现**：集成合成技能后，使用GPT-4o的智能体平均成功率从22.6%提升至29.8%，**绝对提升7.2个百分点，相对提升31.8%**。使用GPT-4o-mini的弱智能体提升更为显著，从9.2%提升至14.1%，**绝对提升4.9个百分点，相对提升54.3%**。这表明技能库对弱智能体的知识蒸馏效果极佳。\n- **跨网站分析**：提升效果在所有5个WebArena网站上都一致存在。在**CMS**网站上，GPT-4o-mini智能体获得了最大的相对提升（133%），从3.3%到7.7%，说明该网站任务可能高度依赖特定流程，而合成技能恰好捕捉并封装了这些流程。在**Shopping**网站上，SKILLWEAVER（27.2%）表现不如AutoEval（39.6%）和SteP（37.0%），作者解释是因为购物网站需要与动态、部分可观测的信息（如产品搜索结果、详情）进行更广泛的交互，这对当前基于固定轨迹合成的API提出了挑战。\n- **真实网站分析**：在四个真实网站上平均相对提升39.8%。在**Flight**网站上提升最大（151%，从11.7%到29.4%），表明航班预订涉及的标准操作流程能被有效抽象为API。在**Car**网站上提升为0%，作者指出虽然合成API在9个任务中的4个成功将智能体引导至最终所需状态，但最终步骤需要强大的环境理解和视觉推理，智能体仍然失败，揭示了当前方法在处理需要复杂决策和判断的“最后一公里”问题上的局限性。\n\n**§3 效率与开销的定量对比**\n原文**未提供**关于延迟、Token消耗或显存占用的具体定量数据。因此无法进行效率与开销的数值对比。实验焦点完全集中在任务成功率的提升上。\n\n**§4 消融实验结果详解**\n消融实验的核心是“有无技能”的对比，结果已在上文主结果中详细列出。具体来看：\n- **移除整个技能库（即使用Baseline Agent）**：对于GPT-4o智能体，平均成功率从29.8%下降至22.6%，**绝对下降7.2个百分点，相对下降24.2%**。对于GPT-4o-mini智能体，平均成功率从14.1%下降至9.2%，**绝对下降4.9个百分点，相对下降34.8%**。这直接证明了技能库每个组成部分（提议、合成、打磨）整体贡献的有效性。\n- **未对Skill Proposal、Synthesis、Honing等子模块进行独立消融**，因此无法量化每个单独组件对最终性能的影响具体数值。\n\n**§5 案例分析/定性分析（如有）**\n- **成功案例：组合式API的出现**：经过一定次数的探索迭代后，流水线开始生成**组合式API**，即调用多个更简单API的复杂API。例如，一个“对搜索结果应用多个筛选器”的API，会依次调用另一个“关闭网页覆盖层”的API，以及两个用于细化搜索的API。这表明SKILLWEAVER具备了**技能抽象和组合**的涌现能力。\n- **失败案例：技能使用的局限性**：即使提供了合成或人工编写的API，LLM在调用API时仍不够鲁棒。失败主要分为两类：\n  1.  **未能识别合适的API**：例如，在Cookpad.com上，任务“保存一个汉堡食谱”，LLM未能识别出应调用“按菜系类型搜索食谱（‘汉堡’）”这个API。\n  2.  **生成错误的参数**：例如，任务“浏览不含坚果的无麸质巧克力曲奇食谱”，LLM成功识别了“按成分搜索食谱”的API，但生成了错误的关键词 `‘chocolate chip, -nuts’` 而不是 `‘chocolate chip without nuts’`，导致搜索结果为空。\n  这些案例揭示了当前基于LLM的智能体在**工具选择（Tool Selection）和参数 grounding** 方面的固有弱点，是技能增强型智能体的主要失败来源。",
    "conclusion_and_future_work": "**§1 本文核心贡献总结**\n1.  **提出了SKILLWEAVER框架**：一个使网页智能体能够通过自主探索网站环境来合成可复用技能（API）以实现自我改进的三阶段（提议、合成、打磨）流水线。\n2.  **实现了非参数化的技能学习与共享**：将成功经验提炼为结构化的Python API代码，而非更新模型参数或存储原始轨迹。这使得技能库可以**即插即用**，轻松在不同智能体间迁移，避免了灾难性遗忘。\n3.  **实证验证了显著性能提升**：在WebArena上，使用GPT-4o的智能体获得平均31.8%的相对成功率提升；在真实网站上获得平均39.8%的提升。特别是，弱智能体（GPT-4o-mini）通过集成强智能体合成的技能，获得了高达54.3%的平均提升，证明了有效的**技能蒸馏**。\n4.  **展示了技能组合的涌现**：框架能够自动生成调用多个简单API的组合式API，体现了层次化技能抽象的能力。\n\n**§2 局限性（作者自述）**\n1.  **LLM调用API的可靠性问题**：即使提供了高质量的API，LLM（如GPT-4o）在**识别正确API**和**生成正确参数**方面仍然不够鲁棒，这限制了技能增强型智能体的最终性能上限。对于更弱的LLM（如GPT-4o-mini），这个问题更严重。\n2.  **对复杂、动态交互的挑战**：在需要与动态、部分可观测信息进行广泛交互的网站（如Shopping）上，性能提升相对有限。处理需要复杂环境理解和视觉推理的“最终步骤”也存在困难（如Car网站案例）。\n3.  **安全与伦理考量**：在真实网站上的自主探索可能触发有害操作（如创建账户、提交表单）。作者通过手动验证和添加安全指令来缓解，但指出这是未来研究需要彻底评估和减轻的关键风险。\n\n**§3 未来研究方向（全量提取）**\n1.  **提升LLM的工具使用能力**：未来工作需要改进LLM在**工具选择（API检索）**和**参数生成**方面的鲁棒性和准确性，以更好地利用合成的技能库。这可能需要更先进的提示工程、微调或专门的推理模块。\n2.  **释放更强基座智能体的潜力**：作者指出，随着基础智能体变得更强大（例如，具备更复杂的推理时搜索和规划能力，如Operator），SKILLWEAVER合成**更复杂、更精密技能**的潜力将被进一步释放。例如，完成需要长程规划和回溯能力的任务（如“为多个列表请求报价”）。\n3.  **深入的安全风险评估与保障**：必须对网页智能体在真实世界部署中可能产生的安全风险进行**彻底评估和缓解**，确保它们不会产生或执行有害动作。这包括隐私侵犯、敏感操作自动化等。\n4.  **探索更广泛的网站和任务**：在更多样化、更复杂的真实网站和任务类型上验证和扩展该方法。",
    "research_contributions": "**§1 核心学术贡献（按重要性排序）**\n1.  **框架创新与概念验证**：首次提出了一个完整的、以技能为中心的框架，使网页智能体能够**完全自主地**通过探索来发现、实践并封装可复用技能为结构化API。这在概念上更贴近人类的程序性知识学习过程，并在WebArena和真实网站上得到了实证验证，证明了其可行性。\n2.  **非参数化自我改进路径**：明确区分并实践了一条**非参数化**的自我改进技术路线。与主流的微调或强化学习方法不同，SKILLWEAVER通过构建外部、可共享的代码化技能库来提升能力，为解决灾难性遗忘、实现高效知识迁移和即插即用提供了新的解决方案，对领域产生了重要影响。\n3.  **技能蒸馏与智能体泛化的实证发现**：通过严谨的实验设计（强/弱智能体对比），提供了强有力的证据表明：强智能体合成的技能可以**显著提升弱智能体**的性能（相对提升高达54.3%）。这一发现为“通过技能进行知识蒸馏”提供了新的实证支持，具有重要的实践价值。\n\n**§2 工程与实践贡献**\n- **开源代码与可复现性**：作者声明代码将以**OPEN-RAIL许可证**发布，仅供研究使用。这为社区提供了可复现的实验基础和进一步开发的起点。\n- **技能表示标准**：推广了将网页交互技能表示为**带有文档字符串和前置条件描述的Python函数（API）** 的实践，这种表示形式兼具可读性、可执行性和可测试性，为技能库的构建提供了实用的工程范式。\n- **在真实动态环境中的验证**：不仅在受控的模拟环境（WebArena）中测试，还勇敢地在复杂、动态的**真实商业网站**上进行了评估（尽管规模有限），证明了该方法在更实际场景中的潜力，并公开讨论了相关的安全挑战。\n\n**§3 与相关工作的定位**\nSKILLWEAVER在当前网页智能体技术路线图中，处于**非参数化、外部技能记忆与合成**这一路线的核心位置。它并非简单延续现有的轨迹微调或自然语言工作流方法，而是开辟了一条将技能**代码化、产品化**的新路径。它借鉴了Voyager在Minecraft中合成代码技能的思想，并将其成功适配到更具结构性但也更复杂多变的网页环境中。同时，它也与AutoEval等在线推理时改进方法形成互补，SKILLWEAVER侧重于**长期、离线**的技能积累，而AutoEval侧重于**单次、在线**的轨迹优化。",
    "professor_critique": "**§1 实验设计与评估体系的缺陷**\n- **评估指标单一**：实验完全依赖**任务成功率**这一终极指标，缺乏对过程效率、成本、鲁棒性的细粒度评估。例如，没有报告集成API后单次任务的平均**推理时间（延迟）**、**LLM Token消耗**、**API调用次数**。这可能导致“指标幸运”——成功率提升但代价是效率急剧下降（例如，频繁调用重型API或进行大量内部推理）。\n- **Baseline选择可能不够全面**：虽然对比了AutoEval和SteP，但未与近期一些更强大的**基于搜索树的智能体（如Tree Search Agent (Koh et al., 2024)、AgentQ）** 或**世界模型增强的智能体（如WebDreamer）** 进行直接比较。这些方法可能在复杂规划任务上具有优势，缺乏与它们的对比使得SKILLWEAVER在技术路线图中的绝对定位不够清晰。\n- **真实网站评估规模过小**：仅在4个网站的57个任务上进行真实世界评估，**样本量严重不足**，且网站选择可能带有偏差。结论“在真实网站上有效”的普适性存疑。\n\n**§2 方法论的理论漏洞或工程局限**\n- **技能提议的盲目性与冗余风险**：Skill Proposal模块完全依赖LLM的“好奇心”，缺乏一个**显式的、基于信息的探索目标**（如最大化状态覆盖、最小化技能冗余）。这可能导致大量迭代浪费在探索无关或功能重复的页面上，探索效率低下。当网站规模极大时，160次迭代可能只能覆盖极小部分功能。\n- **API合成的脆弱性根基**：API合成完全依赖于**单次成功轨迹**的泛化。这存在严重风险：轨迹可能偶然成功（例如，依赖了特定页面状态或缓存），据此合成的API在其他细微不同的场景下极易失败。尽管有Stage III的测试，但测试用例生成同样依赖LLM，可能无法覆盖边界情况。**缺乏对合成API泛化能力的系统性评估**（如在变异测试下的通过率）。\n- **技能库的可扩展性危机**：随着技能库增长，**API选择模块**的负担急剧加重。当前基于LLM语义匹配的筛选方式，在库中有成千上万个API时，其准确性和延迟都可能崩溃。论文未探讨技能库规模增大后的检索效率与精度问题。\n\n**§3 未经验证的边界场景**\n1.  **多模态与富媒体交互**：网站包含复杂Canvas、WebGL、视频播放器或游戏时，仅靠截图和可访问性树可能无法提供足够信息，智能体能否发现并合成相关技能（如“调整视频播放速度”、“在画布上绘图”）？\n2.  **需要跨网站协作的任务**：任务需要在一个网站（如Google搜索）上获取信息，然后在另一个网站（如特定电商）上执行操作。SKILLWEAVER的网站特定技能库如何支持这种**跨网站工作流**？\n3.  **对抗性或不规范网站结构**：当网站HTML结构混乱、可访问性树缺失或包含大量动态加载、iframe时，Playwright代码的定位器（selector）可能极其脆弱。基于此合成的API的鲁棒性如何？\n4.  **需要高级认知与决策的任务**：例如，“从这些产品评论中总结出最常见的三个投诉”，这需要阅读理解、归纳和判断，远非自动化点击和输入所能涵盖。SKILLWEAVER的技能抽象层次目前似乎仅限于“自动化流程”，难以触及此类认知型任务。\n\n**§4 可复现性与公平性问题**\n- **高昂的复现成本**：整个框架重度依赖**GPT-4o API**进行技能提议、实践、奖励评估、API合成和测试。对于没有GPT-4o API访问权限或预算有限的研究者，**几乎无法复现**主要实验结果。使用更便宜的模型（如GPT-4o-mini）会导致基线性能大幅下降，改变实验格局。\n- **对Baseline的超参数调优不公平**：论文详细说明了SKILLWEAVER使用的温度（0.3）和迭代次数（160），但未说明对比基线（如AutoEval, SteP）是否使用了经过同等精心调优的超参数或提示。如果基线使用的是其论文中的默认设置，而SKILLWEAVER经过了大量调优，则对比可能不公平。\n- **探索过程的随机性**：探索始于LLM的随机提议，且技能实践有随机性。论文未报告多次随机种子运行的平均结果和方差，因此结果的**统计显著性**和**稳定性**存疑。",
    "zero_compute_opportunity": "#### 蓝图一：探究轻量级模型能否通过“技能提议-筛选”协作框架实现高效探索\n- **核心假设**：弱模型（如GPT-4o-mini）在自主提出高质量技能方面能力不足，但强模型（如GPT-4o）提出的技能列表，经过一个由弱模型驱动的筛选器过滤后，可以指导弱模型进行更高效的探索，从而以低成本构建有价值的技能库。\n- **与本文的关联**：基于本文发现“弱智能体极大受益于强智能体合成的技能”，但弱智能体自身探索能力差。本蓝图旨在解决弱智能体在“探索阶段”的瓶颈，而非仅仅在“使用阶段”受益。\n- **所需资源**：\n  1.  **低成本API**：主要使用 **GPT-4o-mini**（或更便宜的Claude Haiku）作为核心探索智能体。仅需**少量次数的GPT-4o调用**用于初始技能池生成。\n  2.  **公开数据集**：WebArena的模拟环境（可本地部署，无API成本）或筛选少量Online-Mind2Web中可免费访问的网站（如Wikipedia）。\n  3.  **预计费用**：假设探索100迭代，其中10次调用GPT-4o生成技能池（约$0.5），90次由GPT-4o-mini执行实践和评估（约$0.9），总成本约**$1.5**。\n- **执行步骤**：\n  1.  **技能池预生成**：在目标网站首页，使用**1次GPT-4o调用**，让其一次性生成一个包含20-30个潜在技能描述的列表（涵盖程序性、导航性、信息寻求任务）。\n  2.  **弱模型驱动筛选与排序**：对于技能池中的每个技能描述，使用**GPT-4o-mini** 根据当前网页观察，评估该技能的**可执行性**（当前页面元素是否支持）和**预期效用**（是否可能常用）。\n  3.  **课程式探索**：弱智能体按照筛选排序后的技能列表，依次尝试执行排名最高的技能，使用本文的Skill Synthesis和Honing流程（但奖励模型和API合成也可降级使用GPT-4o-mini）。\n  4.  **动态更新技能池**：每成功合成一个API后，提示GPT-4o-mini基于新API和当前状态，提议1-2个相关的、更复杂的技能，加入待探索列表。\n- **预期产出**：\n  1.  验证“强提议-弱筛选-弱执行”协作模式是否能以极低成本（< $5）构建出性能优于纯弱模型探索的技能库。\n  2.  一篇短论文或技术报告，可投递 **EMNLP/ACL 的Demo或Findings track**，或 **NeurIPS 的Tiny Papers**。\n- **潜在风险**：\n  - **风险**：GPT-4o-mini的评估和排序可能不准确，导致探索仍陷入低效循环。\n  - **应对**：引入简单的启发式规则辅助排序，如优先选择描述中包含高频动作词（click, type, search）的技能。\n\n#### 蓝图二：基于合成API的脆弱性分析及变异测试增强框架\n- **核心假设**：SKILLWEAVER合成的API在面对微小的网页结构或内容变化时非常脆弱。通过构建一个轻量级的网页变异测试框架，可以自动评估并提升合成API的鲁棒性，而无需重新探索。\n- **与本文的关联**：针对本文方法论漏洞“API合成依赖于单次成功轨迹”和教授锐评中“缺乏对泛化能力的系统性评估”。\n- **所需资源**：\n  1.  **工具**：Playwright、BeautifulSoup/ lxml 用于解析和修改HTML。\n  2.  **数据**：SKILLWEAVER在WebArena上合成的一小批API（可从论文作者处请求或自行在1-2个网站上复现少量）。WebArena本地环境。\n  3.  **计算**：本地CPU即可，无需GPU或昂贵API。\n- **执行步骤**：\n  1.  **变异算子定义**：设计一组针对网页DOM的轻量级变异算子，例如：\n     - **Selector变异**：轻微修改元素ID、Class名（如`btn-submit` -> `btn-submit2`）。\n     - **结构变异**：在目标元素附近插入兄弟节点、改变父容器。\n     - **内容变异**：修改输入框的placeholder文本、按钮文字。\n  2.  **自动化测试流水线**：对每个合成API及其原始成功轨迹的最终页面，应用变异算子生成N个变异后的页面。\n  3.  **鲁棒性评估**：在变异后的页面上重新执行该API，统计失败率。计算**变异得分**（通过率）。\n  4.  **API自动加固**：对于失败案例，将变异后的页面和错误信息反馈给一个**轻量级LLM（如CodeLlama 7B）**，提示其修复API代码中的定位器或逻辑，使其能通过原始页面和变异页面。\n- **预期产出**：\n  1.  一个开源的、针对网页自动化API的变异测试工具包。\n  2.  一份分析报告，量化SKILLWEAVER类API的脆弱性，并展示自动加固后的提升效果。\n  3.  可投递 **IEEE/ACM International Conference on Software Engineering (ICSE) 的NIER track** 或 **自动化测试顶会（如ISSTA）**。\n- **潜在风险**：\n  - **风险**：变异可能生成大量无意义或语法无效的HTML，导致测试无效。\n  - **应对**：变异后使用HTML验证器进行过滤，并确保变异后的页面在浏览器中仍能正常渲染（使用Playwright截图验证）。\n\n#### 蓝图三：探索技能库的压缩与高效检索机制\n- **核心假设**：随着技能库增长，基于LLM语义匹配的API选择模块将成为性能瓶颈。通过将技能API的文档字符串和代码语义嵌入到轻量级向量数据库中，并设计基于页面当前状态的快速过滤机制，可以大幅提升检索效率与准确性，且完全本地运行。\n- **与本文的关联**：针对教授锐评中“技能库可扩展性危机”和原文中未详细说明的“API选择模块”。\n- **所需资源**：\n  1.  **嵌入模型**：免费的小型句子嵌入模型（如 **all-MiniLM-L6-v2**，仅80MB），通过 `sentence-transformers` 库使用。\n  2.  **向量数据库**：轻量级本地向量库如 **ChromaDB** 或 **FAISS**。\n  3.  **数据**：模拟生成的技能API文档字符串数据集（可人工编写模板批量生成，或爬取GitHub上简单的Playwright脚本进行抽象）。\n  4.  **计算**：本地CPU。\n- **执行步骤**：\n  1.  **技能索引**：对每个API，从其文档字符串（描述、前置条件）和函数名中提取文本，使用小型嵌入模型生成向量，存入ChromaDB。\n  2.  **状态特征提取**：从当前网页的可访问性树中提取关键文本特征（如页面标题、主要标题、按钮文本、输入框placeholder），同样编码为向量。\n  3.  **两阶段检索**：\n     - **阶段1（语义召回）**：将当前状态向量与技能库向量进行相似度搜索，召回Top-K个候选API。\n     - **阶段2（规则过滤）**：对召回结果，使用一组轻量级规则（如检查候选API文档中明示的前置条件关键词是否出现在当前页面文本中）进行快速过滤。\n  4.  **评估**：在WebArena的少量任务上，对比纯LLM筛选与本混合检索方法在**检索准确率**（返回的API是否真正相关）和**延迟**上的差异。\n- **预期产出**：\n  1.  一个为网页技能库设计的高效检索模块原型，可与SKILLWEAVER集成。\n  2.  实验数据证明在保持相近准确率下，检索速度比纯LLM调用快一个数量级，且成本近乎为零。\n  3.  可投递 **ACL/EMNLP 的系统演示（System Demonstration）track** 或 **专注于效率的研讨会（如 Efficient NLP）**。\n- **潜在风险**：\n  - **风险**：小型嵌入模型在技能语义理解上可能不如大型LLM精准，导致召回率下降。\n  - **应对**：采用集成策略，将本方法作为粗筛器，召回一个较大的候选集（如Top-20），再交给LLM进行精排，依然能大幅减少LLM需要处理的候选数量。",
    "source_file": "SkillWeaver Web Agents can Self-Improve by Discovering and Honing Skills.md"
}