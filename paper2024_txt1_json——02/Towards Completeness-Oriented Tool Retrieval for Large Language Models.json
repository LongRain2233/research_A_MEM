{
    "title": "Towards Completeness-Oriented Tool Retrieval for Large Language Models",
    "background_and_problem": "【一、研究背景与问题核心】\n\n**§1 领域背景与研究动机（150字以上）**\n本工作位于大语言模型（LLM）工具学习领域。随着LLM在各类NLP任务上取得显著进展，其处理复杂问题和提供实时知识的能力仍受限于预训练数据。工具学习（Tool Learning）作为一种有效策略，允许LLM动态调用外部工具，以获取实时数据和执行复杂计算，从而突破其知识局限。然而，真实系统通常包含大量工具，受限于LLM的上下文长度和延迟约束，将所有工具描述输入LLM是不切实际的。因此，开发一个有效的工具检索系统，从海量工具库中为给定用户查询筛选出最合适的工具子集，成为充分释放工具增强型LLM潜力的关键。当前，工具检索作为一个新兴且关键的研究方向，其核心挑战在于如何超越传统的语义匹配，确保检索结果的“完整性”，以满足解决多面性查询的需求。\n\n**§2 现有技术的核心短板——具体失败模式（250字以上）**\n现有工具检索方法主要直接采用密集检索技术，其核心短板在于仅关注查询与工具描述之间的语义相似性匹配，而忽略了工具间的协作关系，导致在需要多个工具协同解决的多面性查询场景下失败。具体失败模式如下：\n1.  **基于语义的密集检索方法（如ANCE、TAS-B、coCondensor、Contriever）**：当输入一个需要多种工具协作的多面性查询时（例如“计算5盎司黄金加上100万股亚马逊股票的人民币价值”），这些方法倾向于检索语义上相似的工具（如多个股票价格工具），而忽略了完成该查询所必需的其他互补工具（如黄金价格工具和货币汇率工具）。这导致检索到的工具集冗余且不完整，无法满足下游LLM生成完整答案的需求。\n2.  **基于词项的检索方法（如BM25）**：当输入查询与工具描述存在词汇不匹配或依赖深层语义理解时，该方法会失败。例如，对于查询“我想去巴黎旅行”，BM25可能仅匹配到包含“巴黎”或“旅行”关键词的工具，而无法理解该查询背后涉及的“场景”（如交通、天气、住宿、景点等多个协作工具类别），导致检索结果不完整。\n3.  **现有方法的共同缺陷**：它们都使用传统的检索评估指标（如Recall@K, NDCG@K），这些指标衡量的是单个工具的相关性排名，无法评估检索到的工具集是否完整覆盖了解决查询所需的所有工具。因此，即使Recall@K得分高，也可能遗漏关键工具，导致下游LLM任务失败。\n\n**§3 问题的根本难点与挑战（200字以上）**\n从理论和工程角度看，实现完整性导向的工具检索面临以下根本难点：\n1.  **建模高阶协作关系**：工具之间的协作关系是隐式且复杂的，超越了简单的语义相似性。一个查询背后的“用户意图”往往对应一个由多个功能互补工具构成的“场景”。如何从数据中自动挖掘并建模这种“查询-场景-工具”之间的高阶关联，是一个核心挑战。\n2.  **评估指标与优化目标脱节**：传统检索指标（Recall, NDCG）优化的是单个文档（工具）的相关性排名，而完整性要求优化的是整个工具子集的覆盖度。这导致使用传统指标训练的模型，其优化目标与最终的应用需求（生成完整答案）不一致。需要设计新的评估指标（如COMP@K）和相应的损失函数来直接优化完整性。\n3.  **数据稀缺与质量**：现有的多工具场景数据集（如ToolBench）存在查询冗长、语义直接、不能真实反映用户简短多面性意图的问题。构建高质量、自然、且明确标注了多工具协作关系的数据集是验证新方法的前提，但成本高昂。\n4.  **模型效率与可扩展性**：在真实系统中，工具库可能非常庞大（数万甚至更多）。如何在保证检索完整性的同时，维持低延迟和高吞吐量，对检索系统的工程实现提出了严峻挑战。\n\n**§4 本文的切入点与核心假设（200字以上）**\n本文的突破口在于引入“场景”作为中介概念来建模工具间的协作关系。其核心假设是：**解决一个多面性用户查询所需的一组工具，可以概念化为一个“场景”；通过建模“查询-场景-工具”之间的二分图关系，并利用图神经网络进行消息传播，可以捕获工具间的高阶协作信息，从而提升工具检索的完整性。**\n该假设的灵感来源于现实世界的认知：复杂任务通常需要多个步骤或工具的协同（如旅行规划涉及交通、住宿、天气等多个方面）。在技术层面，这对应于利用图结构数据挖掘实体间的复杂关系。作者进一步提出一个两阶段学习框架：第一阶段进行语义学习，获取查询和工具的基础表示；第二阶段进行协作学习，在构建的三个二分图（查询-场景、查询-工具、场景-工具）上进行双视图图对比学习，以融合协作信息。此外，作者假设使用列表式多标签损失函数可以促使模型平等地关注真实工具集中的所有工具，避免偏向于某个特定工具，从而更好地优化完整性目标。",
    "core_architecture": "【二、核心架构与技术机制】\n\n**§1 系统整体架构概览（200字以上）**\nCOLT采用两阶段学习框架，整体数据流如下：\n1.  **输入**：用户查询 \\( q \\) 和工具集 \\( \\mathcal{T} = \\{(t_i, d_i)\\} \\)（每个工具 \\( t_i \\) 有其描述 \\( d_i \\)）。\n2.  **阶段一：语义学习**：查询 \\( q \\) 和每个工具 \\( t \\) 分别通过一个预训练语言模型（PLM）的双编码器获得初始语义嵌入 \\( \\mathbf{e}_q \\) 和 \\( \\mathbf{e}_t \\)。使用InfoNCE损失进行对比学习，目标是拉近相关查询-工具对的距离，推远不相关对的距离。输出是初步对齐的语义表示。\n3.  **阶段二：协作学习**：\n    *   **图构建**：基于训练数据，构建三个二分图：查询-场景图（Q-S）、查询-工具图（Q-T）、场景-工具图（S-T）。其中“场景”定义为解决一个查询所需的所有真实工具的集合。\n    *   **双视图表示学习**：\n        *   **场景中心视图**：在Q-S图上使用LightGCN进行 \\( I \\) 层消息传播，更新查询和场景表示（\\( \\mathbf{e}_q^S, \\mathbf{e}_s^S \\)）。初始场景表示 \\( \\mathbf{e}_s^{S(0)} \\) 由其关联的所有工具表示的均值池化得到。\n        *   **工具中心视图**：在Q-T图上使用LightGCN进行 \\( I \\) 层消息传播，更新查询和工具表示（\\( \\mathbf{e}_q^T, \\mathbf{e}_t^T \\)）。场景表示 \\( \\mathbf{e}_s^T \\) 由关联工具表示 \\( \\mathbf{e}_t^T \\) 均值池化得到。\n    *   **分数融合**：对于查询-工具对 \\( (q, t) \\)，其最终匹配分数 \\( \\widehat{y}(q, t) \\) 由两个视图的余弦相似度之和计算：\\( \\operatorname{sim}(\\mathbf{e}_q^S, \\mathbf{e}_t^T) + \\operatorname{sim}(\\mathbf{e}_q^T, \\mathbf{e}_t^T) \\)。\n4.  **输出**：根据 \\( \\widehat{y}(q, t) \\) 对所有工具进行排序，返回Top-K个工具。\n\n**§2 各核心模块深度拆解（每个模块100字以上，共至少3个模块）**\n#### 模块一：语义学习模块（Semantic Learning Module）\n-   **输入**：原始查询文本 \\( q \\)，工具文本描述 \\( d_t \\)。\n-   **核心处理逻辑**：采用标准的双编码器架构。查询编码器和工具编码器共享同一个PLM（如BERT）参数。对PLM最后一层的输出进行均值池化，得到查询向量 \\( \\mathbf{e}_q \\) 和工具向量 \\( \\mathbf{e}_t \\)。使用InfoNCE损失（公式2）进行训练：\\( -\\log \\frac{e^{\\operatorname{sim}(q, t^+)}}{e^{\\operatorname{sim}(q, t^+)} + \\sum_{j=1}^{k} e^{\\operatorname{sim}(q, t_j^-)}} \\)，其中 \\( t^+ \\) 是正例工具，\\( \\{t_j^-\\} \\) 是负例工具。\n-   **输出**：查询和工具的初始语义嵌入 \\( \\mathbf{e}_q, \\mathbf{e}_t \\)。\n-   **设计理由**：为后续的图学习提供高质量的、在语义空间中对齐的初始表示。直接使用未在工具检索数据上微调的PLM（零样本）性能很差（见表3），因此需要此阶段进行领域适配。\n\n#### 模块二：图构建与场景中心视图（Scene-centric View）\n-   **输入**：语义学习阶段得到的查询表示 \\( \\mathbf{e}_q^{S(0)} = \\mathbf{e}_q \\)，以及通过场景-工具图关联计算得到的初始场景表示 \\( \\mathbf{e}_s^{S(0)} = \\frac{1}{|\\mathcal{N}_s^T|} \\sum_{t \\in \\mathcal{N}_s^T} \\mathbf{e}_t \\)。\n-   **核心处理逻辑**：在查询-场景二分图（Q-S）上应用LightGCN进行消息传播。对于第 \\( i \\) 层，查询和场景的表示更新遵循公式3：\n    \\[ \\mathbf{e}_q^{S(i)} = \\sum_{s \\in \\mathcal{N}_q^S} \\frac{1}{\\sqrt{|\\mathcal{N}_q^S|} \\sqrt{|\\mathcal{N}_s^Q|}} \\mathbf{e}_s^{S(i-1)}, \\quad \\mathbf{e}_s^{S(i)} = \\sum_{q \\in \\mathcal{N}_s^Q} \\frac{1}{\\sqrt{|\\mathcal{N}_q^S|} \\sqrt{|\\mathcal{N}_s^Q|}} \\mathbf{e}_q^{S(i-1)} \\]\n    其中 \\( \\mathcal{N}_q^S \\) 是查询 \\( q \\) 在Q-S图中的邻居场景集合，\\( \\mathcal{N}_s^Q \\) 是场景 \\( s \\) 的邻居查询集合。传播 \\( I \\) 层后，将第0层到第 \\( I \\) 层的表示求和得到最终表示（公式5）：\\( \\mathbf{e}_q^S = \\sum_{i=0}^I \\mathbf{e}_q^{S(i)}, \\quad \\mathbf{e}_s^S = \\sum_{i=0}^I \\mathbf{e}_s^{S(i)} \\)。\n-   **输出**：场景中心视图下的查询表示 \\( \\mathbf{e}_q^S \\) 和场景表示 \\( \\mathbf{e}_s^S \\)。\n-   **设计理由**：通过图传播，使查询表示能够融合其关联场景的信息，场景表示能够融合其关联查询的信息。这有助于捕获“哪些工具经常在同一个场景下被共同使用”的协作模式，从而在检索时倾向于返回一个完整的工具组合。\n\n#### 模块三：工具中心视图与分数融合（Tool-centric View & Score Fusion）\n-   **输入**：语义学习阶段得到的查询表示 \\( \\mathbf{e}_q^{T(0)} = \\mathbf{e}_q \\) 和工具表示 \\( \\mathbf{e}_t^{T(0)} = \\mathbf{e}_t \\)。\n-   **核心处理逻辑**：在查询-工具二分图（Q-T）上应用LightGCN进行消息传播。更新公式类似公式6。传播 \\( I \\) 层后求和得到最终表示 \\( \\mathbf{e}_q^T, \\mathbf{e}_t^T \\)（公式7）。场景表示 \\( \\mathbf{e}_s^T \\) 由关联工具表示均值池化得到（公式8）。最终，查询-工具对 \\( (q, t) \\) 的匹配分数由两个视图的相似度相加计算（公式9）：\\( \\widehat{y}(q, t) = \\operatorname{sim}(\\mathbf{e}_q^S, \\mathbf{e}_t^T) + \\operatorname{sim}(\\mathbf{e}_q^T, \\mathbf{e}_t^T) \\)。\n-   **输出**：工具中心视图下的查询表示 \\( \\mathbf{e}_q^T \\) 和工具表示 \\( \\mathbf{e}_t^T \\)，以及最终的匹配分数 \\( \\widehat{y}(q, t) \\)。\n-   **设计理由**：工具中心视图保留了查询与工具之间的直接语义关联。双视图设计提供了互补信息：场景视图强调工具集的完整性，工具视图强调个体工具的相关性。分数融合是一种简单有效的集成策略。\n\n**§3 关键公式与算法（如有）**\n1.  **语义学习损失（InfoNCE）**：\n    \\[ \\mathcal{L}_{SL} = - \\log \\frac{e^{\\operatorname{sim}(q, t^+)}}{e^{\\operatorname{sim}(q, t^+)} + \\sum_{j=1}^{k} e^{\\operatorname{sim}(q, t_j^-)}} \\]\n2.  **双视图图对比学习损失**：\n    \\[ \\mathcal{L}_{Q}^{C} = - \\frac{1}{|Q|} \\sum_{q \\in Q} \\log \\frac{e^{\\operatorname{sim}(\\mathbf{e}_q^S, \\mathbf{e}_q^T) / \\tau}}{\\sum_{q^- \\in Q} e^{\\operatorname{sim}(\\mathbf{e}_q^S, \\mathbf{e}_{q^-}^T) / \\tau}} \\]\n    \\[ \\mathcal{L}_{S}^{C} = - \\frac{1}{|\\mathcal{S}|} \\sum_{s \\in \\mathcal{S}} \\log \\frac{e^{\\operatorname{sim}(\\mathbf{e}_s^S, \\mathbf{e}_s^T) / \\tau}}{\\sum_{s^- \\in \\mathcal{S}} e^{\\operatorname{sim}(\\mathbf{e}_s^S, \\mathbf{e}_{s^-}^T) / \\tau}} \\]\n    其中 \\( \\tau \\) 是温度系数。\n3.  **列表式多标签损失**：\n    \\[ \\mathcal{L}_{\\text{list}} = - \\sum_{q \\in Q} \\sum_{t \\in \\mathcal{T}_q} p_q^t \\log \\widehat{p_q^t} + (1 - p_q^t) \\log (1 - \\widehat{p_q^t}) \\]\n    其中 \\( p_q^t \\) 是真实概率（相关为1，不相关为0），\\( \\widehat{p_q^t} = \\frac{\\gamma(\\widehat{y}(q, t))}{\\sum_{t' \\in \\mathcal{T}_q} \\gamma(\\widehat{y}(q, t'))} \\)，\\( \\gamma(x)=1 \\) if \\( x>0 \\) else 0（基于公式13简化理解，原文公式12-13定义了理想和预测的概率分布）。\n4.  **总损失**：\n    \\[ \\mathcal{L} = \\mathcal{L}_{\\text{list}} + \\lambda (\\mathcal{L}_{Q}^{C} + \\mathcal{L}_{S}^{C}) \\]\n    其中 \\( \\lambda \\) 是平衡系数。\n\n**§4 方法变体对比（如有多个变体/消融组件）**\n论文未提出多个官方变体，但进行了详尽的消融实验，产生了多个变体：\n1.  **COLT (完整模型)**：包含语义学习、协作学习（双视图GNN）、列表式多标签损失和对比学习损失。\n2.  **w/o semantic learning**：移除第一阶段语义学习，直接使用预训练PLM的零样本表示作为图学习的初始输入。\n3.  **w/o collaborative learning**：移除第二阶段协作学习（即不使用图神经网络），仅使用语义学习阶段微调后的PLM进行检索。这等价于传统的微调密集检索方法。\n4.  **w/o list-wise learning**：在协作学习阶段，将列表式多标签损失 \\( \\mathcal{L}_{\\text{list}} \\) 替换为更简单的损失函数（原文未具体说明，推测可能是二元交叉熵损失）。\n5.  **w/o contrastive learning**：移除双视图对比学习损失 \\( \\mathcal{L}_{Q}^{C} \\) 和 \\( \\mathcal{L}_{S}^{C} \\)，仅使用列表式多标签损失进行训练。\n\n**§5 与已有方法的核心技术差异（200字以上）**\n本文方法与现有代表性工作存在本质区别：\n1.  **与语义密集检索方法（ANCE, TAS-B, coCondensor, Contriever）的区别**：这些方法仅优化查询与工具描述之间的语义相似度（通常使用对比学习损失）。而COLT在此基础上，引入了“场景”概念和图结构，通过双视图图协作学习显式地建模工具之间的高阶协作关系。其优化目标不仅是语义匹配，更是工具集的完整性（通过列表式多标签损失和新的COMP指标驱动）。\n2.  **与词项检索方法（BM25）的区别**：BM25完全基于词汇匹配，无法理解语义和协作关系。COLT使用神经网络学习语义和协作表示，能处理词汇不匹配和复杂意图。\n3.  **与可能使用图神经网络的通用推荐/检索系统的区别**：虽然都使用GNN，但COLT的图结构是专门为工具检索任务设计的。它构建了独特的“查询-场景-工具”三实体二分图，其中“场景”是一个抽象的概念，代表一组协作工具，这不同于传统推荐中“用户-物品”或“查询-文档”的图。此外，其双视图对比学习设计（场景中心vs工具中心）和列表式多标签损失都是针对“完整性”检索目标量身定制的。\n4.  **与工具学习工作中简单的工具检索（如ToolLLaMA使用的检索）的区别**：以往工作通常将工具检索视为一个预处理步骤，直接使用现成的检索器。COLT则首次将工具检索本身作为一个深入研究的问题，提出了完整的、以完整性为导向的检索框架和评估体系。",
    "methodology_and_formulas": "【三、方法论细节与关键公式】\n\n**§1 完整算法流程（伪代码级描述）**\n根据论文Algorithm 1，COLT的学习算法流程如下：\n**输入**：预训练语言模型（PLM），语义学习训练轮数 \\( E \\)，查询-场景二分图，查询-工具二分图，场景-工具二分图，学习率 \\( lr \\)，权重衰减，GNN层数 \\( I \\)，对比损失权重 \\( \\lambda \\)，温度系数 \\( \\tau \\)，列表长度 \\( L \\)。\n**输出**：训练好的COLT模型参数 \\( \\theta \\)。\n\n**步骤**：\n1.  **语义学习阶段**：\n    *   For 轮数 \\( e = 1 \\) to \\( E \\) do:\n        *   使用公式(2)计算InfoNCE损失。\n        *   使用AdamW优化器更新PLM参数。\n    *   End for.\n    *   获得初始查询表示 \\( \\mathbf{e}_q \\) 和工具表示 \\( \\mathbf{e}_t \\)。\n2.  **协作学习阶段（初始化）**：\n    *   设置场景中心视图的初始查询表示：\\( \\mathbf{e}_q^{S(0)} = \\mathbf{e}_q \\)。\n    *   根据公式(4)计算初始场景表示：\\( \\mathbf{e}_s^{S(0)} = \\frac{1}{|\\mathcal{N}_s^T|} \\sum_{t \\in \\mathcal{N}_s^T} \\mathbf{e}_t \\)。\n    *   设置工具中心视图的初始查询表示：\\( \\mathbf{e}_q^{T(0)} = \\mathbf{e}_q \\)。\n    *   设置工具中心视图的初始工具表示：\\( \\mathbf{e}_t^{T(0)} = \\mathbf{e}_t \\)。\n3.  **协作学习阶段（迭代训练）**：\n    *   While 模型未收敛 do:\n        *   For 层数 \\( i = 1 \\) to \\( I \\) do:\n            *   **场景中心视图传播**：使用公式(3)在Q-S图上进行消息传播，计算 \\( \\mathbf{e}_q^{S(i)} \\) 和 \\( \\mathbf{e}_s^{S(i)} \\)。\n            *   **工具中心视图传播**：使用公式(6)在Q-T图上进行消息传播，计算 \\( \\mathbf{e}_q^{T(i)} \\) 和 \\( \\mathbf{e}_t^{T(i)} \\)。\n        *   End for.\n        *   使用公式(5)计算场景中心视图的最终表示 \\( \\mathbf{e}_q^S, \\mathbf{e}_s^S \\)。\n        *   使用公式(7)计算工具中心视图的最终表示 \\( \\mathbf{e}_q^T, \\mathbf{e}_t^T \\)。\n        *   使用公式(8)计算工具中心视图的场景表示 \\( \\mathbf{e}_s^T \\)。\n        *   使用公式(10)和(11)计算对比损失 \\( \\mathcal{L}_Q^C \\) 和 \\( \\mathcal{L}_S^C \\)。\n        *   使用公式(14)计算列表式多标签损失 \\( \\mathcal{L}_{\\text{list}} \\)。\n        *   使用公式(15)计算总损失 \\( \\mathcal{L} = \\mathcal{L}_{\\text{list}} + \\lambda (\\mathcal{L}_Q^C + \\mathcal{L}_S^C) \\)。\n        *   使用Adam优化器更新模型所有参数。\n    *   End while.\n4.  **返回**训练好的模型。\n\n**推理时**：对于新查询 \\( q \\)，使用训练好的模型计算其与所有工具 \\( t \\in \\mathcal{T} \\) 的匹配分数 \\( \\widehat{y}(q, t) \\)（公式9），按分数降序排序，返回Top-K个工具。\n\n**§2 关键超参数与配置**\n论文中明确提及的超参数及其选择理由如下：\n1.  **语义学习阶段**：\n    *   **训练轮数 \\( E \\)**：设置为5。理由：遵循BEIR框架的常见设置，在工具检索数据集上微调5轮足以使模型收敛。\n    *   **学习率**：\\( 2e-5 \\)。理由：微调PLM的典型学习率。\n    *   **优化器**：AdamW，权重衰减0.01。\n2.  **协作学习阶段**：\n    *   **批次大小（Batch Size）**：2048。理由：较大的批次有助于对比学习和列表损失的稳定性。\n    *   **学习率**：在集合 \\( \\{1e-3, 5e-3, 1e-4, 5e-4, 1e-5\\} \\) 中仔细调整。理由：图神经网络训练需要调整学习率，作者通过网格搜索确定最佳值。\n    *   **权重衰减**：在集合 \\( \\{1e-5, 1e-6, 1e-7\\} \\) 中调整。\n    *   **GNN层数 \\( I \\)**：在 \\( \\{1, 2, 3\\} \\) 中调整。理由：控制消息传播的跳数，层数过多可能导致过平滑。\n    *   **对比损失权重 \\( \\lambda \\)**：需要调整的超参数，用于平衡列表损失和对比损失。论文未给出具体值，但表明其重要性。\n    *   **温度系数 \\( \\tau \\)**：对比损失中的超参数，控制分布尖锐程度。论文未给出具体值。\n    *   **列表长度 \\( L \\)**：构造训练样本时，每个查询对应的工具列表长度。包含 \\( N_q \\) 个真实工具和 \\( L-N_q \\) 个随机采样的负例工具。论文未给出具体值。\n3.  **评估时的K值**：\\( K \\in \\{3, 5\\} \\)。理由：考虑到数据集中每个查询的真实工具数多为1~4个，选择3和5作为检索截断值是合理的。\n\n**§3 训练/微调设置（如有）**\n1.  **训练数据构造**：使用ToolLens和ToolBench (I2, I3) 数据集。随机选择10%的数据作为测试集，其余为训练集。数据统计见表1。\n2.  **语义学习训练**：在训练集上，使用InfoNCE损失微调PLM双编码器。正例是查询的真实相关工具，负例是在批次内随机采样或其他策略（如ANCE的异步负采样）得到的工具。\n3.  **协作学习训练**：基于语义学习得到的嵌入和构建的二分图进行训练。使用Adam优化器。损失函数为公式(15)。\n4.  **初始化**：协作学习阶段的查询和工具表示初始化为语义学习阶段的输出。场景表示初始化为其关联工具表示的均值。\n\n**§4 推理阶段的工程细节**\n论文未详细描述推理阶段的工程实现细节，但可以推断：\n1.  **向量检索**：训练完成后，可以预先计算所有工具在工具中心视图下的最终表示 \\( \\mathbf{e}_t^T \\)，并存入向量数据库（如FAISS）。\n2.  **在线推理**：对于新查询，通过模型计算其场景中心视图表示 \\( \\mathbf{e}_q^S \\) 和工具中心视图表示 \\( \\mathbf{e}_q^T \\)。然后，在向量数据库中通过近似最近邻搜索，计算 \\( \\mathbf{e}_q^S \\) 与所有 \\( \\mathbf{e}_t^T \\) 的余弦相似度，以及 \\( \\mathbf{e}_q^T \\) 与所有 \\( \\mathbf{e}_t^T \\) 的余弦相似度，将两个相似度相加得到最终分数并排序。\n3.  **效率考虑**：双编码器架构利于离线索引和快速在线检索。图神经网络部分仅在训练时使用，推理时不需要进行图传播，因此不会引入额外延迟。主要开销在于计算两个查询表示与工具向量库的相似度。",
    "experimental_design": "【四、实验设计】\n\n**§1 数据集详情（每个数据集单独列出）**\n1.  **ToolLens（新构建数据集）**\n    *   **名称**：ToolLens\n    *   **规模**：总共18,770个查询，其中训练集16,893个，测试集1,877个。包含464个工具。\n    *   **领域类型**：面向日常用户查询的多领域工具集合。\n    *   **评测问题类型**：多工具场景下的检索任务。每个查询与1~3个已验证的工具相关联（即真实工具集）。\n    *   **特殊构造方法**：采用五步法人工构建，确保查询自然、简洁且意图多面性。步骤包括：工具筛选、场景挖掘、查询生成、工具聚合、查询重写。每一步都包含人工验证。\n2.  **ToolBench (I2)**\n    *   **名称**：ToolBench (Instruction 2 subset)\n    *   **规模**：总共82,507个查询，训练集74,257，测试集8,250。包含11,473个工具。\n    *   **领域类型**：广泛的API工具集合。\n    *   **评测问题类型**：多工具场景下的检索任务。每个查询与2~4个工具相关联。\n    *   **数据过滤**：作者选择了ToolBench中专注于多工具任务的I2和I3子集，排除了单工具场景的I1子集。\n3.  **ToolBench (I3)**\n    *   **名称**：ToolBench (Instruction 3 subset)\n    *   **规模**：总共23,734个查询，训练集21,361，测试集2,373。包含1,419个工具。\n    *   **领域类型**：广泛的API工具集合。\n    *   **评测问题类型**：多工具场景下的检索任务。每个查询与2~4个工具相关联。\n\n**§2 评估指标体系（全量列出）**\n1.  **准确性指标**：\n    *   **Recall@K (R@K)**：在检索出的Top-K个工具中，命中真实工具的比例。\n    *   **NDCG@K (N@K)**：衡量Top-K检索列表的排序质量，考虑工具的相关性等级（此处为二元相关）。\n    *   **COMP@K (C@K)**：**本文新提出的完整性指标**。计算方式：\\( \\mathrm{COMP}@K = \\frac{1}{|Q|} \\sum_{q=1}^{|Q|} \\mathbb{I}(\\Phi_q \\subseteq \\Psi_q^K) \\)，其中 \\( \\Phi_q \\) 是查询 \\( q \\) 的真实工具集，\\( \\Psi_q^K \\) 是检索出的Top-K工具集，\\( \\mathbb{I}(\\cdot) \\) 是指示函数（当检索结果包含所有真实工具时返回1，否则返回0）。该指标直接衡量检索集是否完整覆盖了真实需求。\n    *   报告时 \\( K \\in \\{3, 5\\} \\)。\n2.  **下游任务评估指标（用于验证检索有效性）**：\n    *   使用GPT-4作为评判员，对基于不同检索模型得到的工具所生成的LLM回答进行两两比较，评估四个维度：连贯性（Coherence）、相关性（Relevance）、全面性（Comprehensiveness）、整体质量（Overall）。\n    *   采用**Elo评分系统**量化模型相对能力。初始分1000，K因子32。为消除顺序偏差，每个比较进行两次（交换回答顺序），并重复计算10000次使用不同随机种子。最终得到每个模型在每个维度上的Elo分数。\n\n**§3 对比基线（完整枚举）**\n1.  **BM25**：经典的词项检索模型，基于倒排索引和精确词项匹配。类型：词项检索。代表性：是信息检索领域的强基线，在工具检索文献[8,28]中常被用作基线。使用与本文相同的工具描述文本。\n2.  **ANCE (Zero-shot)**：异步负采样训练的双编码器密集检索模型。类型：语义检索（PLM-based）。代表性：在零样本检索任务上表现良好的模型。直接使用预训练模型，未在工具数据集上微调。\n3.  **ANCE (+Fine-tune)**：在工具检索数据集上微调后的ANCE模型。类型：语义检索（PLM-based）。代表性：展示了传统密集检索方法在领域微调后的性能上限。\n4.  **TAS-B (Zero-shot & +Fine-tune)**：使用平衡边际采样的双编码器模型。类型：语义检索（PLM-based）。代表性：另一种高效的密集检索方法。\n5.  **coCondensor (Zero-shot & +Fine-tune)**：使用查询无关对比损失进行预训练的模型。类型：语义检索（PLM-based）。代表性：通过改进预训练提升检索性能的模型。\n6.  **Contriever (Zero-shot & +Fine-tune)**：利用逆完形填空任务等进行预训练的模型。类型：语义检索（PLM-based）。代表性：在零样本检索上表现优异的模型。\n**注**：所有“+Fine-tune”基线都使用与COLT语义学习阶段相同的设置（在相同数据集上微调PLM），但不包含协作学习阶段。因此，COLT与“+Fine-tune”基线的对比，可以清晰显示协作学习带来的增益。\n\n**§4 实验控制变量与消融设计**\n1.  **控制变量**：所有基于PLM的基线（ANCE, TAS-B, coCondensor, Contriever）在微调时使用相同的框架（BEIR）、训练轮数（5）、学习率（2e-5）、优化器（AdamW）和权重衰减（0.01），确保比较的公平性。\n2.  **消融设计**：为了验证COLT各个组件的有效性，设计了4个消融变体（见核心架构§4），并在ToolLens和ToolBench (I3) 数据集上评估其性能。评估指标采用Recall@|N|和COMP@|N|，其中|N|是每个查询的真实工具数量，这使得指标对不同的查询更具个性化。通过比较完整模型与各消融变体的性能下降程度，来量化每个组件（语义学习、协作学习、列表式损失、对比学习）的贡献。",
    "core_results": "【五、核心实验结果】\n\n**§1 主实验结果全景（表格式呈现）**\n以下数据基于论文表3，展示了在ToolLens、ToolBench I2、ToolBench I3三个数据集上，不同检索方法在Recall@3/5 (R@3/5)、NDCG@3/5 (N@3/5)、COMP@3/5 (C@3/5) 指标上的表现。最佳结果用†标记。\n\n**格式**：方法名 (框架) | R@3 | R@5 | N@3 | N@5 | C@3 | C@5 | (对于ToolBench I2和I3，指标顺序相同)\n\n**ToolLens数据集结果**：\n- BM25 (-) | 21.58 | 26.88 | 23.19 | 26.09 | 3.89 | 6.13\n- ANCE (Zero-shot) | 20.82 | 26.56 | 21.45 | 24.57 | 5.06 | 7.46\n- ANCE (+Fine-tune) | 80.62 | 94.17 | 82.35 | 90.15 | 54.23 | 85.83\n- ANCE (+COLT) | 92.15 | **97.78†** | 92.78 | 96.10 | 80.50 | 94.40\n- TAS-B (Zero-shot) | 19.10 | 23.71 | 19.81 | 22.33 | 5.17 | 7.14\n- TAS-B (+Fine-tune) | 81.26 | 94.06 | 82.54 | 89.94 | 54.66 | 85.72\n- TAS-B (+COLT) | 91.49 | 96.91 | 92.48 | 95.63 | 79.00 | 92.22\n- coCondensor (Zero-shot) | 15.33 | 19.37 | 16.15 | 18.32 | 3.02 | 5.33\n- coCondensor (+Fine-tune) | 82.37 | 94.69 | 83.90 | 91.06 | 56.37 | 86.73\n- coCondensor (+COLT) | 92.65 | **97.78†** | 93.16 | 96.17 | 82.25 | **94.56†**\n- Contriever (Zero-shot) | 25.67 | 31.15 | 26.96 | 29.95 | 7.46 | 9.80\n- Contriever (+Fine-tune) | 83.58 | 95.17 | 84.98 | 91.69 | 59.46 | 88.65\n- Contriever (+COLT) | **93.64†** | 97.75 | **94.53†** | **96.91†** | **84.55†** | 94.08\n\n**ToolBench I2数据集结果**：\n- BM25 (-) | 17.06 | 21.38 | 17.83 | 19.88 | 2.39 | 4.37\n- ANCE (Zero-shot) | 20.82 | 26.56 | 21.45 | 24.57 | 5.06 | 7.46\n- ANCE (+Fine-tune) | 58.58 | 67.20 | 58.58 | 63.75 | 26.46 | 42.80\n- ANCE (+COLT) | 70.76 | 80.59 | 73.64 | 77.98 | 45.10 | 62.93\n- TAS-B (Zero-shot) | 19.10 | 23.71 | 19.81 | 22.33 | 5.17 | 7.14\n- TAS-B (+Fine-tune) | 62.78 | 67.49 | 58.96 | 64.21 | 26.74 | 43.66\n- TAS-B (+COLT) | 71.64 | 81.12 | 74.60 | 78.74 | 46.77 | 64.38\n- coCondensor (Zero-shot) | 15.33 | 19.37 | 16.15 | 18.32 | 3.02 | 5.30\n- coCondensor (+Fine-tune) | 57.70 | 69.46 | 60.80 | 66.07 | 28.78 | 46.06\n- coCondensor (+COLT) | 73.91 | 83.47 | 76.75 | 80.87 | 49.15 | 67.75\n- Contriever (Zero-shot) | 25.67 | 31.15 | 26.96 | 29.95 | 7.46 | 9.80\n- Contriever (+Fine-tune) | 58.89 | 70.75 | 62.11 | 67.42 | 29.77 | 48.31\n- Contriever (+COLT) | **75.72†** | **85.03†** | **78.57†** | **82.54†** | **51.97†** | **70.10†**\n\n**ToolBench I3数据集结果**：\n- BM25 (-) | 29.33 | 35.88 | 32.20 | 35.08 | 5.52 | 9.78\n- ANCE (Zero-shot) | 21.55 | 26.38 | 23.44 | 25.60 | 2.44 | 4.59\n- ANCE (+Fine-tune) | 65.11 | 76.63 | 69.27 | 74.14 | 34.68 | 53.64\n- ANCE (+COLT) | 73.37 | 83.97 | 77.95 | 82.14 | 46.01 | 66.41\n- TAS-B (Zero-shot) | 25.32 | 31.15 | 27.80 | 30.36 | 3.84 | 6.40\n- TAS-B (+Fine-tune) | 66.04 | 77.64 | 70.41 | 75.34 | 35.69 | 55.75\n- TAS-B (+COLT) | 74.49 | 84.58 | 79.03 | 82.95 | 48.16 | 68.35\n- coCondensor (Zero-shot) | 20.80 | 25.24 | 23.21 | 25.10 | 2.07 | 3.75\n- coCondensor (+Fine-tune) | 66.97 | 79.30 | 71.20 | 76.50 | 37.08 | 58.66\n- coCondensor (+COLT) | 75.48 | 84.97 | 80.00 | 83.55 | 49.17 | **68.64†**\n- Contriever (Zero-shot) | 31.37 | 38.60 | 34.13 | 37.37 | 6.03 | 11.42\n- Contriever (+Fine-tune) | 68.58 | 80.05 | 72.86 | 77.69 | 39.70 | 60.89\n- Contriever (+COLT) | **76.63†** | **85.50†** | **81.21†** | **84.18†** | **52.00†** | 68.47\n\n**§2 分任务/分场景深度分析（每个维度100字以上）**\n1.  **跨数据集性能一致性**：COLT在三个数据集（ToolLens, ToolBench I2, I3）上，无论使用哪种PLM骨干网络（ANCE, TAS-B, coCondensor, Contriever），在几乎所有指标（R, N, C）上都一致地超越了对应的微调基线（+Fine-tune）。这证明了COLT框架的鲁棒性和泛化能力。\n2.  **在COMP@K指标上的巨大提升**：COLT最显著的提升体现在其新提出的COMP@K指标上，这直接反映了其完整性检索的设计目标。例如，在ToolLens数据集上，使用Contriever骨干时，COLT将COMP@3从微调基线的59.46提升至84.55（绝对提升25.09个点，相对提升42.2%）。在ToolBench I2上，COMP@3从29.77提升至51.97（绝对提升22.2个点，相对提升74.6%）。这表明COLT能更有效地确保检索到的Top-K工具集完整覆盖真实需求。\n3.  **在Recall和NDCG上的同步提升**：尽管COLT主要优化完整性，但它在传统指标Recall和NDCG上也取得了显著提升。例如在ToolLens上，Contriever+COLT的R@3达到93.64，比微调基线83.58提升了10.06个点。这说明捕获工具协作关系不仅有助于完整性，也能提高单个工具的相关性排序质量。\n4.  **骨干网络的影响**：在不同PLM骨干上，COLT都带来了增益，但增益幅度不同。总体而言，在零样本和微调场景下表现更好的骨干（如Contriever），在结合COLT后也能达到更高的绝对性能。这表明COLT可以兼容并增强各种先进的密集检索模型。\n5.  **与BM25和零样本基线的对比**：传统密集检索模型在零样本场景下性能甚至不及BM25，这凸显了工具检索任务的领域特殊性。而经过微调后，PLM方法大幅超越BM25。COLT进一步拉大了这个差距，尤其是在完整性指标上。\n\n**§3 效率与开销的定量对比**\n论文**未提供**关于推理延迟、Token消耗、显存占用等效率指标的定量数据。效率对比仅限于模型参数量的一个观察：**BERT-mini (11M参数) 结合COLT框架的性能超过了BERT-large (340M参数)**，后者参数量是前者的30倍。这暗示COLT框架可能通过更高效地利用协作信息，使得小模型也能达到甚至超过大模型的检索效果，从而在部署时具有潜在的计算效率优势。但缺乏具体的延迟和内存数据。\n\n**§4 消融实验结果详解**\n根据论文表5（在ToolLens和ToolBench I3上，使用Recall@|N|和COMP@|N|指标），以Contriever为骨干的消融结果为例（数值为百分比）：\n1.  **完整COLT**：R@|N|: 92.76 (ToolLens), 75.40 (ToolBench I3); C@|N|: 82.95 (ToolLens), 49.81 (ToolBench I3)。\n2.  **w/o semantic learning (移除语义学习)**：性能急剧下降。ToolLens上 R@|N| 从92.76降至65.21（下降29.7%），C@|N| 从82.95降至30.90（下降62.8%）。这证实了语义学习作为基础的必要性，没有良好的初始语义表示，图学习无法有效进行。\n3.  **w/o collaborative learning (移除协作学习)**：即退化为纯语义检索（微调Contriever）。ToolLens上 C@|N| 从82.95降至54.44（下降34.4%）。这证明了协作学习模块对于提升完整性（C@|N|）的关键作用。\n4.  **w/o list-wise learning (移除列表式学习)**：ToolLens上 C@|N| 从82.95降至54.93（下降33.8%）。这表明列表式多标签损失对于促使模型平等关注所有真实工具、优化完整性目标至关重要。\n5.  **w/o contrastive learning (移除对比学习)**：ToolLens上 C@|N| 从82.95降至60.52（下降27.0%）。这表明双视图对比学习有助于对齐场景中心和工具中心视图的表示，从而更好地集成协作信息。\n**结论**：所有组件都对最终性能有正向贡献，其中**语义学习是基础，协作学习是提升完整性的核心，列表式损失和对比学习是重要的优化手段**。\n\n**§5 案例分析/定性分析（如有）**\n论文未提供具体的成功/失败案例细节分析，但通过图1(b)和3.4.1节的描述，给出了一个典型的多工具查询示例及其阐释：\n-   **查询**：“计算5盎司黄金加上100万股亚马逊股票的人民币价值”。\n-   **所需工具集（场景）**：黄金价格查询工具、股票价格查询工具（AMZN）、货币汇率转换工具（USD to CNY）。\n-   **传统语义检索的失败案例**：可能只检索到多个股票价格工具（因为“股票”在查询中突出），而遗漏了黄金价格和汇率工具，导致答案不完整。\n-   **COLT的成功机制**：通过将这三个工具关联到同一个“金融计算”场景，并在图学习中强化这种协作关系，使得在检索时倾向于同时返回这三个互补的工具，从而确保完整性。\n此外，论文通过下游工具学习实验（表4）间接提供了定性证据：使用COLT检索到的工具，能让LLM生成在连贯性、相关性、全面性和整体上获得更高Elo评分的回答，这从应用层面验证了COLT检索结果的有效性和完整性。",
    "conclusion_and_future_work": "【六、结论与未来工作】\n\n**§1 本文核心贡献总结**\n1.  **问题定义与洞察**：首次在工具检索领域明确提出并形式化了“完整性”问题，指出传统仅基于语义匹配的检索方法在多工具场景下的不足，即容易检索到冗余的相似工具而遗漏必需的互补工具。\n2.  **方法创新**：提出了COLT，一个新颖的、模型无关的协作学习工具检索框架。其核心是引入“场景”概念，并构建“查询-场景-工具”二分图，通过双视图图对比学习和列表式多标签损失，显式地建模和优化工具间的协作关系，以实现完整性导向的检索。\n3.  **评估体系创新**：提出了新的评估指标COMP@K，专门用于衡量工具检索的完整性。该指标比传统的Recall和NDCG更能反映检索结果对下游LLM任务的实际效用。\n4.  **数据集贡献**：构建并开源了ToolLens数据集，该数据集包含自然、简洁且意图多面性的查询，以及高质量的多工具标注，弥补了现有数据集（如ToolBench）的不足，为未来研究提供了更好的基准。\n5.  **实验验证**：在多个数据集和骨干模型上的广泛实验表明，COLT在检索准确性（Recall, NDCG）和完整性（COMP）上均显著优于现有最先进的密集检索方法，并能有效提升下游工具学习的性能。\n\n**§2 局限性（作者自述）**\n原文中作者**未明确列出**方法的局限性。通常论文会在结论或未来工作部分讨论局限，但本文未提供。需要从上下文中推断潜在的、作者可能未提及的局限（见第八部分教授锐评）。\n\n**§3 未来研究方向（全量提取）**\n原文在摘要和结论中提到了未来工作方向，但较为概括：\n1.  **促进工具检索的未来研究**：作者声明将公开ToolLens数据集，以促进工具检索领域的未来研究。这表明他们希望社区能在他们构建的数据集和提出的评估指标基础上，开展进一步的工作。\n2.  **更广泛的应用与探索**：论文结论部分提到“我们的工作为LLMs更有效、更可靠地利用外部工具铺平了道路”，暗示未来可以探索COLT框架在更广泛的工具学习场景、更复杂的LLM-agent系统中的应用。\n**注**：论文未提供更具体、技术性的未来研究方向列表（如扩展到动态工具库、处理工具冲突等）。",
    "research_contributions": "【七、研究贡献与学术价值】\n\n**§1 核心学术贡献（按重要性排序）**\n1.  **提出了完整性导向的工具检索新范式**：\n    *   **理论新颖性**：将工具检索的目标从传统的“语义相关性排序”重新定义为“完整性覆盖”，这是一个重要的范式转变。为此引入了“场景”作为中介抽象来形式化工具间的协作关系。\n    *   **实验验证充分性**：通过新提出的COMP指标、在多个数据集上的主实验、以及下游任务评估，全面验证了完整性目标的重要性和COLT在该目标上的有效性。\n    *   **对领域的影响**：为工具学习社区提供了一个更贴近实际应用需求的检索问题定义和评估标准，可能引导后续研究朝此方向发展。\n2.  **设计了融合图协作学习的检索框架（COLT）**：\n    *   **理论新颖性**：首次将图神经网络和双视图对比学习系统性地应用于工具检索任务，以建模高阶工具协作关系。列表式多标签损失的设计也针对完整性优化目标。\n    *   **实验验证充分性**：广泛的实验和消融研究证明了每个组件的有效性，并且框架是模型无关的，能适配多种PLM骨干并带来一致提升。\n    *   **对领域的影响**：提供了一种可扩展的、强大的工具检索方法新蓝图，展示了结合语义学习和结构学习（图学习）的潜力。\n3.  **构建了高质量的ToolLens数据集和COMP评估指标**：\n    *   **理论新颖性**：COMP指标简单直接地量化了完整性，填补了评估体系的空白。ToolLens的构建方法强调了查询的自然性和意图多面性。\n    *   **实验验证充分性**：通过GPT-4和人工评估验证了ToolLens相对于现有数据集的优势（见表2）。COMP指标与下游任务性能（Elo评分）显示出正相关性。\n    *   **对领域的影响**：为社区提供了急需的基准数据和评估工具，有助于进行更公平、更有意义的比较，并推动数据质量标准的提升。\n\n**§2 工程与实践贡献**\n1.  **开源代码与数据**：作者公开了COLT的源代码和ToolLens数据集，这极大地促进了研究的可复现性和该领域的后续发展。\n2.  **高效的框架设计**：COLT的两阶段设计（语义学习+协作学习）在推理时无需进行耗时的图传播，保持了双编码器检索架构的高效性，便于实际部署。\n3.  **模型无关性**：COLT可以灵活地与各种预训练语言模型结合，为实践者提供了根据计算资源选择骨干模型的自由（例如，使用轻量级BERT-mini也能取得良好效果）。\n\n**§3 与相关工作的定位**\n本文在当前技术路线图中处于一个**开创性延伸**的位置。它并非完全开辟新路线，而是在两个成熟路线的交叉点进行深度创新：\n1.  **工具学习路线**：以往工作（如ToolLLaMA, ART）主要关注LLM如何调用和使用工具，而将工具检索视为一个简单的预处理步骤（使用现成检索器）。本文**首次将工具检索本身提升为一个需要深入研究的关键子问题**，并为其设计了专门的解决方案。\n2.",
    "source_file": "Towards Completeness-Oriented Tool Retrieval for Large Language Models.md"
}