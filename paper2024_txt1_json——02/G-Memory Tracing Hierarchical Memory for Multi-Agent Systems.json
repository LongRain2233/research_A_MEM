{
    "title": "G-Memory: Tracing Hierarchical Memory for Multi-Agent Systems",
    "background_and_problem": "**§1 领域背景与研究动机（150字以上）**\n本文研究领域是**大语言模型驱动的多智能体系统**。随着单智能体在感知、规划、推理和行动方面展现出强大能力，由多个LLM智能体协作构成的**多智能体系统**被证明能够超越单个模型的认知和执行边界，在代码生成、数据分析、具身任务等领域取得显著进展。然而，当前MAS的一个核心瓶颈在于其**自我演化能力**严重不足，即系统无法通过与环境交互持续学习和改进。这种自我演化能力的核心驱动力是**记忆机制**。本文旨在解决**如何为多智能体系统设计一个能够存储、检索和管理其冗长交互历史的记忆机制**，使得智能体团队能够从简洁、有指导性的经验和洞察中受益。\n\n**§2 现有技术的核心短板——具体失败模式（250字以上）**\n现有方法在MAS场景下存在三类核心短板：\n1.  **缺乏跨任务记忆的MAS框架**：如LLM-Debate、Mixture-of-Agent等方法完全**省略了记忆组件**，导致每次任务都从零开始，无法积累经验。\n2.  **仅包含简单任务内记忆的MAS框架**：如Exchange-of-Thought、MacNet等方法仅采用**任务内记忆**，即在单个查询解决过程中保留上下文，但任务结束后经验被丢弃，无法实现跨任务的自我演化。\n3.  **采用粗糙跨任务记忆的MAS框架**：如MetaGPT、ChatDev等方法虽然尝试跨任务记忆，但仅将记忆**压缩为最终解决方案或执行结果等“工件”**。例如，当输入一个复杂的具身任务（如“将干净的布放在台面上”）时，这些方法仅存储“任务成功/失败”的标签，而**完全忽略了导致成功或失败的、包含多轮智能体间协作的精细交互轨迹**。这种设计导致系统无法从过去的协作模式、错误中学习，记忆效用极低。\n此外，将单智能体记忆机制（如Voyager, MemoryBank）直接迁移到MAS也失败。当输入MAS产生的**冗长交互轨迹（可达单智能体10倍Token量）**时，这些基于检索的方法会不加抽象地将整个长上下文喂给LLM，导致**信息过载**，并在需要角色分工的任务（如PDDL策略游戏）中表现下降，例如Voyager使AutoGen在PDDL上的性能下降4.17%。\n\n**§3 问题的根本难点与挑战（200字以上）**\n问题的根本难点源于MAS与单智能体在交互模式上的本质差异：\n1.  **交互轨迹的极端长度与复杂性**：MAS涉及多个智能体之间的多轮编排，产生的对话轨迹长度可达单智能体的10倍（如图1左所示）。这给基于检索的记忆设计带来了**巨大的上下文窗口压力和信息过载风险**。\n2.  **协作经验的抽象与泛化困难**：MAS的记忆不仅需要存储原始对话，更需要从中提炼出**可泛化的协作模式、分工策略和高层洞察**。如何从海量、细粒度的交互中自动抽取出对未来任务有指导意义的“经验教训”，是一个认知层面的挑战。\n3.  **角色特定的记忆支持需求**：MAS中的智能体扮演不同角色（如规划者、执行者、评审者）。有效的记忆机制需要为每个角色**提供定制化的记忆线索**，而非“一刀切”的全局记忆。现有方法缺乏这种细粒度、角色感知的记忆分配能力。\n4.  **记忆结构的动态演化**：随着任务不断执行，记忆库需要持续更新，并维护不同粒度记忆单元（从具体话轮到高层洞察）之间的关联。如何设计一个**能随经验增长而有机演化的层次化记忆结构**，是系统工程上的挑战。\n\n**§4 本文的切入点与核心假设（200字以上）**\n本文的切入点是**借鉴组织记忆理论**，该理论认为人类组织的知识是层次化、结构化的。基于此，本文提出核心假设：**将MAS的冗长、复杂的交互历史组织成一个三层的图层次结构，可以有效地支持存储、检索和演化，从而赋能MAS的自我演化**。\n具体而言，本文假设：\n1.  **分层抽象是有效的**：通过**交互图**存储原始对话、**查询图**存储任务元信息、**洞察图**存储泛化知识，可以从不同粒度捕捉MAS经验。\n2.  **双向记忆遍历是关键**：面对新查询时，同时**向上遍历**检索高层洞察（提供战略指导）和**向下遍历**检索核心交互子图（提供具体程序性知识），能为MAS提供多粒度记忆支持。\n3.  **图结构能编码关系**：用图来建模记忆单元（查询、洞察、话轮）之间的语义、时序和逻辑关联，比简单的扁平列表或键值存储更能反映MAS协作的本质。\n4.  **记忆更新应是智能体驱动的**：任务完成后，由LLM驱动对三层图结构进行联合更新，实现“群体知识的制度化”。该假设基于LLM具备总结、关联和抽象的能力。",
    "core_architecture": "**§1 系统整体架构概览（200字以上）**\nG-Memory是一个**可插拔的层次化记忆系统**，其整体架构围绕三个核心图结构组织，数据流如下：\n**输入新用户查询Q → 触发G-Memory → 阶段1：粗粒度记忆检索**：在查询图 \\(\\mathcal{G}_{\\text{query}}\\) 上基于嵌入相似度检索Top-k个相关历史查询节点，并进行1-hop图扩展，得到扩展查询集 \\(\\tilde{\\mathcal{Q}}^{\\mathcal{S}}\\)。\n**→ 阶段2：双向记忆遍历**：\n    *   **向上遍历（查询图→洞察图）**：通过投影函数 \\(\\Pi_{\\mathcal{Q} \\rightarrow \\mathcal{I}}\\)，找出那些支持查询集与 \\(\\tilde{\\mathcal{Q}}^{\\mathcal{S}}\\) 有交集的洞察节点，得到高层洞察集 \\(\\mathcal{I}^{\\mathcal{S}}\\)。\n    *   **向下遍历（查询图→交互图）**：使用LLM驱动的相关度评分器 \\(\\mathcal{R}_{\\mathrm{LLM}}\\) 从扩展查询集中选出Top-M个最相关查询，并对每个查询对应的原始交互图 \\(\\mathcal{G}_{\\text{inter}}^{(Q_j)}\\) 应用LLM驱动的图稀疏器 \\(\\mathcal{S}_{\\mathrm{LLM}}\\)，提取出核心交互子图 \\(\\{\\hat{\\mathcal{G}}_{\\text{inter}}^{Q_i}\\}_{i=1}^{|M|}\\)。\n**→ 阶段3：角色特定记忆注入**：通过算子 \\(\\Phi\\)，根据每个智能体的角色 \\(\\mathsf{Role}_i\\) 和当前任务Q，评估并过滤检索到的洞察和交互子图，初始化每个智能体的内部记忆状态 \\(\\mathsf{Mem}_i\\)。\n**→ MAS执行任务**：记忆增强后的MAS按标准流程执行，产生最终解决方案 \\(a^{(T)}\\) 和反馈。\n**→ 阶段4：层次化记忆更新**：基于任务结果，更新三层图：构建新交互图、在查询图中添加新节点并建立边、在洞察图中生成新洞察并更新关联。\n**最终输出**：赋能MAS执行任务，并更新其内部记忆知识库。\n\n**§2 各核心模块深度拆解（每个模块100字以上，共至少3个模块）**\n#### 模块一：粗粒度检索模块 (Coarse-grained Memory Retrieval)\n-   **输入**：新用户查询 \\(Q\\) 的文本，以及现有的查询图 \\(\\mathcal{G}_{\\text{query}}\\)。\n-   **核心处理逻辑**：\n    1.  **嵌入与相似度计算**：使用MiniLM等模型将查询 \\(Q\\) 和查询图中的每个节点 \\(q_i\\) 映射为固定长度嵌入向量 \\(\\mathbf{v}(\\cdot)\\)，计算余弦相似度 \\(\\frac{\\mathbf{v}(Q) \\cdot \\mathbf{v}(q_i)}{|\\mathbf{v}(Q)| |\\mathbf{v}(q_i)|}\\)。\n    2.  **Top-k检索**：根据相似度得分检索出最相关的 \\(k\\) 个查询节点，形成初始相关集 \\(\\mathcal{Q}^{\\mathcal{S}}\\)（公式(4)）。超参数 \\(k\\) 在{1, 2}中选择。\n    3.  **1-hop图扩展**：将 \\(\\mathcal{Q}^{\\mathcal{S}}\\) 中每个节点的所有一阶邻居（入边和出边节点）加入，形成扩展查询集 \\(\\tilde{\\mathcal{Q}}^{\\mathcal{S}}\\)（公式(5)）。论文发现1-hop效果最佳，2-hop和3-hop会引入噪声。\n-   **输出**：扩展后的相关查询节点集合 \\(\\tilde{\\mathcal{Q}}^{\\mathcal{S}}\\)。\n-   **设计理由**：直接相似度检索可能只捕捉到表面相似性。利用查询图本身的拓扑结构进行扩展，可以找到那些语义不同但逻辑相关（通过中间查询连接）的历史任务，从而提供更丰富的记忆线索。\n\n#### 模块二：双向记忆遍历模块 (Bi-directional Memory Traversal)\n-   **输入**：扩展查询集 \\(\\tilde{\\mathcal{Q}}^{\\mathcal{S}}\\)、洞察图 \\(\\mathcal{G}_{\\text{insight}}\\)、交互图集合、当前查询 \\(Q\\)。\n-   **核心处理逻辑**：\n    *   **向上遍历（检索洞察）**：执行查询到洞察的投影：\\(\\mathcal{I}^{\\mathcal{S}} = \\Pi_{\\mathcal{Q} \\rightarrow \\mathcal{I}}(\\tilde{\\mathcal{Q}}^{\\mathcal{S}}) = \\{\\iota_k \\in \\mathcal{I} \\mid \\Omega_k \\cap \\tilde{\\mathcal{Q}}^{\\mathcal{S}} \\neq \\emptyset \\}\\)（公式(6)）。即，找出所有支持查询集与当前相关查询集有交集的洞察节点。\n    *   **向下遍历（检索核心交互）**：\n        1.  **相关性重排序**：使用LLM评分器 \\(\\mathcal{R}_{\\mathrm{LLM}}(Q, q'_k)\\) 对 \\(\\tilde{\\mathcal{Q}}^{\\mathcal{S}}\\) 中的查询进行重新评分，选出Top-M个最相关的查询。超参数 \\(M\\) 在{2,3,4,5}中调优。\n        2.  **图稀疏化**：对于选出的每个查询 \\(Q_j\\)，将其对应的完整交互图 \\(\\mathcal{G}_{\\text{inter}}^{(Q_j)}\\) 输入给LLM驱动的稀疏器 \\(\\mathcal{S}_{\\mathrm{LLM}}\\)，该稀疏器识别并保留对当前任务 \\(Q\\) 最关键的对话元素（话轮和边），输出压缩后的核心子图 \\(\\hat{\\mathcal{G}}_{\\text{inter}}^{(Q_j)}\\)（公式(7)）。\n-   **输出**：高层洞察集合 \\(\\mathcal{I}^{\\mathcal{S}}\\) 和核心交互子图集合 \\(\\{\\hat{\\mathcal{G}}_{\\text{inter}}^{Q_i}\\}_{i=1}^{|M|}\\)。\n-   **设计理由**：同时提供抽象洞察和具体轨迹，满足MAS不同层面的记忆需求。洞察提供战略方向（如“避免错误指代”），而核心交互子图提供可模仿的具体协作模式。使用LLM进行重排序和稀疏化，比单纯基于嵌入的方法更能理解任务语义和对话结构。\n\n#### 模块三：角色特定记忆注入模块 (Role-specific Memory Injection)\n-   **输入**：检索到的洞察集 \\(\\mathcal{I}^{\\mathcal{S}}\\)、核心交互子图集 \\(\\{\\hat{\\mathcal{G}}_{\\text{inter}}^{Q_i}\\}_{i=1}^{|M|}\\)、每个智能体的角色描述 \\(\\mathsf{Role}_i\\)、当前查询 \\(Q\\)。\n-   **核心处理逻辑**：通过算子 \\(\\Phi\\) 为每个智能体 \\(C_i\\) 初始化其记忆 \\(\\mathsf{Mem}_i\\)。\\(\\Phi\\) 的实现（根据附录C）涉及一个LLM，其提示词要求评估每个洞察 \\(\\iota_k\\) 和每个交互子图 \\(\\hat{\\mathcal{G}}_{\\text{inter}}^{(Q_j)}\\) 对于特定角色 \\(\\mathsf{Role}_i\\) 执行当前任务 \\(Q\\) 的**效用和相关性**。基于评估结果，LLM会过滤、总结或直接选择最相关的记忆片段，并格式化后放入该智能体的记忆上下文中。\n-   **输出**：更新每个智能体的记忆状态 \\(\\mathsf{Mem}_i\\)，为其后续参与MAS推理周期做好准备。\n-   **设计理由**：MAS中智能体职责不同，规划者需要高层策略，执行者需要具体操作步骤。统一的全局记忆会导致信息冗余或缺失。此模块确保每个智能体只获得与其角色最相关的记忆，提高记忆利用效率。\n\n**§3 关键公式与算法（如有）**\n1.  **粗粒度检索公式**：\n    \\[\n    \\mathcal{Q}^{\\mathcal{S}} = \\underset{q_i \\in \\mathcal{Q} \\text{ s.t. } |\\mathcal{Q}^{\\mathcal{S}}| = k}{\\arg\\operatorname{top-k}} \\left(\\frac{\\mathbf{v}(Q) \\cdot \\mathbf{v}(q_i)}{|\\mathbf{v}(Q)| |\\mathbf{v}(q_i)|}\\right)\n    \\]\n2.  **查询图扩展公式**：\n    \\[\n    \\tilde{\\mathcal{Q}}^{\\mathcal{S}} = \\mathcal{Q}^{\\mathcal{S}} \\cup \\left\\{Q_k \\in \\mathcal{Q} \\mid \\exists Q_j \\in \\mathcal{Q}^{\\mathcal{S}}, Q_k \\in \\mathcal{N}^{+}(Q_j) \\cup \\mathcal{N}^{-}(Q_j) \\right\\}\n    \\]\n3.  **向上遍历（洞察检索）公式**：\n    \\[\n    \\mathcal{I}^{\\mathcal{S}} = \\Pi_{\\mathcal{Q} \\rightarrow \\mathcal{I}}(\\tilde{\\mathcal{Q}}^{\\mathcal{S}}), \\quad \\Pi_{\\mathcal{Q} \\rightarrow \\mathcal{I}}(\\mathcal{S}_q) \\triangleq \\left\\{\\iota_k \\in \\mathcal{I} \\mid \\Omega_k \\cap \\mathcal{S}_q \\neq \\emptyset \\right\\}\n    \\]\n4.  **向下遍历（核心交互检索）公式**：\n    \\[\n    \\left\\{\\hat{\\mathcal{G}}_{\\text{inter}}^{Q_i}\\right\\}_{i=1}^{|M|} = \\left\\{\\mathcal{S}_{\\mathrm{LLM}}\\left(\\mathcal{G}_{\\text{inter}}^{(Q_j)}, Q\\right) \\mid q_j \\in \\underset{\\{q'_k \\in \\tilde{\\mathcal{Q}}^{\\mathcal{S}}\\} \\text{ s.t. } |\\cdot| = M}{\\operatorname{argtop-M}} \\mathcal{R}_{\\mathrm{LLM}}(Q, q'_k) \\right\\}\n    \\]\n\n**§4 方法变体对比（如有多个变体/消融组件）**\n论文进行了消融实验，对比了G-Memory的两个变体：\n1.  **仅洞察变体 (Insight-only)**：仅启用向上遍历，为智能体提供高层洞察 \\(\\mathcal{I}^{\\mathcal{S}}\\)，而不提供细粒度交互子图。\n2.  **仅交互变体 (Interaction-only)**：仅启用向下遍历，为智能体提供核心交互子图 \\(\\{\\hat{\\mathcal{G}}_{\\text{inter}}^{Q_i}\\}_{i=1}^{|M|}\\)，而不提供高层洞察。\n3.  **完整G-Memory**：同时启用双向遍历，提供洞察和交互子图。\n实验表明，完整版本性能最优。移除任一部分都会导致性能下降，其中移除交互部分下降更显著（AutoGen平均下降4.47%，DyLAN平均下降3.82%），表明细粒度交互轨迹的记忆贡献略大于高层洞察。\n\n**§5 与已有方法的核心技术差异（200字以上）**\n1.  **与单智能体记忆机制（如MemoryBank, Voyager）的本质区别**：\n    *   **记忆粒度与结构**：单智能体记忆通常是扁平的、基于块（chunk）的检索，而G-Memory是**层次化、图结构化的**，专门为编码多智能体间复杂的协作关系而设计。\n    *   **记忆内容**：单智能体记忆存储的是单个智能体的行动和观察序列，而G-Memory存储的是**多智能体之间的对话（交互图）以及从群体协作中提炼的洞察**。\n    *   **记忆分配**：单智能体记忆是全局统一的，而G-Memory引入了**角色特定的记忆注入**，为不同职责的智能体提供定制化记忆线索。\n2.  **与现有MAS记忆机制（如MetaGPT-M, ChatDev-M）的本质区别**：\n    *   **记忆范围与深度**：MetaGPT-M等仅存储最终解决方案（“工件”），是**极度压缩的、结果导向的**。G-Memory则存储**完整的交互轨迹**，并能通过图稀疏化提取核心子图，保留了导致成功或失败的**过程性知识**。\n    *   **记忆抽象能力**：ChatDev-M等缺乏对经验的抽象。G-Memory通过**洞察图**主动从历史交互中蒸馏出可泛化的高层知识（如“清洁物品前需先检查其状态”），这是现有MAS记忆所不具备的。\n    *   **记忆检索机制**：现有方法多基于简单相似度匹配。G-Memory采用**基于图拓扑的扩展检索**和**LLM驱动的重排序与稀疏化**，检索精度和相关性更高。\n3.  **与动态MAS构建方法（如AFlow）的区别**：AFlow等方法通过搜索为特定任务领域一次性构建复杂MAS，但**缺乏持续演化能力**。G-Memory作为一个**持续学习的记忆模块**，可以嵌入任何MAS框架，使其能够随着任务暴露量的增加而不断进化协作策略。",
    "methodology_and_formulas": "**§1 完整算法流程（伪代码级描述）**\n**算法：G-Memory 工作流**\n**输入**：新用户查询 \\(Q\\)，现有记忆层次 \\(\\mathcal{G}_{\\text{query}}, \\mathcal{G}_{\\text{insight}}, \\{\\mathcal{G}_{\\text{inter}}^{(Q_i)}\\}\\)，多智能体系统 \\(\\bar{\\mathcal{G}} = (\\mathcal{V}, \\bar{\\mathcal{E}})\\)。\n**输出**：MAS执行结果 \\(a^{(T)}\\)，更新后的记忆层次。\n\n1.  **// 阶段1：粗粒度记忆检索**\n2.  计算查询 \\(Q\\) 的嵌入 \\(\\mathbf{v}(Q)\\)。\n3.  对于查询图 \\(\\mathcal{G}_{\\text{query}}\\) 中的每个节点 \\(q_i\\)，计算其嵌入 \\(\\mathbf{v}(q_i)\\) 与 \\(\\mathbf{v}(Q)\\) 的余弦相似度。\n4.  选取相似度最高的Top-\\(k\\)个查询节点，构成集合 \\(\\mathcal{Q}^{\\mathcal{S}}\\)。\n5.  对 \\(\\mathcal{Q}^{\\mathcal{S}}\\) 中每个节点，将其在查询图上的所有一阶邻居（入边和出边节点）加入，形成扩展查询集 \\(\\tilde{\\mathcal{Q}}^{\\mathcal{S}}\\)。\n\n6.  **// 阶段2：双向记忆遍历**\n7.  **向上遍历（检索洞察）**：\n8.  \\(\\mathcal{I}^{\\mathcal{S}} \\leftarrow \\emptyset\\)\n9.  对于每个洞察图节点 \\(\\iota_k = (\\kappa_k, \\Omega_k) \\in \\mathcal{G}_{\\text{insight}}\\)：\n10.     如果 \\(\\Omega_k \\cap \\tilde{\\mathcal{Q}}^{\\mathcal{S}} \\neq \\emptyset\\)，则将 \\(\\iota_k\\) 加入 \\(\\mathcal{I}^{\\mathcal{S}}\\)。\n11. **向下遍历（检索核心交互）**：\n12. 对于 \\(\\tilde{\\mathcal{Q}}^{\\mathcal{S}}\\) 中的每个查询节点 \\(q'_k\\)，使用LLM评分器 \\(\\mathcal{R}_{\\mathrm{LLM}}(Q, q'_k)\\) 计算其与当前查询 \\(Q\\) 的相关性得分。\n13. 根据得分选取Top-\\(M\\)个最相关的查询节点，记为 \\(\\mathcal{Q}^{\\mathcal{R}}\\)。\n14. 对于 \\(\\mathcal{Q}^{\\mathcal{R}}\\) 中的每个查询 \\(Q_j\\)：\n15.     获取其对应的完整交互图 \\(\\mathcal{G}_{\\text{inter}}^{(Q_j)}\\)。\n16.     使用LLM图稀疏器 \\(\\mathcal{S}_{\\mathrm{LLM}}(\\mathcal{G}_{\\text{inter}}^{(Q_j)}, Q)\\)，提取核心交互子图 \\(\\hat{\\mathcal{G}}_{\\text{inter}}^{(Q_j)}\\)。\n17.     将 \\(\\hat{\\mathcal{G}}_{\\text{inter}}^{(Q_j)}\\) 加入集合 \\(\\{\\hat{\\mathcal{G}}_{\\text{inter}}^{Q_i}\\}_{i=1}^{|M|}\\)。\n\n18. **// 阶段3：角色特定记忆注入**\n19. 对于MAS中的每个智能体 \\(C_i = (\\mathsf{Base}_i, \\mathsf{Role}_i, \\mathsf{Mem}_i, \\mathsf{Plugin}_i) \\in \\mathcal{V}\\)：\n20.     \\(\\mathsf{Mem}_i \\leftarrow \\Phi(\\mathcal{I}^{\\mathcal{S}}, \\{\\hat{\\mathcal{G}}_{\\text{inter}}^{Q_i}\\}_{i=1}^{|M|}; \\mathsf{Role}_i, Q)\\) // 使用LLM评估并过滤记忆\n\n21. **// 阶段4：MAS执行与记忆更新**\n22. 记忆增强后的MAS \\(\\bar{\\mathcal{G}}\\) 执行查询 \\(Q\\)，经过 \\(T\\) 轮通信，产生最终解 \\(a^{(T)}\\) 和环境反馈（状态 \\(\\Psi\\)，token消耗等）。\n23. **更新交互图**：根据本轮对话记录构建新的交互图 \\(\\mathcal{G}_{\\text{inter}}^{(Q)}\\)。\n24. **更新查询图**：\n25.     创建新查询节点 \\(q_{\\text{new}} = (Q, \\Psi, \\mathcal{G}_{\\text{inter}}^{(Q)})\\)。\n26.     确定连接邻居 \\(\\mathcal{N}_{\\text{conn}} = \\mathcal{Q}^{\\mathcal{R}} \\cup (\\bigcup_{\\iota_k \\in \\mathcal{I}^{\\mathcal{S}}} \\Omega_k)\\)。\n27.     创建新边集 \\(\\mathcal{E}_{\\text{new}} = \\{(q_n, q_{\\text{new}}) \\mid q_n \\in \\mathcal{N}_{\\text{conn}}\\}\\)。\n28.     更新查询图：\\(\\mathcal{G}_{\\text{query}}^{\\text{next}} \\leftarrow (\\mathcal{Q} \\cup \\{q_{\\text{new}}\\}, \\mathcal{E}_{\\mathbf{q}} \\cup \\mathcal{E}_{\\text{new}})\\)。\n29. **更新洞察图**：\n30.     使用总结函数 \\(\\mathcal{J}\\) 生成新洞察：\\(\\iota_{\\text{new}} = (\\mathcal{J}(\\mathcal{G}_{\\text{inter}}^{(Q)}, \\Psi), \\{q_{\\text{new}}\\})\\)。\n31.     创建新边连接所用过的洞察：\\(\\mathcal{E}_{\\mathrm{i, new}} \\leftarrow \\{(\\iota_k, \\iota_{\\text{new}}, q_{\\text{new}}) \\mid \\iota_k \\in \\mathcal{I}^{\\mathcal{S}}\\}\\)。\n32.     更新所用洞察的支持查询集：对于每个 \\(\\iota_k = (\\kappa_k, \\Omega_k) \\in \\mathcal{I}^{\\mathcal{S}}\\)，更新 \\(\\Omega_k \\leftarrow \\Omega_k \\cup \\{q_{\\text{new}}\\}\\)。\n33.     更新洞察图节点集：\\(\\mathcal{I}^{\\text{next}} \\leftarrow (\\mathcal{I} \\setminus \\mathcal{I}^{\\mathcal{S}}) \\cup \\{(\\kappa_k, \\Omega_k \\cup \\{q_{\\text{new}}\\}) \\mid \\iota_k \\in \\mathcal{I}^{\\mathcal{S}}\\} \\cup \\{\\iota_{\\text{new}}\\}\\)。\n34.     最终洞察图：\\(\\mathcal{G}_{\\text{insight}}^{\\text{next}} \\leftarrow (\\mathcal{I}^{\\text{next}}, \\mathcal{E}_{\\mathrm{i}} \\cup \\mathcal{E}_{\\mathrm{i, new}})\\)。\n\n**§2 关键超参数与配置**\n-   **\\(k\\)（公式(4)）**：初始Top-k相似查询数量。**取值**：在{1, 2}中选择。**选择理由**：通过敏感性分析（图4b）发现，\\(k=1\\)或\\(2\\)效果最佳，更大的\\(k\\)（如5）会引入任务无关噪声，导致性能下降（例如在ALFWorld+AutoGen上下降7.71%）。\n-   **Hop Expansion（公式(5)）**：查询图扩展的跳数。**取值**：1-hop。**选择理由**：敏感性分析（图4a）表明，1-hop扩展在各项任务上取得最佳或接近最佳性能（如AutoGen在ALFWorld上达85.82%）。2-hop和3-hop扩展会引入不相关洞察，损害任务特定推理（如PDDL性能降至49.79%）。\n-   **\\(M\\)（公式(7)）**：向下遍历时选择的最相关交互图数量。**取值**：在{2, 3, 4, 5}中通过实验确定（具体最优值论文未明确给出，需调优）。\n-   **嵌入模型**：\\(\\mathbf{v}(\\cdot)\\) 函数使用 **ALL-MINILM-L6-V2**。\n-   **LLM骨干**：实验使用了GPT-4o-mini、Qwen-2.5-7B、Qwen-2.5-14B。G-Memory中的LLM模块（评分器 \\(\\mathcal{R}_{\\mathrm{LLM}}\\)、稀疏器 \\(\\mathcal{S}_{\\mathrm{LLM}}\\)、记忆注入器 \\(\\Phi\\)、总结器 \\(\\mathcal{J}\\)）默认使用与MAS骨干相同的LLM。\n\n**§3 训练/微调设置（如有）**\n原文未提供。G-Memory是一个**无需训练、即插即用**的模块。其所有组件（检索、评分、稀疏化、总结）均基于预训练LLM的零样本或少样本提示（prompting）完成。论文未提及对底层LLM进行任何微调。\n\n**§4 推理阶段的工程细节**\n-   **向量检索**：使用MiniLM等轻量级模型生成查询和记忆片段的嵌入，进行相似度计算。可能集成到向量数据库（如FAISS）中进行高效检索，但原文未明确说明。\n-   **图存储与遍历**：需要维护三个图数据结构（洞察图、查询图、交互图）并支持邻居查询、节点和边的增删改操作。原文未指定具体图数据库或内存数据结构。\n-   **LLM调用策略**：\n    -   **评分器 \\(\\mathcal{R}_{\\mathrm{LLM}}\\) 和稀疏器 \\(\\mathcal{S}_{\\mathrm{LLM}}\\)**：对筛选出的少量（Top-M）查询及其交互图进行调用，而非全量计算，以控制API成本/延迟。\n    -   **记忆注入器 \\(\\Phi\\)**：为每个智能体单独调用一次或批处理，以生成角色特定的记忆上下文。\n    -   **总结器 \\(\\mathcal{J}\\)**：任务结束后调用一次，生成新洞察。\n-   **并行化**：不同智能体的记忆注入过程 \\(\\Phi\\) 可以并行执行。不同历史查询的图稀疏化过程 \\(\\mathcal{S}_{\\mathrm{LLM}}\\) 也可以并行。\n-   **缓存**：查询嵌入 \\(\\mathbf{v}(q_i)\\) 可以预先计算并缓存，避免每次检索时重复计算。\n-   **部署**：对于开源LLM（Qwen系列），通过**Ollama**进行本地实例化。对于GPT系列，通过**OpenAI API**访问。",
    "experimental_design": "**§1 数据集详情（每个数据集单独列出）**\n1.  **ALFWorld**：**领域**：具身任务。**问题类型**：文本游戏中的交互任务，要求智能体在模拟家庭环境中执行如“拿起”、“清洁”、“放置”等动作。**规模**：论文未提供具体样本数。\n2.  **SciWorld**：**领域**：具身任务。**问题类型**：科学实验场景中的交互任务，涉及操作实验器材、遵循科学流程。**规模**：论文未提供具体样本数。\n3.  **PDDL**：**领域**：游戏/规划。**问题类型**：策略游戏任务，基于规划域定义语言，需要多智能体协作进行战略规划和资源分配。**规模**：论文未提供具体样本数。\n4.  **HotpotQA**：**领域**：知识推理。**问题类型**：多跳问答，需要从维基百科文章中聚合多个事实来回答问题。**规模**：论文未提供具体样本数。\n5.  **FEVER**：**领域**：知识推理。**问题类型**：事实验证，给定一个声明，需要判断其是否被维基百科证据支持。**规模**：论文未提供具体样本数。\n**注**：所有数据集的详细信息（样本数、划分等）在附录A.1中，但主文未提供。\n\n**§2 评估指标体系（全量列出）**\n-   **准确性指标**：\n    -   **成功率/准确率**：在ALFWorld、SciWorld、PDDL、HotpotQA、FEVER五个基准上报告。具体指标名未明确说明，但根据上下文，应为任务特定的**成功率（对于具身和游戏任务）**和**答案准确率（对于QA任务）**。所有结果以百分比形式呈现。\n-   **效率/部署指标**：\n    -   **Token消耗量**：测量整个系统（包括MAS框架和记忆模块）在执行任务过程中消耗的总Token数。在图3中以 \\(\\times 10^6\\) 为单位展示。\n    -   **性能-成本权衡**：通过散点图可视化不同记忆架构的性能提升与额外Token消耗之间的关系（图3）。\n-   **其他自定义指标**：论文未提出新的评估维度。\n\n**§3 对比基线（完整枚举）**\n**单智能体记忆基线（4个）**：\n1.  **No-memory**：无任何记忆机制的基线。\n2.  **Voyager**：面向具身任务的单智能体记忆方法，采用递归总结和检索。\n3.  **MemoryBank**：基于RAG的单智能体记忆，使用相似度检索记忆块。\n4.  **Generative Agents**：具有记忆和反思能力的单智能体架构，用于社会模拟。\n**多智能体记忆基线（3个，从现有MAS框架中提取其记忆组件）**：\n5.  **MetaGPT-M**：从MetaGPT框架中提取的记忆组件，主要存储最终解决方案工件。\n6.  **ChatDev-M**：从ChatDev框架中提取的记忆组件，存储执行结果。\n7.  **MacNet-M**：从MacNet框架中提取的记忆组件，属于任务内记忆。\n**所有基线均与G-Memory使用相同的底层MAS框架（AutoGen, DyLAN, MacNet）和LLM骨干进行公平对比。**\n\n**§4 实验控制变量与消融设计**\n-   **控制变量**：\n    1.  **MAS框架**：固定为AutoGen、DyLAN、MacNet三者之一。\n    2.  **LLM骨干**：固定为GPT-4o-mini、Qwen-2.5-7B、Qwen-2.5-14B之一。\n    3.  **任务/数据集**：在五个基准上分别测试。\n    4.  **超参数**：对G-Memory，固定使用1-hop扩展，\\(k \\in \\{1,2\\}\\)，\\(M\\)在{2,3,4,5}中调优（未报告具体值）。\n-   **消融设计**：\n    1.  **组件消融**：构建两个G-Memory变体：仅提供高层洞察（Insight-only）和仅提供细粒度交互（Interaction-only），与完整G-Memory对比，以验证双向遍历的必要性。\n    2.  **超参数敏感性分析**：\n        -   **Hop数**：测试0-hop（仅相似度检索）、1-hop、2-hop、3-hop扩展对性能的影响。\n        -   **参数k**：测试 \\(k = 1, 2, 5\\) 对性能的影响。\n    结果以折线图或柱状图形式展示（图4a, 4b, 4c）。",
    "core_results": "**§1 主实验结果全景（表格式呈现）**\n**注意**：论文提供了多个表格（表1、2、3）对应不同LLM骨干。此处以**表1（GPT-4o-mini骨干）**为例进行全景还原，展示G-Memory在三个MAS框架（AutoGen, DyLAN, MacNet）上与所有基线的对比。数值为成功率/准确率（%）。箭头表示相对于该MAS框架的No-memory基线的变化。\n`方法名 | ALFWorld | SciWorld | PDDL | HotpotQA | FEVER | Avg.`\n`AutoGen-No-memory | 77.61↑0.00 | 54.49↑0.00 | 23.53↑0.00 | 28.57↑0.00 | 57.13↑0.00 | 48.27↑0.00`\n`AutoGen-Voyager | 85.07↑7.46 | 62.36↑7.87 | 24.56↑1.03 | 32.32↑3.75 | 63.27↑6.14 | 53.52↑5.25`\n`AutoGen-MemoryBank | 74.96↓2.65 | 53.11↓1.38 | 20.41↓3.12 | 33.67↑5.10 | 61.22↑4.09 | 48.67↑0.40`\n`AutoGen-Generative | 86.36↑8.75 | 61.19↑6.70 | 25.53↑2.00 | 31.63↑3.06 | 60.20↑3.07 | 52.98↑4.71`\n`AutoGen-MetaGPT-M | 81.34↑3.73 | 61.91↑7.42 | 21.63↓1.90 | 32.67↑4.10 | 62.67↑5.54 | 52.04↑3.77`\n`AutoGen-ChatDev-M | 79.85↑2.24 | 50.96↓3.53 | 16.65↓6.88 | 24.49↓4.08 | 59.18↑2.05 | 46.23↓2.04`\n`AutoGen-MacNet-M | 76.55↓1.06 | 55.44↑0.95 | 22.94↓0.59 | 28.36↓0.21 | 60.87↑3.74 | 48.83↑0.56`\n`AutoGen-G-Memory (Ours) | 88.81↑11.20 | 67.40↑12.91 | 27.77↑4.24 | 35.67↑7.10 | 66.24↑9.11 | 57.18↑8.91`\n`DyLAN-No-memory | 56.72↑0.00 | 55.38↑0.00 | 11.62↑0.00 | 31.69↑0.00 | 60.20↑0.00 | 43.12↑0.00`\n`DyLAN-Voyager | 66.42↑9.70 | 62.83↑7.45 | 15.10↑3.48 | 32.64↑0.95 | 62.24↑2.04 | 47.85↑4.73`\n`DyLAN-MemoryBank | 55.22↓1.50 | 54.74↓0.64 | 8.08↓3.54 | 29.59↓2.10 | 59.13↓1.07 | 41.35↓1.77`\n`DyLAN-Generative | 67.91↑11.19 | 64.16↑8.78 | 13.87↑2.25 | 29.29↓2.40 | 62.30↑2.10 | 47.51↑4.39`\n`DyLAN-MetaGPT-M | 69.40↑12.68 | 62.37↑6.99 | 14.45↑2.83 | 32.34↑0.65 | 60.20↑0.00 | 47.75↑4.63`\n`DyLAN-ChatDev-M | 46.27↓10.45 | 53.35↓2.03 | 10.75↓0.87 | 22.45↓9.24 | 58.33↓1.87 | 38.23↓4.89`\n`DyLAN-MacNet-M | 53.44↓3.28 | 54.32↓1.06 | 12.11↑0.49 | 30.12↓1.57 | 61.10↑0.90 | 42.22↓0.90`\n`DyLAN-G-Memory (Ours) | 70.90↑14.18 | 65.64↑10.26 | 18.95↑7.33 | 34.69↑3.00 | 64.22↑4.02 | 50.88↑7.76`\n`MacNet-No-memory | 51.49↑0.00 | 57.53↑0.00 | 12.18↑0.00 | 28.57↑0.00 | 60.29↑0.00 | 42.01↑0.00`\n`MacNet-Voyager | 61.94↑10.45 | 64.53↑7.00 | 14.06↑1.88 | 32.65↑4.08 | 62.54↑2.25 | 47.14↑5.13`\n`MacNet-MemoryBank | 50.00↓1.49 | 60.15↑2.62 | 8.64↓3.54 | 33.67↑5.10 | 61.22↑0.93 | 42.74↑0.73`\n`MacNet-Generative | 62.69↑11.20 | 65.49↑7.96 | 7.92↓4.26 | 29.59↑1.02 | 63.27↑2.98 | 45.79↑3.78`\n`MacNet-MetaGPT-M | 63.70↑12.21 | 65.27↑7.74 | 16.03↑3.85 | 31.00↑2.43 | 59.33↓0.96 | 47.07↑5.06`\n`MacNet-ChatDev-M | 49.25↓2.24 | 56.58↓0.95 | 13.51↑1.33 | 29.00↑0.43 | 59.18↓1.11 | 41.50↓0.51`\n`MacNet-MacNet-M | 53.44↑1.95 | 56.14↓1.39 | 13.59↑1.41 | 27.89↓0.68 | 59.20↓1.09 | 42.05↑0.04`\n`MacNet-G-Memory (Ours) | 67.16↑15.67 | 68.11↑10.58 | 24.33↑12.15 | 35.69↑7.12 | 64.44↑4.15 | 51.95↑9.94`\n\n**§2 分任务/分场景深度分析（每个维度100字以上）**\n-   **具身动作任务（ALFWorld, SciWorld）**：G-Memory提升显著。在MacNet+Qwen-2.5-14B上，ALFWorld成功率从58.21%提升至79.10%，绝对提升20.89个百分点，相对提升35.9%。**原因**：G-Memory能检索到高度相似的历史任务（如“放干净鸡蛋到微波炉”对于“放干净布到台面”），并提供具体的协作轨迹（如“清洁前尝试放置”的错误操作及纠正），为具身任务提供了可操作的程序性指导。\n-   **知识推理任务（HotpotQA, FEVER）**：G-Memory稳定提升。在AutoGen+GPT-4o-mini上，HotpotQA从28.57%提升至35.67%（+7.10点），FEVER从57.13%提升至66.24%（+9.11点）。**原因**：高层洞察发挥了关键作用，例如在HotpotQA中检索到“避免错误指代”的洞察，防止智能体基于同名人物错误作答。\n-   **游戏/规划任务（PDDL）**：G-Memory提升最大之一。在MacNet+GPT-4o-mini上，PDDL从12.18%提升至24.33%（+12.15点，相对翻倍）。**原因**：PDDL任务需要有效的分工和策略规划。G-Memory的角色特定记忆注入和从历史协作中提炼的洞察，为不同角色的智能体提供了定制化的战略提示，这是其他基线（如Voyager、MemoryBank）所缺乏的，后者甚至会导致性能下降。\n-   **基线表现分析**：\n    -   **单智能体记忆在MAS中可能有害**：如MemoryBank在多个设置下导致性能下降（如AutoGen-PDDL下降3.12点），因为它们无法提供角色特定的支持。\n    -   **现有MAS记忆效果有限或不稳定**：ChatDev-M在多个场景下表现最差（如DyLAN-ALFWorld下降10.45点），因其记忆范围过窄。MetaGPT-M虽有提升，但代价高昂（Token消耗大）。\n\n**§3 效率与开销的定量对比**\n-   **Token消耗**：如图3所示，在PDDL+AutoGen设置中，G-Memory在实现10.32%性能提升（相对于无记忆）的同时，仅增加了约 \\(1.4 \\times 10^6\\) 个Token的消耗。\n-   **对比基线效率**：在相同设置下，MetaGPT-M为了实现4.07%的性能提升，却额外消耗了 \\(2.2 \\times 10^6\\) 个Token，其Token效率远低于G-Memory。\n-   **结论**：G-Memory在**性能提升幅度和Token消耗之间取得了更好的权衡**，实现了高性能的集体记忆而没有过度的开销。\n\n**§4 消融实验结果详解**\n消融实验（图4c）使用Qwen-2.5-14b骨干，在AutoGen和DyLAN框架上测试了PDDL和FEVER数据集。具体数值如下（以AutoGen为例）：\n-   **完整G-Memory**：PDDL准确率55.24%，FEVER准确率71.43%。\n-   **仅交互变体（移除洞察）**：PDDL降至54.46%（下降0.78点，-1.4%），FEVER降至63.27%（下降8.16点，-11.4%）。平均性能下降约4.47%。\n-   **仅洞察变体（移除交互）**：PDDL降至50.00%（下降5.24点，-9.5%），FEVER降至68.77%（下降2.66点，-3.7%）。平均性能下降约3.95%。\n-   **结论**：两个组件都对最终性能有贡献。**细粒度交互轨迹的贡献略大于高层洞察**，因为其保留了更多对话级别的具体上下文依据。两者结合能实现最佳效果。\n\n**§5 案例分析/定性分析（如有）**\n论文图5展示了具体案例：\n-   **成功案例（ALFWorld+AutoGen）**：任务查询：“put a clean cloth in countertop”。G-Memory成功检索到高度相似的历史查询：“put a clean egg in microwave”（两者都要求物体处于清洁状态）。同时，G-Memory检索到关键的轨迹片段：求解器智能体试图在清洁之前将鸡蛋放入微波炉，导致地面智能体进行干预。这个协作轨迹为当前任务提供了可操作的指导。\n-   **成功案例（HotpotQA）**：在网页搜索任务中，G-Memory检索到一个洞察，警告“mistakenly referring”（错误指代），这有助于防止智能体基于相似名称的个人进行错误回答。\n-   **总体分析**：G-Memory在具身动作、知识推理和游戏环境等多种领域提供了有效的多层次记忆支持，包括具体的程序性示例和抽象的战略警告。",
    "conclusion_and_future_work": "**§1 本文核心贡献总结**\n1.  **瓶颈识别**：首次系统性地指出并论证了现有MAS自我演化能力不足的根本原因在于**过度简化的记忆架构**，无法处理冗长、复杂的多智能体协作轨迹。\n2.  **提出G-Memory**：设计了一个**层次化、图结构化的智能体记忆框架**，通过洞察图、查询图、交互图三层结构来组织和管理MAS的交互历史。该设计实现了对MAS经验从抽象洞察到具体轨迹的多粒度捕获。\n3.  **双向遍历与角色特定注入**：提出了**双向记忆遍历机制**（向上检索洞察，向下检索核心交互）和**角色特定记忆注入算子 \\(\\Phi\\)**，确保每个智能体获得定制化的记忆支持，从而直接提升了任务成功率（如在MacNet+Qwen-2.5-14B上ALFWorld任务提升20.89%）。\n4.  **即插即用与高效性**：G-Memory是一个**无需训练、可无缝集成到主流MAS框架**的插件模块，且在提升性能的同时保持了较高的Token效率（对比MetaGPT-M，以更少的Token消耗获得了更大的性能增益）。\n\n**§2 局限性（作者自述）**\n作者在结论中明确承认的局限性：**虽然G-Memory已在三个领域（具身动作、知识推理、游戏）和五个基准上进行了评估，但在更广泛多样的任务（例如医疗问答）上进行进一步验证，将能增强其可靠性和普适性。** 作者将此项工作留作未来研究。\n\n**§3 未来研究方向（全量提取）**\n原文在“Limitation”部分仅提及了上述一点。未在结论章节明确列出多条未来工作方向。但根据全文内容，可推断出潜在方向：\n1.  **扩展到更多领域和任务**：正如作者所述，在医疗、法律、金融等专业领域验证G-Memory的有效性。\n2.  **处理更大规模记忆库**：探索当记忆图规模增长到百万级别时，如何维持高效的检索和更新性能，可能涉及图数据库优化、近似检索算法等。\n3.  **记忆压缩与遗忘机制**：研究如何智能地压缩或遗忘旧记忆，以防止记忆库无限膨胀并保持其新鲜度和相关性。\n4.  **多模态MAS记忆**：当前G-Memory处理文本交互。未来可扩展至支持视觉、音频等多模态交互轨迹的记忆存储与检索。\n5.  **理论分析**：对G-Memory的层次化图结构进行更形式化的理论分析，例如其与组织学习理论的关系，或证明其检索效率的下界。",
    "research_contributions": "**§1 核心学术贡献（按重要性排序）**\n1.  **提出了首个专为MAS设计的层次化图记忆架构**：\n    -   **理论新颖性**：创新性地将组织记忆理论引入LLM驱动的MAS，设计了洞察、查询、交互三层图结构，为建模复杂的多智能体协作经验提供了新的形式化框架。\n    -   **实验验证充分性**：在5个基准、3个MAS框架、3个LLM骨干上进行了广泛实验，证明了其普遍有效性和大幅性能提升（最高+20.89%）。\n    -   **对领域的影响**：为MAS的“自我演化”能力研究开辟了新方向，指明了记忆机制专业化的重要性，可能推动一系列基于图结构或层次化记忆的后续工作。\n2.  **设计了双向记忆遍历与角色特定记忆注入机制**：\n    -   **理论新颖性**：明确了MAS记忆应同时提供抽象指导和具体示例，并首次形式化了角色感知的记忆分配问题。\n    -   **实验验证充分性**：通过消融实验定量证明了双向遍历（洞察+交互）的必要性，以及角色特定注入的有效性。\n    -   **对领域的影响**：为后续MAS记忆设计提供了关键的技术范式，即记忆检索需考虑粒度层次和智能体异构性。\n3.  **系统性地揭示了现有记忆机制在MAS中的局限**：\n    -   **理论新颖性**：通过实证分析指出，简单迁移单智能体记忆或使用粗糙的MAS记忆不仅无效，甚至可能有害，从反面论证了专门化设计的必要性。\n    -   **实验验证充分性**：提供了大量基线对比数据，清晰展示了各类基线在不同任务上的失败模式（如性能下降）。\n    -   **对领域的影响**：纠正了社区可能存在的“记忆机制可通用”的误解，明确了MAS记忆这一独立研究子领域的价值。\n\n**§2 工程与实践贡献**\n1.  **开源实现**：代码已在GitHub上开源（https://github.com/bingreeky/GMemory），便于社区复现、使用和扩展。\n2.  **即插即用模块**：G-Memory被设计为与具体MAS框架解耦的插件，可无缝集成到AutoGen、DyLAN、MacNet等主流框架中，降低了应用门槛。\n3.  **提供了详实的实验基准**：论文构建了涵盖单智能体和多智能体记忆的全面基线对比体系，并在多个LLM骨干上测试，为后续研究提供了可靠的性能参照。\n\n**§3 与相关工作的定位**\n本文在技术路线图中处于**开辟新路线**的位置。现有工作主要集中在两条路线上：(1) 为单智能体设计复杂的记忆机制；(2) 为MAS设计动态工作流或通信拓扑，但忽视或简化记忆。本文首次明确指出并致力于解决“**MAS专用记忆**”这一被忽视的关键问题。它不是在现有单智能体记忆或MAS工作流设计上的简单改进，而是**引入了一个全新的层次化图记忆范式**，专门用于捕获和利用多智能体协作的独特经验。因此，它开辟了“MAS记忆架构”这一新的研究子方向。",
    "professor_critique": "**§1 实验设计与评估体系的缺陷**\n1.  **数据集覆盖不全**：实验仅在5个基准上进行，且主要集中在**英文**文本任务。缺乏对**代码生成、复杂",
    "source_file": "G-Memory Tracing Hierarchical Memory for Multi-Agent Systems.md"
}