{
  "experiment": "AdaptMR vs Baseline Comparison",
  "model": "qwen2.5:1.5b",
  "backend": "ollama",
  "retrieve_k": 10,
  "total_questions": 199,
  "baseline_aggregate": {
    "overall": {
      "exact_match": {
        "mean": 0.15577889447236182,
        "std": 0.3635602173966771,
        "median": 0,
        "min": 0,
        "max": 1,
        "count": 199
      },
      "f1": {
        "mean": 0.34709007340761233,
        "std": 0.37013263619245235,
        "median": 0.2222222222222222,
        "min": 0.0,
        "max": 1.0,
        "count": 199
      },
      "rouge1_f": {
        "mean": 0.3608649919838936,
        "std": 0.3776897610502049,
        "median": 0.2222222222222222,
        "min": 0.0,
        "max": 1.0,
        "count": 199
      },
      "rouge2_f": {
        "mean": 0.21258441719961718,
        "std": 0.36604105640939394,
        "median": 0.0,
        "min": 0.0,
        "max": 1.0,
        "count": 199
      },
      "rougeL_f": {
        "mean": 0.35094918082046506,
        "std": 0.3755121864312992,
        "median": 0.2222222222222222,
        "min": 0.0,
        "max": 1.0,
        "count": 199
      },
      "bleu1": {
        "mean": 0.29114753449546055,
        "std": 0.35816372076337766,
        "median": 0.12262648039048077,
        "min": 0,
        "max": 1.0,
        "count": 199
      },
      "bleu2": {
        "mean": 0.21656211759537897,
        "std": 0.33309576757953463,
        "median": 0.04279677428117006,
        "min": 0,
        "max": 1.0,
        "count": 199
      },
      "bleu3": {
        "mean": 0.18783547900883507,
        "std": 0.3211920532569437,
        "median": 0.028067124621919234,
        "min": 0,
        "max": 1.0,
        "count": 199
      },
      "bleu4": {
        "mean": 0.156137952976355,
        "std": 0.28495088428206633,
        "median": 0.021105340631872645,
        "min": 0,
        "max": 1.0,
        "count": 199
      },
      "bert_precision": {
        "mean": 0.17649305435880344,
        "std": 0.35901179099180347,
        "median": 0.0,
        "min": 0.0,
        "max": 0.9999999403953552,
        "count": 199
      },
      "bert_recall": {
        "mean": 0.17226776106273708,
        "std": 0.3506153889418225,
        "median": 0.0,
        "min": 0.0,
        "max": 0.9999999403953552,
        "count": 199
      },
      "bert_f1": {
        "mean": 0.17428912978675498,
        "std": 0.35454797888823186,
        "median": 0.0,
        "min": 0.0,
        "max": 0.9999999403953552,
        "count": 199
      },
      "meteor": {
        "mean": 0.25980159493686744,
        "std": 0.349557854473118,
        "median": 0.0909090909090909,
        "min": 0.0,
        "max": 0.9997106481481481,
        "count": 199
      },
      "sbert_similarity": {
        "mean": 0.5208490090163883,
        "std": 0.32864811972504715,
        "median": 0.497897207736969,
        "min": -0.04855134338140488,
        "max": 1.000000238418579,
        "count": 199
      }
    },
    "category_1": {
      "exact_match": {
        "mean": 0.03125,
        "std": 0.1767766952966369,
        "median": 0.0,
        "min": 0,
        "max": 1,
        "count": 32
      },
      "f1": {
        "mean": 0.2174908642259985,
        "std": 0.28680453107043075,
        "median": 0.12549019607843137,
        "min": 0.0,
        "max": 1.0,
        "count": 32
      },
      "rouge1_f": {
        "mean": 0.21701969873138455,
        "std": 0.2882104366162934,
        "median": 0.1213235294117647,
        "min": 0.0,
        "max": 1.0,
        "count": 32
      },
      "rouge2_f": {
        "mean": 0.02306547619047619,
        "std": 0.1181199454791859,
        "median": 0.0,
        "min": 0.0,
        "max": 0.6666666666666666,
        "count": 32
      },
      "rougeL_f": {
        "mean": 0.19722803206471787,
        "std": 0.2693175926056007,
        "median": 0.1213235294117647,
        "min": 0.0,
        "max": 1.0,
        "count": 32
      },
      "bleu1": {
        "mean": 0.14789578569727738,
        "std": 0.2023097611612502,
        "median": 0.10620300751879698,
        "min": 0,
        "max": 1.0,
        "count": 32
      },
      "bleu2": {
        "mean": 0.06270745780643484,
        "std": 0.1023148489726987,
        "median": 0.024874020649289695,
        "min": 0,
        "max": 0.4723665527410147,
        "count": 32
      },
      "bleu3": {
        "mean": 0.04745261632004098,
        "std": 0.09129708884592838,
        "median": 0.016702246373135735,
        "min": 0,
        "max": 0.4723665527410147,
        "count": 32
      },
      "bleu4": {
        "mean": 0.04006919719438334,
        "std": 0.08681348007507823,
        "median": 0.014724647950516713,
        "min": 0,
        "max": 0.4723665527410147,
        "count": 32
      },
      "bert_precision": {
        "mean": 0.3874782659113407,
        "std": 0.44795039361860356,
        "median": 0.0,
        "min": 0.0,
        "max": 0.9999999403953552,
        "count": 32
      },
      "bert_recall": {
        "mean": 0.38234107196331024,
        "std": 0.44162690624485035,
        "median": 0.0,
        "min": 0.0,
        "max": 0.9999999403953552,
        "count": 32
      },
      "bert_f1": {
        "mean": 0.3848004937171936,
        "std": 0.44456464133501883,
        "median": 0.0,
        "min": 0.0,
        "max": 0.9999999403953552,
        "count": 32
      },
      "meteor": {
        "mean": 0.09254840540054653,
        "std": 0.1500020021408219,
        "median": 0.0,
        "min": 0.0,
        "max": 0.5923507462686567,
        "count": 32
      },
      "sbert_similarity": {
        "mean": 0.42510819336166605,
        "std": 0.24709931807752386,
        "median": 0.37645289301872253,
        "min": -0.003922225907444954,
        "max": 1.0,
        "count": 32
      }
    },
    "category_2": {
      "exact_match": {
        "mean": 0,
        "std": 0.0,
        "median": 0,
        "min": 0,
        "max": 0,
        "count": 37
      },
      "f1": {
        "mean": 0.2743672243672244,
        "std": 0.2595421376029069,
        "median": 0.25,
        "min": 0.0,
        "max": 0.8,
        "count": 37
      },
      "rouge1_f": {
        "mean": 0.2722882222882223,
        "std": 0.2578286621439378,
        "median": 0.25,
        "min": 0.0,
        "max": 0.8,
        "count": 37
      },
      "rouge2_f": {
        "mean": 0.11038961038961038,
        "std": 0.20597360845952412,
        "median": 0.0,
        "min": 0.0,
        "max": 0.6666666666666666,
        "count": 37
      },
      "rougeL_f": {
        "mean": 0.26628221628221627,
        "std": 0.2508812813674687,
        "median": 0.25,
        "min": 0.0,
        "max": 0.8,
        "count": 37
      },
      "bleu1": {
        "mean": 0.171556102643035,
        "std": 0.21609834011779147,
        "median": 0.06766764161830635,
        "min": 0,
        "max": 0.6666666666666666,
        "count": 37
      },
      "bleu2": {
        "mean": 0.08921820506625051,
        "std": 0.14556897611272007,
        "median": 0.030261889307125377,
        "min": 0,
        "max": 0.5773502691896257,
        "count": 37
      },
      "bleu3": {
        "mean": 0.05410475475718477,
        "std": 0.08112679262286272,
        "median": 0.02355435073584915,
        "min": 0,
        "max": 0.3254992452916931,
        "count": 37
      },
      "bleu4": {
        "mean": 0.044499054545677895,
        "std": 0.06223740357570964,
        "median": 0.020237345084409754,
        "min": 0,
        "max": 0.24028114141347542,
        "count": 37
      },
      "bert_precision": {
        "mean": 0.4948754600576452,
        "std": 0.46349115653052214,
        "median": 0.8706594109535217,
        "min": 0.0,
        "max": 0.9887830018997192,
        "count": 37
      },
      "bert_recall": {
        "mean": 0.48204693762031764,
        "std": 0.45259058560314824,
        "median": 0.8169572353363037,
        "min": 0.0,
        "max": 0.9887830018997192,
        "count": 37
      },
      "bert_f1": {
        "mean": 0.48814918866028656,
        "std": 0.4575359962049707,
        "median": 0.8516839742660522,
        "min": 0.0,
        "max": 0.9887830018997192,
        "count": 37
      },
      "meteor": {
        "mean": 0.1371595251472747,
        "std": 0.19896368372056863,
        "median": 0.08928571428571427,
        "min": 0.0,
        "max": 0.8928571428571429,
        "count": 37
      },
      "sbert_similarity": {
        "mean": 0.6354076226015348,
        "std": 0.18719501320277307,
        "median": 0.645390510559082,
        "min": 0.15914350748062134,
        "max": 0.9536036252975464,
        "count": 37
      }
    },
    "category_3": {
      "exact_match": {
        "mean": 0,
        "std": 0.0,
        "median": 0,
        "min": 0,
        "max": 0,
        "count": 13
      },
      "f1": {
        "mean": 0.11570512820512821,
        "std": 0.20664702139878874,
        "median": 0.0,
        "min": 0.0,
        "max": 0.6666666666666666,
        "count": 13
      },
      "rouge1_f": {
        "mean": 0.1428315902297803,
        "std": 0.19814518328752598,
        "median": 0.1176470588235294,
        "min": 0.0,
        "max": 0.6666666666666666,
        "count": 13
      },
      "rouge2_f": {
        "mean": 0.004807692307692308,
        "std": 0.01733438113203841,
        "median": 0.0,
        "min": 0.0,
        "max": 0.0625,
        "count": 13
      },
      "rougeL_f": {
        "mean": 0.13843598583417588,
        "std": 0.19809174352352132,
        "median": 0.1142857142857143,
        "min": 0.0,
        "max": 0.6666666666666666,
        "count": 13
      },
      "bleu1": {
        "mean": 0.04249854452919654,
        "std": 0.10279389267337029,
        "median": 0,
        "min": 0,
        "max": 0.36787944117144233,
        "count": 13
      },
      "bleu2": {
        "mean": 0.014335001839084774,
        "std": 0.03326819475912324,
        "median": 0,
        "min": 0,
        "max": 0.11633369384516798,
        "count": 13
      },
      "bleu3": {
        "mean": 0.008908667394662749,
        "std": 0.02232766070035967,
        "median": 0,
        "min": 0,
        "max": 0.08048325236348887,
        "count": 13
      },
      "bleu4": {
        "mean": 0.006891682638097702,
        "std": 0.018022269396246356,
        "median": 0,
        "min": 0,
        "max": 0.06541924356118012,
        "count": 13
      },
      "bert_precision": {
        "mean": 0.33941702200816226,
        "std": 0.4473380959409354,
        "median": 0.0,
        "min": 0.0,
        "max": 0.9279205203056335,
        "count": 13
      },
      "bert_recall": {
        "mean": 0.3238948812851539,
        "std": 0.42684035414482746,
        "median": 0.0,
        "min": 0.0,
        "max": 0.8712078332901001,
        "count": 13
      },
      "bert_f1": {
        "mean": 0.3314154652448801,
        "std": 0.4367070134173178,
        "median": 0.0,
        "min": 0.0,
        "max": 0.89814692735672,
        "count": 13
      },
      "meteor": {
        "mean": 0.03604234156427487,
        "std": 0.08097843957273718,
        "median": 0.0,
        "min": 0.0,
        "max": 0.2631578947368421,
        "count": 13
      },
      "sbert_similarity": {
        "mean": 0.30981271599347776,
        "std": 0.15972391131370833,
        "median": 0.27236443758010864,
        "min": 0.10540685057640076,
        "max": 0.6290402412414551,
        "count": 13
      }
    },
    "category_4": {
      "exact_match": {
        "mean": 0.12857142857142856,
        "std": 0.3371418043988196,
        "median": 0.0,
        "min": 0,
        "max": 1,
        "count": 70
      },
      "f1": {
        "mean": 0.36028306909258273,
        "std": 0.3451598298604328,
        "median": 0.2857142857142857,
        "min": 0.0,
        "max": 1.0,
        "count": 70
      },
      "rouge1_f": {
        "mean": 0.38874648054193195,
        "std": 0.3630636907048218,
        "median": 0.30536130536130535,
        "min": 0.0,
        "max": 1.0,
        "count": 70
      },
      "rouge2_f": {
        "mean": 0.2355136409554238,
        "std": 0.35202096115017234,
        "median": 0.0,
        "min": 0.0,
        "max": 1.0,
        "count": 70
      },
      "rougeL_f": {
        "mean": 0.37359579470159093,
        "std": 0.3616897988874794,
        "median": 0.26785714285714285,
        "min": 0.0,
        "max": 1.0,
        "count": 70
      },
      "bleu1": {
        "mean": 0.3162506206743197,
        "std": 0.33265626610355153,
        "median": 0.1919698602928606,
        "min": 0,
        "max": 1.0,
        "count": 70
      },
      "bleu2": {
        "mean": 0.2304423140677645,
        "std": 0.3025526014827964,
        "median": 0.06519706014347107,
        "min": 0,
        "max": 1.0,
        "count": 70
      },
      "bleu3": {
        "mean": 0.18335036075972339,
        "std": 0.26828756722689756,
        "median": 0.04198056519057385,
        "min": 0,
        "max": 1.0,
        "count": 70
      },
      "bleu4": {
        "mean": 0.1276240941208157,
        "std": 0.1763948204974339,
        "median": 0.03596491431744327,
        "min": 0,
        "max": 0.6198021310128995,
        "count": 70
      },
      "bert_precision": {
        "mean": 0.0,
        "std": 0.0,
        "median": 0.0,
        "min": 0.0,
        "max": 0.0,
        "count": 70
      },
      "bert_recall": {
        "mean": 0.0,
        "std": 0.0,
        "median": 0.0,
        "min": 0.0,
        "max": 0.0,
        "count": 70
      },
      "bert_f1": {
        "mean": 0.0,
        "std": 0.0,
        "median": 0.0,
        "min": 0.0,
        "max": 0.0,
        "count": 70
      },
      "meteor": {
        "mean": 0.29085718423842905,
        "std": 0.3321472088402798,
        "median": 0.14219443323920936,
        "min": 0.0,
        "max": 0.9814814814814815,
        "count": 70
      },
      "sbert_similarity": {
        "mean": 0.4937565542092281,
        "std": 0.32278518348598956,
        "median": 0.4652784615755081,
        "min": -0.015214240178465843,
        "max": 1.000000238418579,
        "count": 70
      }
    },
    "category_5": {
      "exact_match": {
        "mean": 0.44680851063829785,
        "std": 0.5025375018797699,
        "median": 0,
        "min": 0,
        "max": 1,
        "count": 47
      },
      "f1": {
        "mean": 0.5369286840031521,
        "std": 0.47279713445092275,
        "median": 0.6666666666666666,
        "min": 0.0,
        "max": 1.0,
        "count": 47
      },
      "rouge1_f": {
        "mean": 0.5473143512724239,
        "std": 0.47665860916832553,
        "median": 0.8125000000000001,
        "min": 0.0,
        "max": 1.0,
        "count": 47
      },
      "rouge2_f": {
        "mean": 0.4453900709219858,
        "std": 0.4963842953715808,
        "median": 0.0,
        "min": 0.0,
        "max": 1.0,
        "count": 47
      },
      "rougeL_f": {
        "mean": 0.5473143512724239,
        "std": 0.47665860916832553,
        "median": 0.8125000000000001,
        "min": 0.0,
        "max": 1.0,
        "count": 47
      },
      "bleu1": {
        "mean": 0.5142147637959478,
        "std": 0.47353905748770303,
        "median": 0.49123845184678916,
        "min": 0,
        "max": 1.0,
        "count": 47
      },
      "bleu2": {
        "mean": 0.4568262160759918,
        "std": 0.46476013700795765,
        "median": 0.316227766016838,
        "min": 0,
        "max": 1.0,
        "count": 47
      },
      "bleu3": {
        "mean": 0.4448630371316974,
        "std": 0.46959334753243825,
        "median": 0.2187761623949553,
        "min": 0,
        "max": 1.0,
        "count": 47
      },
      "bleu4": {
        "mean": 0.40679776279004093,
        "std": 0.4511178496282044,
        "median": 0.1778279410038923,
        "min": 0,
        "max": 1.0,
        "count": 47
      },
      "bert_precision": {
        "mean": 0.0,
        "std": 0.0,
        "median": 0.0,
        "min": 0.0,
        "max": 0.0,
        "count": 47
      },
      "bert_recall": {
        "mean": 0.0,
        "std": 0.0,
        "median": 0.0,
        "min": 0.0,
        "max": 0.0,
        "count": 47
      },
      "bert_f1": {
        "mean": 0.0,
        "std": 0.0,
        "median": 0.0,
        "min": 0.0,
        "max": 0.0,
        "count": 47
      },
      "meteor": {
        "mean": 0.48586197132222037,
        "std": 0.4617617957169198,
        "median": 0.5,
        "min": 0.0,
        "max": 0.9997106481481481,
        "count": 47
      },
      "sbert_similarity": {
        "mean": 0.5945720099546807,
        "std": 0.44408230827299594,
        "median": 0.8889155387878418,
        "min": -0.04855134338140488,
        "max": 1.000000238418579,
        "count": 47
      }
    }
  },
  "adaptmr_aggregate": {
    "overall": {
      "exact_match": {
        "mean": 0.1507537688442211,
        "std": 0.35871112526270943,
        "median": 0,
        "min": 0,
        "max": 1,
        "count": 199
      },
      "f1": {
        "mean": 0.31454209417391865,
        "std": 0.36226508396250334,
        "median": 0.16666666666666666,
        "min": 0.0,
        "max": 1.0,
        "count": 199
      },
      "rouge1_f": {
        "mean": 0.3278292402180277,
        "std": 0.36642513859775055,
        "median": 0.19999999999999998,
        "min": 0.0,
        "max": 1.0,
        "count": 199
      },
      "rouge2_f": {
        "mean": 0.2002975899126155,
        "std": 0.36118719356353357,
        "median": 0.0,
        "min": 0.0,
        "max": 1.0,
        "count": 199
      },
      "rougeL_f": {
        "mean": 0.32507855266173313,
        "std": 0.3665742794024888,
        "median": 0.18181818181818182,
        "min": 0.0,
        "max": 1.0,
        "count": 199
      },
      "bleu1": {
        "mean": 0.2634584458991838,
        "std": 0.35426662244879226,
        "median": 0.1174266328516845,
        "min": 0,
        "max": 1.0,
        "count": 199
      },
      "bleu2": {
        "mean": 0.20176633742381414,
        "std": 0.337938181032207,
        "median": 0.03131334342651994,
        "min": 0,
        "max": 1.0,
        "count": 199
      },
      "bleu3": {
        "mean": 0.1822160541003287,
        "std": 0.32992022994961256,
        "median": 0.023547737997202885,
        "min": 0,
        "max": 1.0,
        "count": 199
      },
      "bleu4": {
        "mean": 0.15319922826744287,
        "std": 0.2916852167068317,
        "median": 0.018850319022747353,
        "min": 0,
        "max": 1.0,
        "count": 199
      },
      "bert_precision": {
        "mean": 0.17418162517212143,
        "std": 0.35455400459143466,
        "median": 0.0,
        "min": 0.0,
        "max": 0.991973876953125,
        "count": 199
      },
      "bert_recall": {
        "mean": 0.17279828253702903,
        "std": 0.3516169023258681,
        "median": 0.0,
        "min": 0.0,
        "max": 0.991973876953125,
        "count": 199
      },
      "bert_f1": {
        "mean": 0.17341292263874455,
        "std": 0.35283917192931247,
        "median": 0.0,
        "min": 0.0,
        "max": 0.991973876953125,
        "count": 199
      },
      "meteor": {
        "mean": 0.24910186857164643,
        "std": 0.3517092935107744,
        "median": 0.08771929824561403,
        "min": 0.0,
        "max": 0.9998177842565598,
        "count": 199
      },
      "sbert_similarity": {
        "mean": 0.5196125144560133,
        "std": 0.33167128242312593,
        "median": 0.46271559596061707,
        "min": -0.04855134338140488,
        "max": 1.000000238418579,
        "count": 199
      }
    },
    "category_1": {
      "exact_match": {
        "mean": 0.03125,
        "std": 0.1767766952966369,
        "median": 0.0,
        "min": 0,
        "max": 1,
        "count": 32
      },
      "f1": {
        "mean": 0.142285747784469,
        "std": 0.2491234390120364,
        "median": 0.0,
        "min": 0.0,
        "max": 1.0,
        "count": 32
      },
      "rouge1_f": {
        "mean": 0.14411652857376542,
        "std": 0.24815600169443428,
        "median": 0.0,
        "min": 0.0,
        "max": 1.0,
        "count": 32
      },
      "rouge2_f": {
        "mean": 0.023237179487179488,
        "std": 0.11819648429233819,
        "median": 0.0,
        "min": 0.0,
        "max": 0.6666666666666666,
        "count": 32
      },
      "rougeL_f": {
        "mean": 0.1393088362660731,
        "std": 0.24636855565027607,
        "median": 0.0,
        "min": 0.0,
        "max": 1.0,
        "count": 32
      },
      "bleu1": {
        "mean": 0.10286015737967061,
        "std": 0.1984568449508306,
        "median": 0.0,
        "min": 0,
        "max": 1.0,
        "count": 32
      },
      "bleu2": {
        "mean": 0.04308795153758456,
        "std": 0.098352808353945,
        "median": 0.0,
        "min": 0,
        "max": 0.4723665527410147,
        "count": 32
      },
      "bleu3": {
        "mean": 0.034096964467191786,
        "std": 0.08982054618266913,
        "median": 0.0,
        "min": 0,
        "max": 0.4723665527410147,
        "count": 32
      },
      "bleu4": {
        "mean": 0.030533331286785467,
        "std": 0.08724509033709794,
        "median": 0.0,
        "min": 0,
        "max": 0.4723665527410147,
        "count": 32
      },
      "bert_precision": {
        "mean": 0.38021646812558174,
        "std": 0.43905155070471774,
        "median": 0.0,
        "min": 0.0,
        "max": 0.9656624794006348,
        "count": 32
      },
      "bert_recall": {
        "mean": 0.3790240101516247,
        "std": 0.43715907740285587,
        "median": 0.0,
        "min": 0.0,
        "max": 0.9319413304328918,
        "count": 32
      },
      "bert_f1": {
        "mean": 0.37953851744532585,
        "std": 0.4379281809776951,
        "median": 0.0,
        "min": 0.0,
        "max": 0.9485023021697998,
        "count": 32
      },
      "meteor": {
        "mean": 0.07637270475048612,
        "std": 0.14389093928567034,
        "median": 0.0,
        "min": 0.0,
        "max": 0.5923507462686567,
        "count": 32
      },
      "sbert_similarity": {
        "mean": 0.37956556398421526,
        "std": 0.23266232289084873,
        "median": 0.3198002278804779,
        "min": -0.026648148894309998,
        "max": 1.0,
        "count": 32
      }
    },
    "category_2": {
      "exact_match": {
        "mean": 0,
        "std": 0.0,
        "median": 0,
        "min": 0,
        "max": 0,
        "count": 37
      },
      "f1": {
        "mean": 0.2753753753753754,
        "std": 0.2248324347103234,
        "median": 0.2222222222222222,
        "min": 0.0,
        "max": 0.6666666666666666,
        "count": 37
      },
      "rouge1_f": {
        "mean": 0.275028875028875,
        "std": 0.22501443034861585,
        "median": 0.2222222222222222,
        "min": 0.0,
        "max": 0.6666666666666666,
        "count": 37
      },
      "rouge2_f": {
        "mean": 0.08622908622908623,
        "std": 0.17327701198389167,
        "median": 0.0,
        "min": 0.0,
        "max": 0.5,
        "count": 37
      },
      "rougeL_f": {
        "mean": 0.275028875028875,
        "std": 0.22501443034861585,
        "median": 0.2222222222222222,
        "min": 0.0,
        "max": 0.6666666666666666,
        "count": 37
      },
      "bleu1": {
        "mean": 0.1985320257598579,
        "std": 0.19760261218076505,
        "median": 0.1353352832366127,
        "min": 0,
        "max": 0.6666666666666666,
        "count": 37
      },
      "bleu2": {
        "mean": 0.10125079816117408,
        "std": 0.1540151061348868,
        "median": 0.048795003647426664,
        "min": 0,
        "max": 0.5773502691896257,
        "count": 37
      },
      "bleu3": {
        "mean": 0.06931611124765338,
        "std": 0.08759226030277446,
        "median": 0.044556965439969995,
        "min": 0,
        "max": 0.3254992452916931,
        "count": 37
      },
      "bleu4": {
        "mean": 0.058983105363262775,
        "std": 0.0661499884462686,
        "median": 0.0417991745584234,
        "min": 0,
        "max": 0.24028114141347542,
        "count": 37
      },
      "bert_precision": {
        "mean": 0.49188907243110036,
        "std": 0.4618869282521837,
        "median": 0.7725777626037598,
        "min": 0.0,
        "max": 0.991973876953125,
        "count": 37
      },
      "bert_recall": {
        "mean": 0.4863910272314742,
        "std": 0.4565903279333306,
        "median": 0.8062412738800049,
        "min": 0.0,
        "max": 0.991973876953125,
        "count": 37
      },
      "bert_f1": {
        "mean": 0.4888512153883238,
        "std": 0.45871416754370414,
        "median": 0.7926827669143677,
        "min": 0.0,
        "max": 0.991973876953125,
        "count": 37
      },
      "meteor": {
        "mean": 0.1563167961194277,
        "std": 0.2059525883267502,
        "median": 0.08771929824561403,
        "min": 0.0,
        "max": 0.9814814814814815,
        "count": 37
      },
      "sbert_similarity": {
        "mean": 0.7179666660927437,
        "std": 0.16074924266453255,
        "median": 0.7655600309371948,
        "min": 0.3253958821296692,
        "max": 0.9706802368164062,
        "count": 37
      }
    },
    "category_3": {
      "exact_match": {
        "mean": 0,
        "std": 0.0,
        "median": 0,
        "min": 0,
        "max": 0,
        "count": 13
      },
      "f1": {
        "mean": 0.08000474559179013,
        "std": 0.12982104611905187,
        "median": 0.0,
        "min": 0.0,
        "max": 0.4,
        "count": 13
      },
      "rouge1_f": {
        "mean": 0.11347882886344425,
        "std": 0.13058235032747137,
        "median": 0.09999999999999999,
        "min": 0.0,
        "max": 0.4,
        "count": 13
      },
      "rouge2_f": {
        "mean": 0.0,
        "std": 0.0,
        "median": 0.0,
        "min": 0.0,
        "max": 0.0,
        "count": 13
      },
      "rougeL_f": {
        "mean": 0.11347882886344425,
        "std": 0.13058235032747137,
        "median": 0.09999999999999999,
        "min": 0.0,
        "max": 0.4,
        "count": 13
      },
      "bleu1": {
        "mean": 0.03410534179694285,
        "std": 0.07407158605238737,
        "median": 2.2603294069810542e-06,
        "min": 0,
        "max": 0.25,
        "count": 13
      },
      "bleu2": {
        "mean": 0.015738865844993732,
        "std": 0.03384168578280828,
        "median": 7.14778918831783e-07,
        "min": 0,
        "max": 0.09128709291752769,
        "count": 13
      },
      "bleu3": {
        "mean": 0.010221023199448337,
        "std": 0.02291507752413483,
        "median": 4.945061934077801e-07,
        "min": 0,
        "max": 0.07665320007195604,
        "count": 13
      },
      "bleu4": {
        "mean": 0.009173243861756412,
        "std": 0.022621988009646904,
        "median": 4.0194972443398975e-07,
        "min": 0,
        "max": 0.08034284189446518,
        "count": 13
      },
      "bert_precision": {
        "mean": 0.33040928840637207,
        "std": 0.43533633635351426,
        "median": 0.0,
        "min": 0.0,
        "max": 0.8974241018295288,
        "count": 13
      },
      "bert_recall": {
        "mean": 0.3278170686501723,
        "std": 0.43250462093639375,
        "median": 0.0,
        "min": 0.0,
        "max": 0.9257596731185913,
        "count": 13
      },
      "bert_f1": {
        "mean": 0.3289572367301354,
        "std": 0.4335618290362441,
        "median": 0.0,
        "min": 0.0,
        "max": 0.9113717079162598,
        "count": 13
      },
      "meteor": {
        "mean": 0.022396957880828853,
        "std": 0.055045216565224736,
        "median": 0.0,
        "min": 0.0,
        "max": 0.16129032258064518,
        "count": 13
      },
      "sbert_similarity": {
        "mean": 0.27329537444389784,
        "std": 0.18171711348184805,
        "median": 0.2169199436903,
        "min": 0.1082494780421257,
        "max": 0.6725395917892456,
        "count": 13
      }
    },
    "category_4": {
      "exact_match": {
        "mean": 0.1,
        "std": 0.30216609311120096,
        "median": 0.0,
        "min": 0,
        "max": 1,
        "count": 70
      },
      "f1": {
        "mean": 0.3065673216164149,
        "std": 0.33506814605833657,
        "median": 0.16666666666666666,
        "min": 0.0,
        "max": 1.0,
        "count": 70
      },
      "rouge1_f": {
        "mean": 0.33828293325480824,
        "std": 0.35281777583615487,
        "median": 0.20526315789473684,
        "min": 0.0,
        "max": 1.0,
        "count": 70
      },
      "rouge2_f": {
        "mean": 0.20253883658726649,
        "std": 0.3446858898878005,
        "median": 0.0,
        "min": 0.0,
        "max": 1.0,
        "count": 70
      },
      "rougeL_f": {
        "mean": 0.3326609236854302,
        "std": 0.35280343701662836,
        "median": 0.18333333333333335,
        "min": 0.0,
        "max": 1.0,
        "count": 70
      },
      "bleu1": {
        "mean": 0.2486610135498282,
        "std": 0.319168024904438,
        "median": 0.11111111111111109,
        "min": 0,
        "max": 1.0,
        "count": 70
      },
      "bleu2": {
        "mean": 0.18154598594681756,
        "std": 0.29391333283474563,
        "median": 0.030206511882450875,
        "min": 0,
        "max": 1.0,
        "count": 70
      },
      "bleu3": {
        "mean": 0.15463482600358927,
        "std": 0.27223845377913536,
        "median": 0.019619309243463657,
        "min": 0,
        "max": 1.0,
        "count": 70
      },
      "bleu4": {
        "mean": 0.10925943763178178,
        "std": 0.18605286212802757,
        "median": 0.016134176373668686,
        "min": 0,
        "max": 0.8070557274927982,
        "count": 70
      },
      "bert_precision": {
        "mean": 0.0,
        "std": 0.0,
        "median": 0.0,
        "min": 0.0,
        "max": 0.0,
        "count": 70
      },
      "bert_recall": {
        "mean": 0.0,
        "std": 0.0,
        "median": 0.0,
        "min": 0.0,
        "max": 0.0,
        "count": 70
      },
      "bert_f1": {
        "mean": 0.0,
        "std": 0.0,
        "median": 0.0,
        "min": 0.0,
        "max": 0.0,
        "count": 70
      },
      "meteor": {
        "mean": 0.24254964717472272,
        "std": 0.32208256010911784,
        "median": 0.09118625277161863,
        "min": 0.0,
        "max": 0.9814814814814815,
        "count": 70
      },
      "sbert_similarity": {
        "mean": 0.4751603984407016,
        "std": 0.3025964083331331,
        "median": 0.3937814086675644,
        "min": 0.03152526170015335,
        "max": 1.000000238418579,
        "count": 70
      }
    },
    "category_5": {
      "exact_match": {
        "mean": 0.46808510638297873,
        "std": 0.504374939460682,
        "median": 0,
        "min": 0,
        "max": 1,
        "count": 47
      },
      "f1": {
        "mean": 0.5394057386548,
        "std": 0.4706556255599862,
        "median": 0.6666666666666667,
        "min": 0.0,
        "max": 1.0,
        "count": 47
      },
      "rouge1_f": {
        "mean": 0.5381955619127083,
        "std": 0.47069254323739923,
        "median": 0.6666666666666667,
        "min": 0.0,
        "max": 1.0,
        "count": 47
      },
      "rouge2_f": {
        "mean": 0.4627114020731042,
        "std": 0.4862357248004985,
        "median": 0.25,
        "min": 0.0,
        "max": 1.0,
        "count": 47
      },
      "rougeL_f": {
        "mean": 0.5381955619127083,
        "std": 0.47069254323739923,
        "median": 0.6666666666666667,
        "min": 0.0,
        "max": 1.0,
        "count": 47
      },
      "bleu1": {
        "mean": 0.5093910713367052,
        "std": 0.48015894511115975,
        "median": 0.48404410457807934,
        "min": 0,
        "max": 1.0,
        "count": 47
      },
      "bleu2": {
        "mean": 0.47050176370022806,
        "std": 0.4762074606474784,
        "median": 0.316227766016838,
        "min": 0,
        "max": 1.0,
        "count": 47
      },
      "bleu3": {
        "mean": 0.4605932907448516,
        "std": 0.4812034893450396,
        "median": 0.2187761623949553,
        "min": 0,
        "max": 1.0,
        "count": 47
      },
      "bleu4": {
        "mean": 0.4161657898122492,
        "std": 0.45666342890204625,
        "median": 0.1552645155070156,
        "min": 0,
        "max": 1.0,
        "count": 47
      },
      "bert_precision": {
        "mean": 0.0,
        "std": 0.0,
        "median": 0.0,
        "min": 0.0,
        "max": 0.0,
        "count": 47
      },
      "bert_recall": {
        "mean": 0.0,
        "std": 0.0,
        "median": 0.0,
        "min": 0.0,
        "max": 0.0,
        "count": 47
      },
      "bert_f1": {
        "mean": 0.0,
        "std": 0.0,
        "median": 0.0,
        "min": 0.0,
        "max": 0.0,
        "count": 47
      },
      "meteor": {
        "mean": 0.512212512396636,
        "std": 0.4646489638176025,
        "median": 0.5,
        "min": 0.0,
        "max": 0.9998177842565598,
        "count": 47
      },
      "sbert_similarity": {
        "mean": 0.5931480409617119,
        "std": 0.44706870824744066,
        "median": 0.8449620604515076,
        "min": -0.04855134338140488,
        "max": 1.000000238418579,
        "count": 47
      }
    }
  },
  "baseline_results": [
    {
      "sample_id": 0,
      "question": "When did Caroline go to the LGBTQ support group?",
      "prediction": "12 July",
      "reference": "7 May 2023",
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.910971462726593,
        "bert_recall": 0.8773210644721985,
        "bert_f1": 0.8938297033309937,
        "meteor": 0.0,
        "sbert_similarity": 0.5845963954925537
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie paint a sunrise?",
      "prediction": "8 May 2023",
      "reference": 2022,
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.883742094039917,
        "bert_recall": 0.9298762679100037,
        "bert_f1": 0.9062223434448242,
        "meteor": 0.0,
        "sbert_similarity": 0.6544517278671265
      }
    },
    {
      "sample_id": 0,
      "question": "What fields would Caroline be likely to pursue in her educaton?",
      "prediction": "education and mental health jobs",
      "reference": "Psychology, counseling certification",
      "category": 3,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8692922592163086,
        "bert_recall": 0.8712078332901001,
        "bert_f1": 0.8702489733695984,
        "meteor": 0.0,
        "sbert_similarity": 0.47970330715179443
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline research?",
      "prediction": "Caroline researched counseling or mental health work.",
      "reference": "Adoption agencies",
      "category": 1,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8558960556983948,
        "bert_recall": 0.855493426322937,
        "bert_f1": 0.8556946516036987,
        "meteor": 0.0,
        "sbert_similarity": 0.20158417522907257
      }
    },
    {
      "sample_id": 0,
      "question": "What is Caroline's identity?",
      "prediction": "transgender",
      "reference": "Transgender woman",
      "category": 1,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.0,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.36787944117144233,
        "bleu2": 0.11633369384516798,
        "bleu3": 0.08048325236348887,
        "bleu4": 0.06541924356118012,
        "bert_precision": 0.9624814987182617,
        "bert_recall": 0.9216964244842529,
        "bert_f1": 0.9416475892066956,
        "meteor": 0.2631578947368421,
        "sbert_similarity": 0.8627292513847351
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie run a charity race?",
      "prediction": "2023",
      "reference": "The sunday before 25 May 2023",
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.2857142857142857,
        "rouge1_f": 0.2857142857142857,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2857142857142857,
        "bleu1": 0.006737946999085467,
        "bleu2": 0.002130725927060655,
        "bleu3": 0.0014741021868805238,
        "bleu4": 0.0011981952414407235,
        "bert_precision": 0.9123231172561646,
        "bert_recall": 0.8169572353363037,
        "bert_f1": 0.8620105385780334,
        "meteor": 0.0909090909090909,
        "sbert_similarity": 0.6214897632598877
      }
    },
    {
      "sample_id": 0,
      "question": "When is Melanie planning on going camping?",
      "prediction": "Next month",
      "reference": "June 2023",
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8716428279876709,
        "bert_recall": 0.8618627786636353,
        "bert_f1": 0.8667252063751221,
        "meteor": 0.0,
        "sbert_similarity": 0.567993700504303
      }
    },
    {
      "sample_id": 0,
      "question": "What is Caroline's relationship status?",
      "prediction": "Single",
      "reference": "Single",
      "category": 1,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 0.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 0.316227766016838,
        "bleu3": 0.2187761623949553,
        "bleu4": 0.1778279410038923,
        "bert_precision": 0.9999999403953552,
        "bert_recall": 0.9999999403953552,
        "bert_f1": 0.9999999403953552,
        "meteor": 0.5,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline give a speech at a school?",
      "prediction": "8 May 2023",
      "reference": "The week before 9 June 2023",
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.2222222222222222,
        "rouge1_f": 0.2222222222222222,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2222222222222222,
        "bleu1": 0.12262648039048077,
        "bleu2": 0.04749303163563625,
        "bleu3": 0.044556965439969995,
        "bleu4": 0.0417991745584234,
        "bert_precision": 0.9300906658172607,
        "bert_recall": 0.8876339793205261,
        "bert_f1": 0.9083664417266846,
        "meteor": 0.08771929824561403,
        "sbert_similarity": 0.7655600309371948
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline meet up with her friends, family, and mentors?",
      "prediction": "9 June, 2023",
      "reference": "The week before 9 June 2023",
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.5714285714285715,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.45489799478447507,
        "bleu2": 0.30326532985631666,
        "bleu3": 0.14283448174223617,
        "bleu4": 0.11404605374835301,
        "bert_precision": 0.9525121450424194,
        "bert_recall": 0.89644455909729,
        "bert_f1": 0.9236282706260681,
        "meteor": 0.17543859649122806,
        "sbert_similarity": 0.8582825660705566
      }
    },
    {
      "sample_id": 0,
      "question": "How long has Caroline had her current group of friends for?",
      "prediction": "2 years",
      "reference": "4 years",
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.5,
        "rouge1_f": 0.5,
        "rouge2_f": 0.0,
        "rougeL_f": 0.5,
        "bleu1": 0.5,
        "bleu2": 0.223606797749979,
        "bleu3": 0.1740444189610778,
        "bleu4": 0.1495348781221221,
        "bert_precision": 0.9887830018997192,
        "bert_recall": 0.9887830018997192,
        "bert_f1": 0.9887830018997192,
        "meteor": 0.25,
        "sbert_similarity": 0.8421549201011658
      }
    },
    {
      "sample_id": 0,
      "question": "Where did Caroline move from 4 years ago?",
      "prediction": "Melaniesays: Thanks, Caroline! The event was really thought-provoking. I'm starting to realize that self-care is really important.",
      "reference": "Sweden",
      "category": 1,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7953370809555054,
        "bert_recall": 0.7972809672355652,
        "bert_f1": 0.7963078618049622,
        "meteor": 0.0,
        "sbert_similarity": -0.003922225907444954
      }
    },
    {
      "sample_id": 0,
      "question": "How long ago was Caroline's 18th birthday?",
      "prediction": "ten years",
      "reference": "10 years ago",
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.4,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4,
        "bleu1": 0.3032653298563167,
        "bleu2": 0.13562437855552414,
        "bleu3": 0.10556327625176448,
        "bleu4": 0.09069748827745895,
        "bert_precision": 0.8250130414962769,
        "bert_recall": 0.8106273412704468,
        "bert_f1": 0.8177568912506104,
        "meteor": 0.6465517241379309,
        "sbert_similarity": 0.654263436794281
      }
    },
    {
      "sample_id": 0,
      "question": "What career path has Caroline decided to persue?",
      "prediction": "counseling or mental health",
      "reference": "counseling or mental health for Transgender people",
      "category": 1,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.7272727272727273,
        "rouge1_f": 0.7272727272727273,
        "rouge2_f": 0.6666666666666666,
        "rougeL_f": 0.7272727272727273,
        "bleu1": 0.4723665527410147,
        "bleu2": 0.4723665527410147,
        "bleu3": 0.4723665527410147,
        "bleu4": 0.4723665527410147,
        "bert_precision": 0.9656624794006348,
        "bert_recall": 0.9319413304328918,
        "bert_f1": 0.9485023021697998,
        "meteor": 0.5923507462686567,
        "sbert_similarity": 0.676784873008728
      }
    },
    {
      "sample_id": 0,
      "question": "Would Caroline still want to pursue counseling as a career if she hadn't received support growing up?",
      "prediction": "No",
      "reference": "Likely no",
      "category": 3,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.0,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.36787944117144233,
        "bleu2": 0.11633369384516798,
        "bleu3": 0.08048325236348887,
        "bleu4": 0.06541924356118012,
        "bert_precision": 0.9279205203056335,
        "bert_recall": 0.8702245950698853,
        "bert_f1": 0.89814692735672,
        "meteor": 0.2631578947368421,
        "sbert_similarity": 0.6290402412414551
      }
    },
    {
      "sample_id": 0,
      "question": "What activities does Melanie partake in?",
      "prediction": "Melanie partsakes in hiking, exploring nature, camping, and family outings.",
      "reference": "pottery, camping, painting, swimming",
      "category": 1,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.14285714285714288,
        "rouge1_f": 0.14285714285714288,
        "rouge2_f": 0.0,
        "rougeL_f": 0.14285714285714288,
        "bleu1": 0.2857142857142857,
        "bleu2": 0.20965696734438366,
        "bleu3": 0.15706026521556773,
        "bleu4": 0.07596458453655348,
        "bert_precision": 0.8598499298095703,
        "bert_recall": 0.8752995729446411,
        "bert_f1": 0.8675059676170349,
        "meteor": 0.10869565217391304,
        "sbert_similarity": 0.33984267711639404
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie sign up for a pottery class?",
      "prediction": "15 July 2023",
      "reference": "2 July 2023",
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.5,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.6666666666666666,
        "bleu2": 0.5773502691896257,
        "bleu3": 0.3254992452916931,
        "bleu4": 0.24028114141347542,
        "bert_precision": 0.9838387966156006,
        "bert_recall": 0.9838387966156006,
        "bert_f1": 0.9838387966156006,
        "meteor": 0.625,
        "sbert_similarity": 0.9079325199127197
      }
    },
    {
      "sample_id": 0,
      "question": "When is Caroline going to the transgender conference?",
      "prediction": "3 July 2023",
      "reference": "July 2023",
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.8,
        "rouge1_f": 0.8,
        "rouge2_f": 0.6666666666666666,
        "rougeL_f": 0.8,
        "bleu1": 0.6666666666666666,
        "bleu2": 0.5773502691896257,
        "bleu3": 0.3254992452916931,
        "bleu4": 0.24028114141347542,
        "bert_precision": 0.9582687616348267,
        "bert_recall": 0.9789573550224304,
        "bert_f1": 0.9685026407241821,
        "meteor": 0.8928571428571429,
        "sbert_similarity": 0.945121169090271
      }
    },
    {
      "sample_id": 0,
      "question": "Where has Melanie camped?",
      "prediction": "Melanie has camped in the mountains last week.",
      "reference": "beach, mountains, forest",
      "category": 1,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.18181818181818182,
        "rouge1_f": 0.18181818181818182,
        "rouge2_f": 0.0,
        "rougeL_f": 0.18181818181818182,
        "bleu1": 0.11111111111111109,
        "bleu2": 0.03726779962499649,
        "bleu3": 0.028067124621919234,
        "bleu4": 0.023980296761827107,
        "bert_precision": 0.8622395992279053,
        "bert_recall": 0.8777278065681458,
        "bert_f1": 0.8699148297309875,
        "meteor": 0.0,
        "sbert_similarity": 0.31764644384384155
      }
    },
    {
      "sample_id": 0,
      "question": "What do Melanie's kids like?",
      "prediction": "nature",
      "reference": "dinosaurs, nature",
      "category": 1,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.0,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.1353352832366127,
        "bleu2": 0.04279677428117006,
        "bleu3": 0.02960813390314045,
        "bleu4": 0.024066394763145416,
        "bert_precision": 0.9019801616668701,
        "bert_recall": 0.8497076034545898,
        "bert_f1": 0.875063955783844,
        "meteor": 0.2631578947368421,
        "sbert_similarity": 0.7095581889152527
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie go to the museum?",
      "prediction": "Yesterday",
      "reference": "5 July 2023",
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8706594109535217,
        "bert_recall": 0.8335179686546326,
        "bert_f1": 0.8516839742660522,
        "meteor": 0.0,
        "sbert_similarity": 0.35495805740356445
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline have a picnic?",
      "prediction": "8:18 pm on 6 July, 2023",
      "reference": "The week before 6 July 2023",
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.5,
        "rouge1_f": 0.4615384615384615,
        "rouge2_f": 0.3636363636363636,
        "rougeL_f": 0.4615384615384615,
        "bleu1": 0.42857142857142855,
        "bleu2": 0.26726124191242434,
        "bleu3": 0.11511121735118796,
        "bleu4": 0.07730551756939454,
        "bert_precision": 0.8911066651344299,
        "bert_recall": 0.9181780815124512,
        "bert_f1": 0.9044399261474609,
        "meteor": 0.16666666666666666,
        "sbert_similarity": 0.7281993627548218
      }
    },
    {
      "sample_id": 0,
      "question": "Would Caroline likely have Dr. Seuss books on her bookshelf?",
      "prediction": "Yes",
      "reference": "Yes, since she collects classic children's books",
      "category": 3,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.25,
        "rouge1_f": 0.2222222222222222,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2222222222222222,
        "bleu1": 0.00033546262790251185,
        "bleu2": 0.0001060825974037491,
        "bleu3": 7.33912263594384e-05,
        "bleu4": 5.965462840365855e-05,
        "bert_precision": 0.9121391177177429,
        "bert_recall": 0.8539786338806152,
        "bert_f1": 0.8821011781692505,
        "meteor": 0.0,
        "sbert_similarity": 0.24328027665615082
      }
    },
    {
      "sample_id": 0,
      "question": "What books has Melanie read?",
      "prediction": "Melanie mentions she is reading a book that Caroline recommended",
      "reference": "\"Nothing is Impossible\", \"Charlotte's Web\"",
      "category": 1,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.13333333333333333,
        "rouge1_f": 0.125,
        "rouge2_f": 0.0,
        "rougeL_f": 0.125,
        "bleu1": 0.09048374180359597,
        "bleu2": 0.03016124726786533,
        "bleu3": 0.022576199178367274,
        "bleu4": 0.01909690192411307,
        "bert_precision": 0.8526877164840698,
        "bert_recall": 0.8461896181106567,
        "bert_f1": 0.84942626953125,
        "meteor": 0.09090909090909091,
        "sbert_similarity": 0.24481061100959778
      }
    },
    {
      "sample_id": 0,
      "question": "What does Melanie do to destress?",
      "prediction": "Carving out me-time such as running, reading, or playing the violin.",
      "reference": "Running, pottery",
      "category": 1,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.15384615384615385,
        "rouge1_f": 0.14285714285714285,
        "rouge2_f": 0.0,
        "rougeL_f": 0.14285714285714285,
        "bleu1": 0.14285714285714285,
        "bleu2": 0.10482848367219184,
        "bleu3": 0.04649288856043541,
        "bleu4": 0.030206205252435548,
        "bert_precision": 0.8484804630279541,
        "bert_recall": 0.8560681939125061,
        "bert_f1": 0.852257490158081,
        "meteor": 0.1724137931034483,
        "sbert_similarity": 0.435657799243927
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline go to the LGBTQ conference?",
      "prediction": "3 July, 2023",
      "reference": "10 July 2023",
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.5,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.5,
        "bleu2": 0.12909944487358058,
        "bleu3": 0.09635409769034631,
        "bleu4": 0.09554427922043669,
        "bert_precision": 0.9613050222396851,
        "bert_recall": 0.980563759803772,
        "bert_f1": 0.9708389043807983,
        "meteor": 0.16666666666666666,
        "sbert_similarity": 0.8341851234436035
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie read the book \"nothing is impossible\"?",
      "prediction": "9 June, 2023",
      "reference": 2022,
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.901813805103302,
        "bert_recall": 0.9299807548522949,
        "bert_f1": 0.9156807661056519,
        "meteor": 0.0,
        "sbert_similarity": 0.5873350501060486
      }
    },
    {
      "sample_id": 0,
      "question": "Would Caroline pursue writing as a career option?",
      "prediction": "No",
      "reference": "LIkely no; though she likes reading, she wants to be a counselor",
      "category": 3,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.15384615384615385,
        "rouge2_f": 0.0,
        "rougeL_f": 0.15384615384615385,
        "bleu1": 2.2603294069810542e-06,
        "bleu2": 7.14778918831783e-07,
        "bleu3": 4.945061934077801e-07,
        "bleu4": 4.0194972443398975e-07,
        "bert_precision": 0.8570750951766968,
        "bert_recall": 0.8017058968544006,
        "bert_f1": 0.8284663558006287,
        "meteor": 0.0,
        "sbert_similarity": 0.1082494780421257
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline go to the adoption meeting?",
      "prediction": "August 23rd",
      "reference": "The friday before 15 July 2023",
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8942584991455078,
        "bert_recall": 0.8436445593833923,
        "bert_f1": 0.86821448802948,
        "meteor": 0.0,
        "sbert_similarity": 0.5754455327987671
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie go to the pottery workshop?",
      "prediction": "July 15, 2023",
      "reference": "The Friday before 15 July 2023",
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4444444444444444,
        "bleu1": 0.45489799478447507,
        "bleu2": 0.0959009177708225,
        "bleu3": 0.06680870649838855,
        "bleu4": 0.0641328089975786,
        "bert_precision": 0.9404500722885132,
        "bert_recall": 0.8979936838150024,
        "bert_f1": 0.918731689453125,
        "meteor": 0.17543859649122806,
        "sbert_similarity": 0.7880334854125977
      }
    },
    {
      "sample_id": 0,
      "question": "Would Melanie be considered a member of the LGBTQ community?",
      "prediction": "Yes",
      "reference": "Likely no, she does not refer to herself as part of it",
      "category": 3,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8459942936897278,
        "bert_recall": 0.8135164976119995,
        "bert_f1": 0.8294376134872437,
        "meteor": 0.0,
        "sbert_similarity": 0.17943957448005676
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie go camping in June?",
      "prediction": "27 June",
      "reference": "The week before 27 June 2023",
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.5,
        "rouge1_f": 0.5,
        "rouge2_f": 0.33333333333333337,
        "rougeL_f": 0.5,
        "bleu1": 0.1353352832366127,
        "bleu2": 0.1353352832366127,
        "bleu3": 0.06330106782582003,
        "bleu4": 0.04279677428117006,
        "bert_precision": 0.8995470404624939,
        "bert_recall": 0.855449914932251,
        "bert_f1": 0.8769444227218628,
        "meteor": 0.33482142857142855,
        "sbert_similarity": 0.6680140495300293
      }
    },
    {
      "sample_id": 0,
      "question": "What LGBTQ+ events has Caroline participated in?",
      "prediction": "Caroline has participated in a school event about her transgender journey and an LGBTQ activist group meetup.",
      "reference": "Pride parade, school speech, support group",
      "category": 1,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.1739130434782609,
        "rouge1_f": 0.1739130434782609,
        "rouge2_f": 0.0,
        "rougeL_f": 0.1739130434782609,
        "bleu1": 0.11111111111111109,
        "bleu2": 0.02556549962824567,
        "bleu3": 0.016660661223010558,
        "bleu4": 0.01284618972676772,
        "bert_precision": 0.8668328523635864,
        "bert_recall": 0.8779341578483582,
        "bert_f1": 0.8723481893539429,
        "meteor": 0.14084507042253522,
        "sbert_similarity": 0.413063108921051
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline go to a pride parade during the summer?",
      "prediction": "Last week",
      "reference": "The week before 3 July 2023",
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.25,
        "rouge1_f": 0.25,
        "rouge2_f": 0.0,
        "rougeL_f": 0.25,
        "bleu1": 0.06766764161830635,
        "bleu2": 0.030261889307125377,
        "bleu3": 0.02355435073584915,
        "bleu4": 0.020237345084409754,
        "bert_precision": 0.8967713117599487,
        "bert_recall": 0.8278731107711792,
        "bert_f1": 0.860945999622345,
        "meteor": 0.08928571428571427,
        "sbert_similarity": 0.5026907920837402
      }
    },
    {
      "sample_id": 0,
      "question": "What events has Caroline participated in to help children?",
      "prediction": "Caroline has participated in a charity race for mental health and is currently volunteering at an LGBTQ+ youth center.",
      "reference": "Mentoring program, school speech",
      "category": 1,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8377149701118469,
        "bert_recall": 0.8384920358657837,
        "bert_f1": 0.8381032943725586,
        "meteor": 0.0,
        "sbert_similarity": 0.22922153770923615
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie go camping in July?",
      "prediction": "15 July, 2023",
      "reference": "two weekends before 17 July 2023",
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.4444444444444444,
        "rouge1_f": 0.4444444444444444,
        "rouge2_f": 0.28571428571428575,
        "rougeL_f": 0.4444444444444444,
        "bleu1": 0.3032653298563167,
        "bleu2": 0.07830277146770757,
        "bleu3": 0.05844171443814127,
        "bleu4": 0.05795053470733952,
        "bert_precision": 0.9311733245849609,
        "bert_recall": 0.8930556178092957,
        "bert_f1": 0.9117162227630615,
        "meteor": 0.08771929824561403,
        "sbert_similarity": 0.645390510559082
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline join a mentorship program?",
      "prediction": "2023",
      "reference": "The weekend before 17 July 2023",
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.2857142857142857,
        "rouge1_f": 0.2857142857142857,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2857142857142857,
        "bleu1": 0.006737946999085467,
        "bleu2": 0.002130725927060655,
        "bleu3": 0.0014741021868805238,
        "bleu4": 0.0011981952414407235,
        "bert_precision": 0.9061209559440613,
        "bert_recall": 0.8231768608093262,
        "bert_f1": 0.862659752368927,
        "meteor": 0.0909090909090909,
        "sbert_similarity": 0.627448558807373
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie paint recently?",
      "prediction": "Melanie painted a sunflower piece.",
      "reference": "sunset",
      "category": 1,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8628098964691162,
        "bert_recall": 0.8589086532592773,
        "bert_f1": 0.8608548045158386,
        "meteor": 0.0,
        "sbert_similarity": 0.3394959568977356
      }
    },
    {
      "sample_id": 0,
      "question": "What activities has Melanie done with her family?",
      "prediction": "camping and hiking.",
      "reference": "Pottery, painting, camping, museum, swimming, hiking",
      "category": 1,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.4444444444444444,
        "rouge1_f": 0.4444444444444444,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4444444444444444,
        "bleu1": 0.08688697172522257,
        "bleu2": 0.022434119632945452,
        "bleu3": 0.016743831523260908,
        "bleu4": 0.016603106174265705,
        "bert_precision": 0.9273318648338318,
        "bert_recall": 0.8481745719909668,
        "bert_f1": 0.8859886527061462,
        "meteor": 0.0,
        "sbert_similarity": 0.6190417408943176
      }
    },
    {
      "sample_id": 0,
      "question": "In what ways is Caroline participating in the LGBTQ community?",
      "prediction": "Caroline participates through joining an activist group and attending events related to the LGBTQ+ rights movement.",
      "reference": "Joining activist group, going to pride parades, participating in an art show, mentoring program",
      "category": 1,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.3333333333333333,
        "rouge1_f": 0.39999999999999997,
        "rouge2_f": 0.07142857142857144,
        "rougeL_f": 0.26666666666666666,
        "bleu1": 0.29411764705882354,
        "bleu2": 0.13558153613666013,
        "bleu3": 0.05118494578406863,
        "bleu4": 0.03058760346458022,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.17605633802816903,
        "sbert_similarity": 0.5053346157073975
      }
    },
    {
      "sample_id": 0,
      "question": "How many times has Melanie gone to the beach in 2023?",
      "prediction": "1",
      "reference": 2,
      "category": 1,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.8054155111312866
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline join a new activist group?",
      "prediction": "Last Tues",
      "reference": "The Tuesday before 20 July 2023",
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.21039503812789917
      }
    },
    {
      "sample_id": 0,
      "question": "Would Melanie be more interested in going to a national park or a theme park?",
      "prediction": "Melaniesays: I take my kids to parks, not theme parks.",
      "reference": "National park; she likes the outdoors",
      "category": 3,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.125,
        "rouge2_f": 0.0,
        "rougeL_f": 0.125,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.4036239683628082
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of art does Caroline make?",
      "prediction": "abstract",
      "reference": "abstract art",
      "category": 1,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.0,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.36787944117144233,
        "bleu2": 0.11633369384516798,
        "bleu3": 0.08048325236348887,
        "bleu4": 0.06541924356118012,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.2631578947368421,
        "sbert_similarity": 0.7856197357177734
      }
    },
    {
      "sample_id": 0,
      "question": "When is Melanie's daughter's birthday?",
      "prediction": "25 May 2023",
      "reference": "13 August",
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.49198269844055176
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline attend a pride parade in August?",
      "prediction": "17 July 2023",
      "reference": "The Friday before 14 August 2023",
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.2222222222222222,
        "rouge1_f": 0.2222222222222222,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2222222222222222,
        "bleu1": 0.12262648039048077,
        "bleu2": 0.04749303163563625,
        "bleu3": 0.044556965439969995,
        "bleu4": 0.0417991745584234,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.08771929824561403,
        "sbert_similarity": 0.7594130039215088
      }
    },
    {
      "sample_id": 0,
      "question": "Would Melanie be considered an ally to the transgender community?",
      "prediction": "Yes",
      "reference": "Yes, she is supportive",
      "category": 3,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.4,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4,
        "bleu1": 0.01831563888873418,
        "bleu2": 0.00579191356895553,
        "bleu3": 0.004007025187889067,
        "bleu4": 0.003257032351754417,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.28309470415115356
      }
    },
    {
      "sample_id": 0,
      "question": "Who supports Caroline when she has a negative experience?",
      "prediction": "friends and family",
      "reference": "Her mentors, family, and friends",
      "category": 1,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.7499999999999999,
        "rouge1_f": 0.7499999999999999,
        "rouge2_f": 0.0,
        "rougeL_f": 0.25,
        "bleu1": 0.2635971381157267,
        "bleu2": 0.05894211195011658,
        "bleu3": 0.045877610743154634,
        "bleu4": 0.03941696592147537,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.20833333333333331,
        "sbert_similarity": 0.4482516646385193
      }
    },
    {
      "sample_id": 0,
      "question": "What types of pottery have Melanie and her kids made?",
      "prediction": "Melanie's kids have made bowls.",
      "reference": "bowls, cup",
      "category": 1,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.28571428571428575,
        "rouge1_f": 0.25,
        "rouge2_f": 0.0,
        "rougeL_f": 0.25,
        "bleu1": 0.14285714285714285,
        "bleu2": 0.048795003647426664,
        "bleu3": 0.037468614372419724,
        "bleu4": 0.033031643180138064,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.5510060787200928
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline and Melanie go to a pride fesetival together?",
      "prediction": "Last Friday",
      "reference": 2022,
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.15914350748062134
      }
    },
    {
      "sample_id": 0,
      "question": "What would Caroline's political leaning likely be?",
      "prediction": "likely progressive",
      "reference": "Liberal",
      "category": 3,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.495768666267395
      }
    },
    {
      "sample_id": 0,
      "question": "What has Melanie painted?",
      "prediction": "Melaniesays: 'Yeah, I painted that lake sunrise last year! It's special to me.'",
      "reference": "Horse, sunset, sunrise",
      "category": 1,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.11764705882352941,
        "rouge1_f": 0.11764705882352941,
        "rouge2_f": 0.0,
        "rougeL_f": 0.11764705882352941,
        "bleu1": 0.10526315789473682,
        "bleu2": 0.024182541670333724,
        "bleu3": 0.015742117131956883,
        "bleu4": 0.012109013026441871,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.125,
        "sbert_similarity": 0.471589595079422
      }
    },
    {
      "sample_id": 0,
      "question": "What are Melanie's pets' names?",
      "prediction": "pup and kitty",
      "reference": "Oliver, Luna, Bailey",
      "category": 1,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.41748642921447754
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline apply to adoption agencies?",
      "prediction": "This week",
      "reference": "The week of 23 August 2023",
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.25,
        "rouge1_f": 0.25,
        "rouge2_f": 0.0,
        "rougeL_f": 0.25,
        "bleu1": 0.06766764161830635,
        "bleu2": 0.030261889307125377,
        "bleu3": 0.02355435073584915,
        "bleu4": 0.020237345084409754,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.08928571428571427,
        "sbert_similarity": 0.477629154920578
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline draw a self-portrait?",
      "prediction": "Last week",
      "reference": "The week before 23 August 2023",
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.25,
        "rouge1_f": 0.25,
        "rouge2_f": 0.0,
        "rougeL_f": 0.25,
        "bleu1": 0.06766764161830635,
        "bleu2": 0.030261889307125377,
        "bleu3": 0.02355435073584915,
        "bleu4": 0.020237345084409754,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.08928571428571427,
        "sbert_similarity": 0.48935720324516296
      }
    },
    {
      "sample_id": 0,
      "question": "What subject have Caroline and Melanie both painted?",
      "prediction": "pottery",
      "reference": "Sunsets",
      "category": 1,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.2341538965702057
      }
    },
    {
      "sample_id": 0,
      "question": "What symbols are important to Caroline?",
      "prediction": "necklace, cross, heart",
      "reference": "Rainbow flag, transgender symbol",
      "category": 1,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0.2,
        "bleu2": 0.07071067811865477,
        "bleu3": 0.05665132701906204,
        "bleu4": 0.05372849659117709,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.320530503988266
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline encounter people on a hike and have a negative experience?",
      "prediction": "1:33 pm on 25 August, 2023",
      "reference": "The week before 25 August 2023",
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.5,
        "rouge1_f": 0.4615384615384615,
        "rouge2_f": 0.3636363636363636,
        "rougeL_f": 0.4615384615384615,
        "bleu1": 0.42857142857142855,
        "bleu2": 0.26726124191242434,
        "bleu3": 0.11511121735118796,
        "bleu4": 0.07730551756939454,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.16666666666666666,
        "sbert_similarity": 0.7329952120780945
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie make a plate in pottery class?",
      "prediction": "25 August, 2023",
      "reference": "24 August 2023",
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.5,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.5,
        "bleu2": 0.12909944487358058,
        "bleu3": 0.09635409769034631,
        "bleu4": 0.09554427922043669,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.16666666666666666,
        "sbert_similarity": 0.9536036252975464
      }
    },
    {
      "sample_id": 0,
      "question": "Would Caroline be considered religious?",
      "prediction": "No",
      "reference": "Somewhat, but not extremely religious",
      "category": 3,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.2169199436903
      }
    },
    {
      "sample_id": 0,
      "question": "What instruments does Melanie play?",
      "prediction": "Melanie plays the clarinet.",
      "reference": "clarinet and violin",
      "category": 1,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.28571428571428575,
        "rouge1_f": 0.28571428571428575,
        "rouge2_f": 0.0,
        "rougeL_f": 0.28571428571428575,
        "bleu1": 0.2,
        "bleu2": 0.07071067811865477,
        "bleu3": 0.05665132701906204,
        "bleu4": 0.05372849659117709,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.655861496925354
      }
    },
    {
      "sample_id": 0,
      "question": "What musical artists/bands has Melanie seen?",
      "prediction": "Bach, Mozart",
      "reference": "Summer Sounds, Matt Patterson",
      "category": 1,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0.17113903967753066,
        "bleu2": 0.06628186505570068,
        "bleu3": 0.0621842545921536,
        "bleu4": 0.05833544737207805,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.16346339881420135
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie go to the park?",
      "prediction": "9 June",
      "reference": "27 August 2023",
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.6262680292129517
      }
    },
    {
      "sample_id": 0,
      "question": "When is Caroline's youth center putting on a talent show?",
      "prediction": "Next month",
      "reference": "September 2023",
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.536835789680481
      }
    },
    {
      "sample_id": 0,
      "question": "Would Melanie likely enjoy the song \"The Four Seasons\" by Vivaldi?",
      "prediction": "Melanie would likely enjoy the song 'The Four Seasons' by Vivaldi because of its classical music nature, which aligns with her appreciation for both classical and modern musical genres.",
      "reference": "Yes; it's classical music",
      "category": 3,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.125,
        "rouge1_f": 0.1176470588235294,
        "rouge2_f": 0.0625,
        "rougeL_f": 0.1176470588235294,
        "bleu1": 0.0625,
        "bleu2": 0.044901325506693734,
        "bleu3": 0.019635457864014976,
        "bleu4": 0.012338142098850861,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.15384615384615385,
        "sbert_similarity": 0.3985382318496704
      }
    },
    {
      "sample_id": 0,
      "question": "What are some changes Caroline has faced during her transition journey?",
      "prediction": "Caroline overcame fear and courageously transitioned to express herself authentically, receiving invaluable support and acceptance through friends, family, and people she looked up to.",
      "reference": "Changes to her body, losing unsupportive friends",
      "category": 1,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.14285714285714285,
        "rouge1_f": 0.12903225806451613,
        "rouge2_f": 0.0,
        "rougeL_f": 0.12903225806451613,
        "bleu1": 0.10714285714285714,
        "bleu2": 0.01992047682223989,
        "bleu3": 0.012039171932923394,
        "bleu4": 0.008839374326825921,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.05747126436781609,
        "sbert_similarity": 0.3378354609012604
      }
    },
    {
      "sample_id": 0,
      "question": "What does Melanie do with her family on hikes?",
      "prediction": "Melanie enjoys hiking in the mountains and exploring forests.",
      "reference": "Roast marshmallows, tell stories",
      "category": 1,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.17750951647758484
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline go biking with friends?",
      "prediction": "8 May, 2023",
      "reference": "The weekend before 13 September 2023",
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.2222222222222222,
        "rouge1_f": 0.2222222222222222,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2222222222222222,
        "bleu1": 0.15163266492815836,
        "bleu2": 0.05536842069051654,
        "bleu3": 0.04649251600872798,
        "bleu4": 0.04873039689743777,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.08771929824561403,
        "sbert_similarity": 0.723263680934906
      }
    },
    {
      "sample_id": 0,
      "question": "How long has Melanie been practicing art?",
      "prediction": "7 years",
      "reference": "Since 2016",
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.45240360498428345
      }
    },
    {
      "sample_id": 0,
      "question": "What personality traits might Melanie say Caroline has?",
      "prediction": "Caroline's dedication and passion for helping others",
      "reference": "Thoughtful, authentic, driven",
      "category": 3,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.27236443758010864
      }
    },
    {
      "sample_id": 0,
      "question": "What transgender-specific events has Caroline attended?",
      "prediction": "Caroline has attended a school event about her transgender journey and involvement in the LGBTQ community, as well as participated in a transgender conference.",
      "reference": "Poetry reading, conference",
      "category": 1,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.08695652173913045,
        "rouge1_f": 0.07407407407407407,
        "rouge2_f": 0.0,
        "rougeL_f": 0.07407407407407407,
        "bleu1": 0.07692307692307693,
        "bleu2": 0.017541160386140592,
        "bleu3": 0.011366029557861331,
        "bleu4": 0.008640609739997756,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.20405255258083344
      }
    },
    {
      "sample_id": 0,
      "question": "What book did Melanie read from Caroline's suggestion?",
      "prediction": "The Book Thief",
      "reference": "\"Becoming Nicole\"",
      "category": 1,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.17087173461914062
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie's friend adopt a child?",
      "prediction": "last year",
      "reference": 2022,
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.3672371804714203
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie get hurt?",
      "prediction": "9 June, 2023",
      "reference": "September 2023",
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.4,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4,
        "bleu1": 0.25,
        "bleu2": 0.09128709291752769,
        "bleu3": 0.07665320007195604,
        "bleu4": 0.08034284189446518,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.2380952380952381,
        "sbert_similarity": 0.8329629302024841
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie's family go on a roadtrip?",
      "prediction": "August 25",
      "reference": "The weekend before 20 October 2023",
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.5307796001434326
      }
    },
    {
      "sample_id": 0,
      "question": "How many children does Melanie have?",
      "prediction": "None",
      "reference": 3,
      "category": 1,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.6104696393013
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie go on a hike after the roadtrip?",
      "prediction": "Melanie went on a hike in the mountains last week.",
      "reference": "19 October 2023",
      "category": 1,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.019269078969955444
      }
    },
    {
      "sample_id": 0,
      "question": "Would Melanie go on another roadtrip soon?",
      "prediction": "The talk starts at 1:56 pm on 8 May, 2023.",
      "reference": "Likely no; since this one went badly",
      "category": 3,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.10540685057640076
      }
    },
    {
      "sample_id": 0,
      "question": "What items has Melanie bought?",
      "prediction": "necklace",
      "reference": "Figurines, shoes",
      "category": 1,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.3392271399497986
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline pass the adoption interview?",
      "prediction": "2023",
      "reference": "The Friday before 22 October 2023",
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.2857142857142857,
        "rouge1_f": 0.2857142857142857,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2857142857142857,
        "bleu1": 0.006737946999085467,
        "bleu2": 0.002130725927060655,
        "bleu3": 0.0014741021868805238,
        "bleu4": 0.0011981952414407235,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0909090909090909,
        "sbert_similarity": 0.6578038930892944
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie buy the figurines?",
      "prediction": "2023",
      "reference": "21 October 2023",
      "category": 2,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.5,
        "rouge1_f": 0.5,
        "rouge2_f": 0.0,
        "rougeL_f": 0.5,
        "bleu1": 0.1353352832366127,
        "bleu2": 0.04279677428117006,
        "bleu3": 0.02960813390314045,
        "bleu4": 0.024066394763145416,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.17857142857142855,
        "sbert_similarity": 0.7944611310958862
      }
    },
    {
      "sample_id": 0,
      "question": "Would Caroline want to move back to her home country soon?",
      "prediction": "Caroline expresses excitement about Melanies family being supportive of their relocation, indicating she would likely not want to move back to her home country soon.",
      "reference": "No; she's in the process of adopting children.",
      "category": 3,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0625,
        "rouge1_f": 0.17142857142857146,
        "rouge2_f": 0.0,
        "rougeL_f": 0.1142857142857143,
        "bleu1": 0.10344827586206899,
        "bleu2": 0.019221293610962246,
        "bleu3": 0.011613054982669974,
        "bleu4": 0.008517399705356638,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.05154639175257732,
        "sbert_similarity": 0.21213562786579132
      }
    },
    {
      "sample_id": 0,
      "question": "What did the charity race raise awareness for?",
      "prediction": "mental health",
      "reference": "mental health",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 0.46773514128719823,
        "bleu4": 0.316227766016838,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9375,
        "sbert_similarity": 0.9999999403953552
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie realize after the charity race?",
      "prediction": "Melanie realized she was doing something amazing by running the charity race.",
      "reference": "self-care is important",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.14611203968524933
      }
    },
    {
      "sample_id": 0,
      "question": "How does Melanie prioritize self-care?",
      "prediction": "Melanie prioritizes self-care by running, reading, and playing her violin.",
      "reference": "by carving out some me-time each day for activities like running, reading, or playing the violin",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.38461538461538464,
        "rouge1_f": 0.35714285714285715,
        "rouge2_f": 0.07692307692307693,
        "rougeL_f": 0.35714285714285715,
        "bleu1": 0.36653744525105364,
        "bleu2": 0.24975316986585538,
        "bleu3": 0.20009914045123897,
        "bleu4": 0.15140724688504045,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.20495129870129872,
        "sbert_similarity": 0.45120859146118164
      }
    },
    {
      "sample_id": 0,
      "question": "What are Caroline's plans for the summer?",
      "prediction": "Going camping next month.",
      "reference": "researching adoption agencies",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": -0.013164050877094269
      }
    },
    {
      "sample_id": 0,
      "question": "What type of individuals does the adoption agency Caroline is considering support?",
      "prediction": "LGBTQ+ individuals through adoption",
      "reference": "LGBTQ+ individuals",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.5,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.5,
        "bleu2": 0.408248290463863,
        "bleu3": 0.20600140803015504,
        "bleu4": 0.16990442448471224,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.8522727272727273,
        "sbert_similarity": 0.7470514178276062
      }
    },
    {
      "sample_id": 0,
      "question": "Why did Caroline choose the adoption agency?",
      "prediction": "Caroline chose to apply to adoption agencies because she felt it was her dream and goal to give kids loving homes.",
      "reference": "because of their inclusivity and support for LGBTQ+ individuals",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.14285714285714285,
        "rouge1_f": 0.13333333333333333,
        "rouge2_f": 0.0,
        "rougeL_f": 0.13333333333333333,
        "bleu1": 0.0909090909090909,
        "bleu2": 0.020806259464411975,
        "bleu3": 0.013510398157576722,
        "bleu4": 0.010331208012220438,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.09803921568627451,
        "sbert_similarity": 0.17581398785114288
      }
    },
    {
      "sample_id": 0,
      "question": "What is Caroline excited about in the adoption process?",
      "prediction": "specific things",
      "reference": "creating a family for kids who need one",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.1686214953660965
      }
    },
    {
      "sample_id": 0,
      "question": "What does Melanie think about Caroline's decision to adopt?",
      "prediction": "Melanie thinks Caroline is doing something amazing by creating a family through adoption.",
      "reference": "she thinks Caroline is doing something amazing and will be an awesome mom",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.46153846153846156,
        "rouge1_f": 0.46153846153846156,
        "rouge2_f": 0.4166666666666667,
        "rougeL_f": 0.46153846153846156,
        "bleu1": 0.42857142857142855,
        "bleu2": 0.40599897147057507,
        "bleu3": 0.38386316691836725,
        "bleu4": 0.3498761149110956,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.4604700854700855,
        "sbert_similarity": 0.7562404870986938
      }
    },
    {
      "sample_id": 0,
      "question": "How long have Mel and her husband been married?",
      "prediction": "5 years",
      "reference": "Mel and her husband have been married for 5 years.",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.33333333333333337,
        "rouge1_f": 0.33333333333333337,
        "rouge2_f": 0.19999999999999998,
        "rougeL_f": 0.33333333333333337,
        "bleu1": 0.011108996538242306,
        "bleu2": 0.011108996538242306,
        "bleu3": 0.005196068065373761,
        "bleu4": 0.0035129731579771513,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.05434782608695652,
        "sbert_similarity": 0.3471320867538452
      }
    },
    {
      "sample_id": 0,
      "question": "What does Caroline's necklace symbolize?",
      "prediction": "Caroline's necklace stands for love, faith and strength.",
      "reference": "love, faith, and strength",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6153846153846153,
        "rouge2_f": 0.5454545454545454,
        "rougeL_f": 0.6153846153846153,
        "bleu1": 0.45454545454545453,
        "bleu2": 0.3692744729379982,
        "bleu3": 0.2509287951221701,
        "bleu4": 0.11731175160264001,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.22727272727272727,
        "sbert_similarity": 0.46784132719039917
      }
    },
    {
      "sample_id": 0,
      "question": "What country is Caroline's grandma from?",
      "prediction": "USA",
      "reference": "Sweden",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.6155799031257629
      }
    },
    {
      "sample_id": 0,
      "question": "What was grandma's gift to Caroline?",
      "prediction": "necklace",
      "reference": "necklace",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 0.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 0.316227766016838,
        "bleu3": 0.2187761623949553,
        "bleu4": 0.1778279410038923,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.5,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What is Melanie's hand-painted bowl a reminder of?",
      "prediction": "art and self-expression",
      "reference": "art and self-expression",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie and her family do while camping?",
      "prediction": "roasted marshmallows around the campfire and went on a hike.",
      "reference": "explored nature, roasted marshmallows, and went on a hike",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.7368421052631577,
        "rouge1_f": 0.7368421052631577,
        "rouge2_f": 0.5882352941176471,
        "rougeL_f": 0.7368421052631577,
        "bleu1": 0.6363636363636364,
        "bleu2": 0.5640760748177662,
        "bleu3": 0.4769060747896939,
        "bleu4": 0.40352786374639904,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.5318681318681319,
        "sbert_similarity": 0.8095385432243347
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of counseling and mental health services is Caroline interested in pursuing?",
      "prediction": "Carolinesays: I'm keen on counseling or working in mental health - I'd love to support those with similar issues.",
      "reference": "working with trans people, helping them accept themselves and supporting their mental health",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.25,
        "rouge1_f": 0.30303030303030304,
        "rouge2_f": 0.06451612903225808,
        "rougeL_f": 0.18181818181818185,
        "bleu1": 0.17391304347826086,
        "bleu2": 0.08891084489487741,
        "bleu3": 0.034671909414527975,
        "bleu4": 0.020828838183973034,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.2735294117647059,
        "sbert_similarity": 0.584270179271698
      }
    },
    {
      "sample_id": 0,
      "question": "What workshop did Caroline attend recently?",
      "prediction": "LGBTQ+ counseling workshop",
      "reference": "LGBTQ+ counseling workshop",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 1.000000238418579
      }
    },
    {
      "sample_id": 0,
      "question": "What was discussed in the LGBTQ+ counseling workshop?",
      "prediction": "The LGBTQ+ counseling workshop focused on various therapeutic methods and strategies to effectively work with trans people, emphasizing their mental health needs and providing support.",
      "reference": "therapeutic methods and how to best work with trans people",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.47058823529411764,
        "rouge1_f": 0.45714285714285713,
        "rouge2_f": 0.30303030303030304,
        "rougeL_f": 0.45714285714285713,
        "bleu1": 0.2962962962962963,
        "bleu2": 0.23870495801314426,
        "bleu3": 0.1929826924705226,
        "bleu4": 0.12991916506579942,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.5519077196095828,
        "sbert_similarity": 0.7604888677597046
      }
    },
    {
      "sample_id": 0,
      "question": "What motivated Caroline to pursue counseling?",
      "prediction": "Sharing her own journey and support she received improved her awareness about mental health.",
      "reference": "her own journey and the support she received, and how counseling improved her life",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.64,
        "rouge1_f": 0.6428571428571429,
        "rouge2_f": 0.46153846153846156,
        "rougeL_f": 0.6428571428571429,
        "bleu1": 0.6,
        "bleu2": 0.50709255283711,
        "bleu3": 0.39373704834616635,
        "bleu4": 0.26518122980477765,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.5357142857142857,
        "sbert_similarity": 0.7524806261062622
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of place does Caroline want to create for people?",
      "prediction": "a loving and accepting environment",
      "reference": "a safe and inviting place for people to grow",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.2857142857142857,
        "rouge1_f": 0.2857142857142857,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2857142857142857,
        "bleu1": 0.17973158564688863,
        "bleu2": 0.04493289641172216,
        "bleu3": 0.03199737863082477,
        "bleu4": 0.028709564316081952,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.11627906976744186,
        "sbert_similarity": 0.46271559596061707
      }
    },
    {
      "sample_id": 0,
      "question": "Did Melanie make the black and white bowl in the photo?",
      "prediction": "Yes",
      "reference": "Yes",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 0.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 0.316227766016838,
        "bleu3": 0.2187761623949553,
        "bleu4": 0.1778279410038923,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.5,
        "sbert_similarity": 0.9999999403953552
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of books does Caroline have in her library?",
      "prediction": "Lots of kids' books - classics, stories from different cultures, educational books, all of that.",
      "reference": "kids' books - classics, stories from different cultures, educational books",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.8181818181818181,
        "rouge1_f": 0.782608695652174,
        "rouge2_f": 0.761904761904762,
        "rougeL_f": 0.782608695652174,
        "bleu1": 0.65,
        "bleu2": 0.6407232755171874,
        "bleu3": 0.6336102437438063,
        "bleu4": 0.6198021310128995,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.8412698412698414,
        "sbert_similarity": 0.8430536985397339
      }
    },
    {
      "sample_id": 0,
      "question": "What was Melanie's favorite book from her childhood?",
      "prediction": "Charlotte's Web",
      "reference": "\"Charlotte's Web\"",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 0.513417119032592,
        "bleu2": 0.513417119032592,
        "bleu3": 0.513417119032592,
        "bleu4": 0.288715663092199,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.9549331665039062
      }
    },
    {
      "sample_id": 0,
      "question": "What book did Caroline recommend to Melanie?",
      "prediction": "The gold coin-covered book",
      "reference": "\"Becoming Nicole\"",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": -0.00778384692966938
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline take away from the book \"Becoming Nicole\"?",
      "prediction": "Caroline was inspired by Amy Ellis Nutt's story and felt hopeful about her own path.",
      "reference": "Lessons on self-acceptance and finding support",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.09523809523809522,
        "rouge1_f": 0.08695652173913043,
        "rouge2_f": 0.0,
        "rougeL_f": 0.08695652173913043,
        "bleu1": 0.0588235294117647,
        "bleu2": 0.019174124721184262,
        "bleu3": 0.014076093604378503,
        "bleu4": 0.011502783619900045,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.2717391304347826,
        "sbert_similarity": 0.1793261170387268
      }
    },
    {
      "sample_id": 0,
      "question": "What are the new shoes that Melanie got used for?",
      "prediction": "Luna and Oliver's new shoes",
      "reference": "Running",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.17725317180156708
      }
    },
    {
      "sample_id": 0,
      "question": "What is Melanie's reason for getting into running?",
      "prediction": "Melanie gets into running because it boosts her mood and helps her destress.",
      "reference": "To de-stress and clear her mind",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.2222222222222222,
        "rouge1_f": 0.2,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2,
        "bleu1": 0.14285714285714285,
        "bleu2": 0.033149677206589796,
        "bleu3": 0.021746357799665227,
        "bleu4": 0.0169861974906263,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.14925373134328357,
        "sbert_similarity": 0.3777371942996979
      }
    },
    {
      "sample_id": 0,
      "question": "What does Melanie say running has been great for?",
      "prediction": "clears my mind",
      "reference": "Her mental health",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.23316636681556702
      }
    },
    {
      "sample_id": 0,
      "question": "What did Mel and her kids make during the pottery workshop?",
      "prediction": "clay sculptures",
      "reference": "pots",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.329764723777771
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of pot did Mel and her kids make with clay?",
      "prediction": "A cup",
      "reference": "a cup with a dog face on it",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.4444444444444445,
        "rouge1_f": 0.4,
        "rouge2_f": 0.25,
        "rougeL_f": 0.4,
        "bleu1": 0.049787068367863944,
        "bleu2": 0.049787068367863944,
        "bleu3": 0.02328716145731824,
        "bleu4": 0.015744053406497194,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.13513513513513511,
        "sbert_similarity": 0.6318643093109131
      }
    },
    {
      "sample_id": 0,
      "question": "What creative project do Mel and her kids do together besides pottery?",
      "prediction": "painting",
      "reference": "painting",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 0.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 0.316227766016838,
        "bleu3": 0.2187761623949553,
        "bleu4": 0.1778279410038923,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.5,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What did Mel and her kids paint in their latest project in July 2023?",
      "prediction": "a painting like their last one.",
      "reference": "a sunset with a palm tree",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.1818181818181818,
        "rouge1_f": 0.16666666666666666,
        "rouge2_f": 0.0,
        "rougeL_f": 0.16666666666666666,
        "bleu1": 0.14285714285714285,
        "bleu2": 0.048795003647426664,
        "bleu3": 0.037468614372419724,
        "bleu4": 0.033031643180138064,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.08333333333333333,
        "sbert_similarity": 0.17710807919502258
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline see at the council meeting for adoption?",
      "prediction": "a sign with a picture of a new arrival and information about domestic buildings",
      "reference": "many people wanting to create loving homes for children in need",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.28454723954200745
      }
    },
    {
      "sample_id": 0,
      "question": "What do sunflowers represent according to Caroline?",
      "prediction": "Sunflowers symbolize happiness and warmth.",
      "reference": "warmth and happiness",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.7499999999999999,
        "rouge1_f": 0.7499999999999999,
        "rouge2_f": 0.0,
        "rougeL_f": 0.25,
        "bleu1": 0.5,
        "bleu2": 0.10000000000000002,
        "bleu3": 0.06476199262714716,
        "bleu4": 0.05372849659117709,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.3125,
        "sbert_similarity": 0.5033509731292725
      }
    },
    {
      "sample_id": 0,
      "question": "Why are flowers important to Melanie?",
      "prediction": "Flowers bring joy and represent growth, beauty, reminding us to appreciate small moments.",
      "reference": "They remind her to appreciate the small moments and were a part of her wedding decor",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.3571428571428571,
        "rouge1_f": 0.41379310344827586,
        "rouge2_f": 0.14814814814814814,
        "rougeL_f": 0.3448275862068966,
        "bleu1": 0.3125,
        "bleu2": 0.20412414523193154,
        "bleu3": 0.06859746052812911,
        "bleu4": 0.03889818545474848,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.23694267515923564,
        "sbert_similarity": 0.5022367238998413
      }
    },
    {
      "sample_id": 0,
      "question": "What inspired Caroline's painting for the art show?",
      "prediction": "Caroline's self-acceptance and love theme.",
      "reference": "visiting an LGBTQ center and wanting to capture unity and strength",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.13333333333333333,
        "rouge1_f": 0.1111111111111111,
        "rouge2_f": 0.0,
        "rougeL_f": 0.1111111111111111,
        "bleu1": 0.08067401742967989,
        "bleu2": 0.02755542282313655,
        "bleu3": 0.021159205542625806,
        "bleu4": 0.018653567503517977,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.04807692307692308,
        "sbert_similarity": 0.23503156006336212
      }
    },
    {
      "sample_id": 0,
      "question": "How often does Melanie go to the beach with her kids?",
      "prediction": "Melanie goes to the beach with her kids rarely, usually only once or twice a year.",
      "reference": "once or twice a year",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.47619047619047616,
        "rouge1_f": 0.47619047619047616,
        "rouge2_f": 0.4210526315789474,
        "rougeL_f": 0.47619047619047616,
        "bleu1": 0.2777777777777778,
        "bleu2": 0.25565499628245686,
        "bleu3": 0.23396034203975458,
        "bleu4": 0.20105373454060027,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.6506147540983607,
        "sbert_similarity": 0.3988100588321686
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie and her family see during their camping trip last year?",
      "prediction": "they went on another camping trip in the forest.",
      "reference": "Perseid meteor shower",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": -0.015214240178465843
      }
    },
    {
      "sample_id": 0,
      "question": "How did Melanie feel while watching the meteor shower?",
      "prediction": "Melanie felt tiny and in awe of the universe.",
      "reference": "in awe of the universe",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.7142857142857143,
        "rouge1_f": 0.7142857142857143,
        "rouge2_f": 0.6666666666666666,
        "rougeL_f": 0.7142857142857143,
        "bleu1": 0.5,
        "bleu2": 0.4714045207910317,
        "bleu3": 0.44042320075255215,
        "bleu4": 0.392814650900513,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.7349537037037037,
        "sbert_similarity": 0.497897207736969
      }
    },
    {
      "sample_id": 0,
      "question": "Whose birthday did Melanie celebrate recently?",
      "prediction": "Melanie's daughter",
      "reference": "Melanie's daughter",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9375,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "Who performed at the concert at Melanie's daughter's birthday?",
      "prediction": "Caroline",
      "reference": "Matt Patterson",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.23561638593673706
      }
    },
    {
      "sample_id": 0,
      "question": "Why did Melanie choose to use colors and patterns in her pottery project?",
      "prediction": "To make it visually appealing and express creativity.",
      "reference": "She wanted to catch the eye and make people smile.",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.33333333333333326,
        "rouge1_f": 0.33333333333333326,
        "rouge2_f": 0.0,
        "rougeL_f": 0.22222222222222224,
        "bleu1": 0.35588329018524795,
        "bleu2": 0.059683442168287366,
        "bleu3": 0.035511403352208336,
        "bleu4": 0.027155616465759737,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.1530612244897959,
        "sbert_similarity": 0.4043256640434265
      }
    },
    {
      "sample_id": 0,
      "question": "What pet does Caroline have?",
      "prediction": "a cat",
      "reference": "guinea pig",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.37402838468551636
      }
    },
    {
      "sample_id": 0,
      "question": "What pets does Melanie have?",
      "prediction": "A cat and a dog",
      "reference": "Two cats and a dog",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666665,
        "rouge1_f": 0.8000000000000002,
        "rouge2_f": 0.75,
        "rougeL_f": 0.8000000000000002,
        "bleu1": 0.6,
        "bleu2": 0.5477225575051662,
        "bleu3": 0.4677351412871982,
        "bleu4": 0.26591479484724945,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.7937500000000002,
        "sbert_similarity": 0.8987439870834351
      }
    },
    {
      "sample_id": 0,
      "question": "Where did Oliver hide his bone once?",
      "prediction": "someone's slipper",
      "reference": "In Melanie's slipper",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.5714285714285715,
        "rouge2_f": 0.4,
        "rougeL_f": 0.5714285714285715,
        "bleu1": 0.47768754038252614,
        "bleu2": 0.41368954504257255,
        "bleu3": 0.23323040081963617,
        "bleu4": 0.17216896116316355,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.17241379310344826,
        "sbert_similarity": 0.6148541569709778
      }
    },
    {
      "sample_id": 0,
      "question": "What activity did Caroline used to do with her dad?",
      "prediction": "roasting marshmallows around the campfire",
      "reference": "Horseback riding",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": -0.00467127189040184
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline make for a local church?",
      "prediction": "A poster",
      "reference": "a stained glass window",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.3333333333333333,
        "rouge1_f": 0.3333333333333333,
        "rouge2_f": 0.0,
        "rougeL_f": 0.3333333333333333,
        "bleu1": 0.18393972058572117,
        "bleu2": 0.082260343798398,
        "bleu3": 0.06402736358640969,
        "bleu4": 0.05501080739920602,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.13157894736842105,
        "sbert_similarity": 0.24058020114898682
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline find in her neighborhood during her walk?",
      "prediction": "Caroline found a frisbee.",
      "reference": "a rainbow sidewalk",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.28571428571428575,
        "rouge1_f": 0.28571428571428575,
        "rouge2_f": 0.0,
        "rougeL_f": 0.28571428571428575,
        "bleu1": 0.2,
        "bleu2": 0.07071067811865477,
        "bleu3": 0.05665132701906204,
        "bleu4": 0.05372849659117709,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.16129032258064518,
        "sbert_similarity": 0.1888529360294342
      }
    },
    {
      "sample_id": 0,
      "question": "Which song motivates Caroline to be courageous?",
      "prediction": "Brave",
      "reference": "Brave by Sara Bareilles",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.4,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4,
        "bleu1": 0.049787068367863944,
        "bleu2": 0.015744053406497194,
        "bleu3": 0.010892223754416544,
        "bleu4": 0.008853531856477262,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.13513513513513511,
        "sbert_similarity": 0.5007990598678589
      }
    },
    {
      "sample_id": 0,
      "question": "Which  classical musicians does Melanie enjoy listening to?",
      "prediction": "Bach and Mozart",
      "reference": "Bach and Mozart",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "Who is Melanie a fan of in terms of modern music?",
      "prediction": "Ed Sheeran",
      "reference": "Ed Sheeran",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 0.46773514128719823,
        "bleu4": 0.316227766016838,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9375,
        "sbert_similarity": 1.000000238418579
      }
    },
    {
      "sample_id": 0,
      "question": "How long has Melanie been creating art?",
      "prediction": "Seven years",
      "reference": "7 years",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.5,
        "rouge1_f": 0.5,
        "rouge2_f": 0.0,
        "rougeL_f": 0.5,
        "bleu1": 0.5,
        "bleu2": 0.223606797749979,
        "bleu3": 0.1740444189610778,
        "bleu4": 0.1495348781221221,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9375,
        "sbert_similarity": 0.95577472448349
      }
    },
    {
      "sample_id": 0,
      "question": "What precautionary sign did Melanie see at the caf?",
      "prediction": "A sign posted on a door stating that someone is not being able to leave",
      "reference": "A sign stating that someone is not being able to leave",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.88,
        "rouge1_f": 0.846153846153846,
        "rouge2_f": 0.75,
        "rougeL_f": 0.846153846153846,
        "bleu1": 0.7333333333333333,
        "bleu2": 0.6866065623255951,
        "bleu3": 0.6360749521034652,
        "bleu4": 0.5968774175634496,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.955125416847905,
        "sbert_similarity": 0.8908344507217407
      }
    },
    {
      "sample_id": 0,
      "question": "What advice does Caroline give for getting started with adoption?",
      "prediction": "Thanks, Caroline! The event was really thought-provoking.",
      "reference": "Do research, find an adoption agency or lawyer, gather necessary documents, and prepare emotionally.",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0.08986579282344431,
        "bleu2": 0.02118157050072095,
        "bleu3": 0.01409238791227916,
        "bleu4": 0.011277537484327563,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.007245264016091824
      }
    },
    {
      "sample_id": 0,
      "question": "What setback did Melanie face in October 2023?",
      "prediction": "Melanie faced a setback in October 2023 related to her transition and dealing with mental health.",
      "reference": "She got hurt and had to take a break from pottery.",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.2222222222222222,
        "rouge1_f": 0.2222222222222222,
        "rouge2_f": 0.0,
        "rougeL_f": 0.07407407407407407,
        "bleu1": 0.23529411764705885,
        "bleu2": 0.03834824944236853,
        "bleu3": 0.022241390914229782,
        "bleu4": 0.01626739260030573,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.1739130434782609,
        "sbert_similarity": 0.27528589963912964
      }
    },
    {
      "sample_id": 0,
      "question": "What does Melanie do to keep herself busy during her pottery break?",
      "prediction": "Melanie makes pottery.",
      "reference": "Read a book and paint.",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0.15163266492815836,
        "bleu2": 0.05536842069051654,
        "bleu3": 0.04649251600872798,
        "bleu4": 0.04873039689743777,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.18910202383995056
      }
    },
    {
      "sample_id": 0,
      "question": "What painting did Melanie show to Caroline on October 13, 2023?",
      "prediction": "[Image: a painting of a sunset with pink sky]",
      "reference": "A painting inspired by sunsets with a pink sky.",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.5,
        "rouge1_f": 0.7777777777777778,
        "rouge2_f": 0.375,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.5,
        "bleu2": 0.30151134457776363,
        "bleu3": 0.09916088951040199,
        "bleu4": 0.05637560315259291,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.5679012345679012,
        "sbert_similarity": 0.9067397713661194
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of painting did Caroline share with Melanie on October 13, 2023?",
      "prediction": "A bouquet of sunflowers and roses",
      "reference": "An abstract painting with blue streaks on a wall.",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.13333333333333333,
        "rouge1_f": 0.13333333333333333,
        "rouge2_f": 0.0,
        "rougeL_f": 0.13333333333333333,
        "bleu1": 0.08556951983876535,
        "bleu2": 0.029642151188002917,
        "bleu3": 0.023138784118796173,
        "bleu4": 0.020960166113993737,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0574712643678161,
        "sbert_similarity": 0.1336210072040558
      }
    },
    {
      "sample_id": 0,
      "question": "What was the poetry reading that Caroline attended about?",
      "prediction": "I'm sorry, but there is no mention of a specific poem or theme being discussed in this dialogue.",
      "reference": "It was a transgender poetry reading where transgender people shared their stories.",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.06896551724137931,
        "rouge1_f": 0.06451612903225808,
        "rouge2_f": 0.0,
        "rougeL_f": 0.06451612903225808,
        "bleu1": 0.09523809523809525,
        "bleu2": 0.02182178902359924,
        "bleu3": 0.0141800886003256,
        "bleu4": 0.010862721615727716,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.03968253968253969,
        "sbert_similarity": 0.47062814235687256
      }
    },
    {
      "sample_id": 0,
      "question": "What did the posters at the poetry reading say?",
      "prediction": "trans lives matter",
      "reference": "\"Trans Lives Matter\"",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.3333333333333333,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 0.513417119032592,
        "bleu2": 0.513417119032592,
        "bleu3": 0.513417119032592,
        "bleu4": 0.288715663092199,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.16666666666666666,
        "sbert_similarity": 0.9525076746940613
      }
    },
    {
      "sample_id": 0,
      "question": "What does Caroline's drawing symbolize for her?",
      "prediction": "freedom and being real",
      "reference": "Freedom and being true to herself.",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.6,
        "rouge1_f": 0.6,
        "rouge2_f": 0.5,
        "rougeL_f": 0.6,
        "bleu1": 0.354274914555761,
        "bleu2": 0.3340135926488844,
        "bleu3": 0.2989505394514747,
        "bleu4": 0.1878296463217631,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.5076628352490421,
        "sbert_similarity": 0.6762144565582275
      }
    },
    {
      "sample_id": 0,
      "question": "How do Melanie and Caroline describe their journey through life together?",
      "prediction": "Life's all about creating memories and learning and exploring together.",
      "reference": "An ongoing adventure of learning and growing.",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.25,
        "rouge1_f": 0.2222222222222222,
        "rouge2_f": 0.125,
        "rougeL_f": 0.2222222222222222,
        "bleu1": 0.25,
        "bleu2": 0.1507556722888818,
        "bleu3": 0.06275677488087485,
        "bleu4": 0.03986357128268015,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.2568493150684931,
        "sbert_similarity": 0.5179522633552551
      }
    },
    {
      "sample_id": 0,
      "question": "What happened to Melanie's son on their road trip?",
      "prediction": "Melanie's son was okay after an accident.",
      "reference": "He got into an accident",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.3333333333333333,
        "rouge1_f": 0.3076923076923077,
        "rouge2_f": 0.18181818181818182,
        "rougeL_f": 0.3076923076923077,
        "bleu1": 0.2222222222222222,
        "bleu2": 0.16666666666666669,
        "bleu3": 0.07542890820012248,
        "bleu4": 0.050712153369465586,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.09615384615384616,
        "sbert_similarity": 0.47196274995803833
      }
    },
    {
      "sample_id": 0,
      "question": "How did Melanie's son handle the accident?",
      "prediction": "The speaker is commenting on the children's appearance and their ability to make people happy, especially after mentioning that a child experienced an accident.",
      "reference": "He was scared but reassured by his family",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.22466760873794556
      }
    },
    {
      "sample_id": 0,
      "question": "How did Melanie feel about her family after the accident?",
      "prediction": "Melanie felt lucky to have her family during that time.",
      "reference": "They are important and mean the world to her",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.2105263157894737,
        "rouge1_f": 0.2105263157894737,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2105263157894737,
        "bleu1": 0.18181818181818182,
        "bleu2": 0.042640143271122095,
        "bleu3": 0.028234511901075607,
        "bleu4": 0.022416933501922302,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.10989010989010987,
        "sbert_similarity": 0.24895715713500977
      }
    },
    {
      "sample_id": 0,
      "question": "How did Melanie's children handle the accident?",
      "prediction": "The context does not provide specific information about how Melanie's children handled the accident.",
      "reference": "They were scared but resilient",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.14610442519187927
      }
    },
    {
      "sample_id": 0,
      "question": "How did Melanie feel after the accident?",
      "prediction": "Melanie felt tiny and in awe of the universe.",
      "reference": "Grateful and thankful for her family",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.13333333333333333,
        "rouge1_f": 0.13333333333333333,
        "rouge2_f": 0.0,
        "rougeL_f": 0.13333333333333333,
        "bleu1": 0.10000000000000002,
        "bleu2": 0.03333333333333335,
        "bleu3": 0.024950558772614845,
        "bleu4": 0.021105340631872645,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.07936507936507937,
        "sbert_similarity": 0.2951657176017761
      }
    },
    {
      "sample_id": 0,
      "question": "What was Melanie's reaction to her children enjoying the Grand Canyon?",
      "prediction": "That was a blast!",
      "reference": "She was happy and thankful",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.22222222222222224,
        "rouge1_f": 0.22222222222222224,
        "rouge2_f": 0.0,
        "rougeL_f": 0.22222222222222224,
        "bleu1": 0.2,
        "bleu2": 0.07071067811865477,
        "bleu3": 0.05665132701906204,
        "bleu4": 0.05372849659117709,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.10204081632653061,
        "sbert_similarity": 0.2775891125202179
      }
    },
    {
      "sample_id": 0,
      "question": "What do Melanie's family give her?",
      "prediction": "refreshes her and helps her stay present for her fam!",
      "reference": "Strength and motivation",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.18181818181818182,
        "rouge1_f": 0.15384615384615383,
        "rouge2_f": 0.0,
        "rougeL_f": 0.15384615384615383,
        "bleu1": 0.0909090909090909,
        "bleu2": 0.03015113445777637,
        "bleu3": 0.022461584318318094,
        "bleu4": 0.018850319022747353,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.13513513513513514,
        "sbert_similarity": 0.08587739616632462
      }
    },
    {
      "sample_id": 0,
      "question": "How did Melanie feel about her family supporting her?",
      "prediction": "Melanie felt great support and positivity from her family.",
      "reference": "She appreciated them a lot",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.47307735681533813
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie do after the road trip to relax?",
      "prediction": "Running farther",
      "reference": "Went on a nature walk or hike",
      "category": 4,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.37550801038742065
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline realize after her charity race?",
      "prediction": "self-care is important",
      "reference": "self-care is important",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 0.9999999403953552
      }
    },
    {
      "sample_id": 0,
      "question": "What are Melanie's plans for the summer with respect to adoption?",
      "prediction": "researching adoption agencies",
      "reference": "researching adoption agencies",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What type of individuals does the adoption agency Melanie is considering support?",
      "prediction": "LGBTQ+",
      "reference": "LGBTQ+ individuals",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.0,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.36787944117144233,
        "bleu2": 0.11633369384516798,
        "bleu3": 0.08048325236348887,
        "bleu4": 0.06541924356118012,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.2631578947368421,
        "sbert_similarity": 0.8889155387878418
      }
    },
    {
      "sample_id": 0,
      "question": "Why did Melanie choose the adoption agency?",
      "prediction": "Not mentioned in the conversation",
      "reference": "because of their inclusivity and support for LGBTQ+ individuals",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.09916667640209198
      }
    },
    {
      "sample_id": 0,
      "question": "What is Melanie excited about in her adoption process?",
      "prediction": "creating a family for kids who need one",
      "reference": "creating a family for kids who need one",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9990234375,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What does Melanie's necklace symbolize?",
      "prediction": "love, faith, and strength",
      "reference": "love, faith, and strength",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9921875,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "What country is Melanie's grandma from?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Sweden",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.12741497159004211
      }
    },
    {
      "sample_id": 0,
      "question": "What was grandma's gift to Melanie?",
      "prediction": "necklace",
      "reference": "necklace",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 0.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 0.316227766016838,
        "bleu3": 0.2187761623949553,
        "bleu4": 0.1778279410038923,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.5,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What was grandpa's gift to Caroline?",
      "prediction": "necklace",
      "reference": "necklace",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 0.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 0.316227766016838,
        "bleu3": 0.2187761623949553,
        "bleu4": 0.1778279410038923,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.5,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What is Caroline's hand-painted bowl a reminder of?",
      "prediction": "art and self-expression",
      "reference": "art and self-expression",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline and her family do while camping?",
      "prediction": "roasted marshmallows, roasting marshmallows around the campfire, hiked",
      "reference": "explored nature, roasted marshmallows, and went on a hike",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.25,
        "rouge1_f": 0.35294117647058826,
        "rouge2_f": 0.13333333333333333,
        "rougeL_f": 0.35294117647058826,
        "bleu1": 0.36193496721438384,
        "bleu2": 0.2697703967085066,
        "bleu3": 0.2049606660441659,
        "bleu4": 0.10156297514737136,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.28714107365792757,
        "sbert_similarity": 0.7258478403091431
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of counseling and mental health services is Melanie interested in pursuing?",
      "prediction": "Not mentioned in the conversation or working with trans people, helping them accept themselves and supporting their mental health",
      "reference": "working with trans people, helping them accept themselves and supporting their mental health",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.8125000000000001,
        "rouge1_f": 0.8125000000000001,
        "rouge2_f": 0.8,
        "rougeL_f": 0.8125000000000001,
        "bleu1": 0.7,
        "bleu2": 0.6920602346769048,
        "bleu3": 0.6860959499274262,
        "bleu4": 0.6741942962447748,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9556648103028194,
        "sbert_similarity": 0.8913708925247192
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of counseling workshop did Melanie attend recently?",
      "prediction": "Not mentioned in the conversation",
      "reference": "LGBTQ+ counseling workshop",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.11074957251548767
      }
    },
    {
      "sample_id": 0,
      "question": "What motivated Melanie to pursue counseling?",
      "prediction": "Sharing their experiences motivates others, and by sharing her story, Caroline was able to inspire Melanie.",
      "reference": "her own journey and the support she received, and how counseling improved her life",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.14814814814814814,
        "rouge1_f": 0.13333333333333333,
        "rouge2_f": 0.0,
        "rougeL_f": 0.13333333333333333,
        "bleu1": 0.15789473684210523,
        "bleu2": 0.09365858115816939,
        "bleu3": 0.03847452395409486,
        "bleu4": 0.023830412565256146,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.07042253521126761,
        "sbert_similarity": 0.4989711046218872
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of place does Melanie want to create for people?",
      "prediction": "Not mentioned in the conversation",
      "reference": "a safe and inviting place for people to grow",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.10203893482685089
      }
    },
    {
      "sample_id": 0,
      "question": "Did Caroline make the black and white bowl in the photo?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Yes",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.1172415167093277
      }
    },
    {
      "sample_id": 0,
      "question": "What are the new shoes that Caroline got used for?",
      "prediction": "Running",
      "reference": "Running",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 0.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 0.316227766016838,
        "bleu3": 0.2187761623949553,
        "bleu4": 0.1778279410038923,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.5,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What is Caroline's reason for getting into running?",
      "prediction": "To de-stress and clear her mind",
      "reference": "To de-stress and clear her mind",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9976851851851852,
        "sbert_similarity": 1.000000238418579
      }
    },
    {
      "sample_id": 0,
      "question": "What does Caroline say running has been great for?",
      "prediction": "clear my mind",
      "reference": "Her mental health",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.250509649515152
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie see at the council meeting for adoption?",
      "prediction": "many people wanting to create loving homes for children in need",
      "reference": "many people wanting to create loving homes for children in need",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9996243425995492,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What inspired Melanie's painting for the art show?",
      "prediction": "visiting an LGBTQ center and wanting to capture unity and strength",
      "reference": "visiting an LGBTQ center and wanting to capture unity and strength",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9996243425995492,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What inspired Caroline's sculpture for the art show?",
      "prediction": "Not mentioned in the conversation",
      "reference": "visiting an LGBTQ center and wanting to capture unity and strength",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": -0.0016056559979915619
      }
    },
    {
      "sample_id": 0,
      "question": "How often does Caroline go to the beach with her kids?",
      "prediction": "Once or twice a year",
      "reference": "once or twice a year",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.996,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline and her family see during their camping trip last year?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Perseid meteor shower",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.03334156796336174
      }
    },
    {
      "sample_id": 0,
      "question": "How did Caroline feel while watching the meteor shower?",
      "prediction": "in awe of the universe",
      "reference": "in awe of the universe",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.996,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "Why did Caroline choose to use colors and patterns in her pottery project?",
      "prediction": "Not mentioned in the conversation",
      "reference": "She wanted to catch the eye and make people smile.",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.13333333333333333,
        "rouge1_f": 0.13333333333333333,
        "rouge2_f": 0.0,
        "rougeL_f": 0.13333333333333333,
        "bleu1": 0.060238842382440407,
        "bleu2": 0.02129764696972561,
        "bleu3": 0.01706305179528683,
        "bleu4": 0.016182712188007015,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.052631578947368425,
        "sbert_similarity": 0.04110628366470337
      }
    },
    {
      "sample_id": 0,
      "question": "Is Oscar Melanie's pet?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Yes",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.1172415167093277
      }
    },
    {
      "sample_id": 0,
      "question": "Where did Oscar hide his bone once?",
      "prediction": "In Melanie's slipper",
      "reference": "In Melanie's slipper",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "What activity did Melanie used to do with her dad?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Horseback riding",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.05627930909395218
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie make for a local church?",
      "prediction": "Not mentioned in the conversation",
      "reference": "a stained glass window",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.03617015480995178
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie find in her neighborhood during her walk?",
      "prediction": "Not mentioned in the conversation",
      "reference": "a rainbow sidewalk",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": -0.04855134338140488
      }
    },
    {
      "sample_id": 0,
      "question": "Which song motivates Melanie to be courageous?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Brave by Sara Bareilles",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": -0.004309762269258499
      }
    },
    {
      "sample_id": 0,
      "question": "What type of instrument does Caroline play?",
      "prediction": "clarinet",
      "reference": "clarinet and violin",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.5,
        "rouge1_f": 0.5,
        "rouge2_f": 0.0,
        "rougeL_f": 0.5,
        "bleu1": 0.1353352832366127,
        "bleu2": 0.04279677428117006,
        "bleu3": 0.02960813390314045,
        "bleu4": 0.024066394763145416,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.17857142857142855,
        "sbert_similarity": 0.8449620604515076
      }
    },
    {
      "sample_id": 0,
      "question": "Which classical musicians does Caroline enjoy listening to?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Bach and Mozart",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.1029241532087326
      }
    },
    {
      "sample_id": 0,
      "question": "Who is Caroline a fan of in terms of modern music?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Ed Sheeran",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.09608790278434753
      }
    },
    {
      "sample_id": 0,
      "question": "What precautionary sign did Caroline see at the caf?",
      "prediction": "Not mentioned in the conversation",
      "reference": "A sign stating that someone is not being able to leave",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.12500000000000003,
        "rouge1_f": 0.12500000000000003,
        "rouge2_f": 0.0,
        "rougeL_f": 0.12500000000000003,
        "bleu1": 0.060238842382440407,
        "bleu2": 0.02129764696972561,
        "bleu3": 0.01706305179528683,
        "bleu4": 0.016182712188007015,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.04807692307692308,
        "sbert_similarity": 0.09248797595500946
      }
    },
    {
      "sample_id": 0,
      "question": "What setback did Caroline face recently?",
      "prediction": "Not mentioned in the conversation",
      "reference": "She got hurt and had to take a break from pottery.",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.03774169832468033
      }
    },
    {
      "sample_id": 0,
      "question": "What does Caroline do to keep herself busy during her pottery break?",
      "prediction": "Reading a book and painting",
      "reference": "Read a book and paint.",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.6,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 0.49123845184678916,
        "bleu2": 0.448437301984003,
        "bleu3": 0.38294914446710404,
        "bleu4": 0.21771262023986562,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.7937500000000002,
        "sbert_similarity": 0.6699373722076416
      }
    },
    {
      "sample_id": 0,
      "question": "What was the poetry reading that Melanie attended about?",
      "prediction": "It was a transgender poetry reading where transgender people shared their stories.",
      "reference": "It was a transgender poetry reading where transgender people shared their stories.",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9997106481481481,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "What happened to Caroline's son on their road trip?",
      "prediction": "He got into an accident",
      "reference": "He got into an accident",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.996,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "How did Caroline's son handle the accident?",
      "prediction": "He was scared but reassured by his family",
      "reference": "He was scared but reassured by his family",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9990234375,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "How did Caroline feel about her family after the accident?",
      "prediction": "They are important and mean the world to her",
      "reference": "They are important and mean the world to her",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9993141289437586,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "How did Caroline's children handle the accident?",
      "prediction": "They were scared but resilient",
      "reference": "They were scared but resilient",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.996,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "How did Caroline feel after the accident?",
      "prediction": "Grateful and thankful for her family",
      "reference": "Grateful and thankful for her family",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9976851851851852,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What was Caroline's reaction to her children enjoying the Grand Canyon?",
      "prediction": "She was happy and thankful.",
      "reference": "She was happy and thankful",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 0.8333333333333334,
        "bleu2": 0.816496580927726,
        "bleu3": 0.7955364837549187,
        "bleu4": 0.7598356856515925,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.7937500000000002,
        "sbert_similarity": 0.9901379942893982
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline do after the road trip to relax?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Went on a nature walk or hike",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.06870588660240173
      }
    },
    {
      "sample_id": 0,
      "question": "What does Caroline love most about camping with her family?",
      "prediction": "Being present and bonding with her family",
      "reference": "Being present and bonding with her family",
      "category": 5,
      "strategy": "baseline",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9985422740524781,
        "sbert_similarity": 1.0000001192092896
      }
    }
  ],
  "adaptmr_results": [
    {
      "sample_id": 0,
      "question": "When did Caroline go to the LGBTQ support group?",
      "prediction": "8 May 2023",
      "reference": "7 May 2023",
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.5,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.6666666666666666,
        "bleu2": 0.5773502691896257,
        "bleu3": 0.3254992452916931,
        "bleu4": 0.24028114141347542,
        "bert_precision": 0.991973876953125,
        "bert_recall": 0.991973876953125,
        "bert_f1": 0.991973876953125,
        "meteor": 0.625,
        "sbert_similarity": 0.9042328596115112
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie paint a sunrise?",
      "prediction": "2023-05-08",
      "reference": 2022,
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8490743637084961,
        "bert_recall": 0.9383019208908081,
        "bert_f1": 0.8914609551429749,
        "meteor": 0.0,
        "sbert_similarity": 0.6247018575668335
      }
    },
    {
      "sample_id": 0,
      "question": "What fields would Caroline be likely to pursue in her educaton?",
      "prediction": "Counseling and mental health",
      "reference": "Psychology, counseling certification",
      "category": 3,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.28571428571428575,
        "rouge1_f": 0.28571428571428575,
        "rouge2_f": 0.0,
        "rougeL_f": 0.28571428571428575,
        "bleu1": 0.25,
        "bleu2": 0.09128709291752769,
        "bleu3": 0.07665320007195604,
        "bleu4": 0.08034284189446518,
        "bert_precision": 0.8713847398757935,
        "bert_recall": 0.8638726472854614,
        "bert_f1": 0.8676124215126038,
        "meteor": 0.16129032258064518,
        "sbert_similarity": 0.6725395917892456
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline research?",
      "prediction": "counseling or mental health work",
      "reference": "Adoption agencies",
      "category": 1,
      "strategy": "multi_hop",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8135918378829956,
        "bert_recall": 0.8642898797988892,
        "bert_f1": 0.8381749391555786,
        "meteor": 0.0,
        "sbert_similarity": 0.1471395045518875
      }
    },
    {
      "sample_id": 0,
      "question": "What is Caroline's identity?",
      "prediction": "transgender",
      "reference": "Transgender woman",
      "category": 1,
      "strategy": "multi_hop",
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.0,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.36787944117144233,
        "bleu2": 0.11633369384516798,
        "bleu3": 0.08048325236348887,
        "bleu4": 0.06541924356118012,
        "bert_precision": 0.9624814987182617,
        "bert_recall": 0.9216964244842529,
        "bert_f1": 0.9416475892066956,
        "meteor": 0.2631578947368421,
        "sbert_similarity": 0.8627292513847351
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie run a charity race?",
      "prediction": "8 May 2023",
      "reference": "The sunday before 25 May 2023",
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.4444444444444444,
        "rouge1_f": 0.4444444444444444,
        "rouge2_f": 0.28571428571428575,
        "rougeL_f": 0.4444444444444444,
        "bleu1": 0.24525296078096154,
        "bleu2": 0.21239529438966132,
        "bleu3": 0.11974448045963429,
        "bleu4": 0.08839449202722564,
        "bert_precision": 0.9478057622909546,
        "bert_recall": 0.8704673647880554,
        "bert_f1": 0.9074918031692505,
        "meteor": 0.3289473684210526,
        "sbert_similarity": 0.8088302612304688
      }
    },
    {
      "sample_id": 0,
      "question": "When is Melanie planning on going camping?",
      "prediction": "25 May, 2023",
      "reference": "June 2023",
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.4,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4,
        "bleu1": 0.25,
        "bleu2": 0.09128709291752769,
        "bleu3": 0.07665320007195604,
        "bleu4": 0.08034284189446518,
        "bert_precision": 0.9159290790557861,
        "bert_recall": 0.952430248260498,
        "bert_f1": 0.9338231086730957,
        "meteor": 0.2380952380952381,
        "sbert_similarity": 0.8301676511764526
      }
    },
    {
      "sample_id": 0,
      "question": "What is Caroline's relationship status?",
      "prediction": "single",
      "reference": "Single",
      "category": 1,
      "strategy": "multi_hop",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 0.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 0.316227766016838,
        "bleu3": 0.2187761623949553,
        "bleu4": 0.1778279410038923,
        "bert_precision": 0.9069305658340454,
        "bert_recall": 0.9069305658340454,
        "bert_f1": 0.9069305658340454,
        "meteor": 0.5,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline give a speech at a school?",
      "prediction": "8 May 2023",
      "reference": "The week before 9 June 2023",
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.2222222222222222,
        "rouge1_f": 0.2222222222222222,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2222222222222222,
        "bleu1": 0.12262648039048077,
        "bleu2": 0.04749303163563625,
        "bleu3": 0.044556965439969995,
        "bleu4": 0.0417991745584234,
        "bert_precision": 0.9300906658172607,
        "bert_recall": 0.8876339793205261,
        "bert_f1": 0.9083664417266846,
        "meteor": 0.08771929824561403,
        "sbert_similarity": 0.7655600309371948
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline meet up with her friends, family, and mentors?",
      "prediction": "8 May 2023",
      "reference": "The week before 9 June 2023",
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.2222222222222222,
        "rouge1_f": 0.2222222222222222,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2222222222222222,
        "bleu1": 0.12262648039048077,
        "bleu2": 0.04749303163563625,
        "bleu3": 0.044556965439969995,
        "bleu4": 0.0417991745584234,
        "bert_precision": 0.9300906658172607,
        "bert_recall": 0.8876339793205261,
        "bert_f1": 0.9083664417266846,
        "meteor": 0.08771929824561403,
        "sbert_similarity": 0.7655600309371948
      }
    },
    {
      "sample_id": 0,
      "question": "How long has Caroline had her current group of friends for?",
      "prediction": "Since 2023",
      "reference": "4 years",
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.858249306678772,
        "bert_recall": 0.8669403791427612,
        "bert_f1": 0.862572968006134,
        "meteor": 0.0,
        "sbert_similarity": 0.4586353898048401
      }
    },
    {
      "sample_id": 0,
      "question": "Where did Caroline move from 4 years ago?",
      "prediction": "Mel's family",
      "reference": "Sweden",
      "category": 1,
      "strategy": "multi_hop",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8488978743553162,
        "bert_recall": 0.8211183547973633,
        "bert_f1": 0.8347770571708679,
        "meteor": 0.0,
        "sbert_similarity": 0.07012705504894257
      }
    },
    {
      "sample_id": 0,
      "question": "How long ago was Caroline's 18th birthday?",
      "prediction": "Ten years ago",
      "reference": "10 years ago",
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.5,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.6666666666666666,
        "bleu2": 0.5773502691896257,
        "bleu3": 0.3254992452916931,
        "bleu4": 0.24028114141347542,
        "bert_precision": 0.9494137763977051,
        "bert_recall": 0.9494137763977051,
        "bert_f1": 0.9494137763977051,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 0.9706802368164062
      }
    },
    {
      "sample_id": 0,
      "question": "What career path has Caroline decided to persue?",
      "prediction": "counseling or mental health",
      "reference": "counseling or mental health for Transgender people",
      "category": 1,
      "strategy": "multi_hop",
      "metrics": {
        "exact_match": 0,
        "f1": 0.7272727272727273,
        "rouge1_f": 0.7272727272727273,
        "rouge2_f": 0.6666666666666666,
        "rougeL_f": 0.7272727272727273,
        "bleu1": 0.4723665527410147,
        "bleu2": 0.4723665527410147,
        "bleu3": 0.4723665527410147,
        "bleu4": 0.4723665527410147,
        "bert_precision": 0.9656624794006348,
        "bert_recall": 0.9319413304328918,
        "bert_f1": 0.9485023021697998,
        "meteor": 0.5923507462686567,
        "sbert_similarity": 0.676784873008728
      }
    },
    {
      "sample_id": 0,
      "question": "Would Caroline still want to pursue counseling as a career if she hadn't received support growing up?",
      "prediction": "No, Caroline would not have pursued counseling as a career if she hadn't received support growing up.",
      "reference": "Likely no",
      "category": 3,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.10526315789473684,
        "rouge1_f": 0.09999999999999999,
        "rouge2_f": 0.0,
        "rougeL_f": 0.09999999999999999,
        "bleu1": 0.05000000000000001,
        "bleu2": 0.01622214211307625,
        "bleu3": 0.01186947435439869,
        "bleu4": 0.009629943614188135,
        "bert_precision": 0.816582202911377,
        "bert_recall": 0.8550455570220947,
        "bert_f1": 0.8353713750839233,
        "meteor": 0.0,
        "sbert_similarity": 0.13169097900390625
      }
    },
    {
      "sample_id": 0,
      "question": "What activities does Melanie partake in?",
      "prediction": "Melaniesays she enjoys hiking in the mountains and exploring forests, as well as playing at a park.",
      "reference": "pottery, camping, painting, swimming",
      "category": 1,
      "strategy": "multi_hop",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0.05263157894736841,
        "bleu2": 0.017099639201419235,
        "bleu3": 0.012523428510015045,
        "bleu4": 0.010182425646195498,
        "bert_precision": 0.834284782409668,
        "bert_recall": 0.8490889072418213,
        "bert_f1": 0.8416217565536499,
        "meteor": 0.0,
        "sbert_similarity": 0.24212904274463654
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie sign up for a pottery class?",
      "prediction": "15 July, 2023",
      "reference": "2 July 2023",
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.5,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.5,
        "bleu2": 0.12909944487358058,
        "bleu3": 0.09635409769034631,
        "bleu4": 0.09554427922043669,
        "bert_precision": 0.9506465196609497,
        "bert_recall": 0.9730132818222046,
        "bert_f1": 0.9616998434066772,
        "meteor": 0.16666666666666666,
        "sbert_similarity": 0.9005128741264343
      }
    },
    {
      "sample_id": 0,
      "question": "When is Caroline going to the transgender conference?",
      "prediction": "2 days ago",
      "reference": "July 2023",
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7705049514770508,
        "bert_recall": 0.8161751627922058,
        "bert_f1": 0.7926827669143677,
        "meteor": 0.0,
        "sbert_similarity": 0.33337628841400146
      }
    },
    {
      "sample_id": 0,
      "question": "Where has Melanie camped?",
      "prediction": "Melanie has camped in the forest near her home",
      "reference": "beach, mountains, forest",
      "category": 1,
      "strategy": "multi_hop",
      "metrics": {
        "exact_match": 0,
        "f1": 0.16666666666666666,
        "rouge1_f": 0.16666666666666666,
        "rouge2_f": 0.0,
        "rougeL_f": 0.16666666666666666,
        "bleu1": 0.11111111111111109,
        "bleu2": 0.03726779962499649,
        "bleu3": 0.028067124621919234,
        "bleu4": 0.023980296761827107,
        "bert_precision": 0.8618929386138916,
        "bert_recall": 0.8767486214637756,
        "bert_f1": 0.8692573308944702,
        "meteor": 0.13888888888888892,
        "sbert_similarity": 0.30194568634033203
      }
    },
    {
      "sample_id": 0,
      "question": "What do Melanie's kids like?",
      "prediction": "Melanie's kids love nature.",
      "reference": "dinosaurs, nature",
      "category": 1,
      "strategy": "multi_hop",
      "metrics": {
        "exact_match": 0,
        "f1": 0.3333333333333333,
        "rouge1_f": 0.28571428571428575,
        "rouge2_f": 0.0,
        "rougeL_f": 0.28571428571428575,
        "bleu1": 0.16666666666666669,
        "bleu2": 0.05773502691896258,
        "bleu3": 0.04506819749679463,
        "bleu4": 0.040824829046386304,
        "bert_precision": 0.8687915802001953,
        "bert_recall": 0.8564651012420654,
        "bert_f1": 0.8625842928886414,
        "meteor": 0.0,
        "sbert_similarity": 0.32282188534736633
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie go to the museum?",
      "prediction": "15 July 2023",
      "reference": "5 July 2023",
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.5,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.6666666666666666,
        "bleu2": 0.5773502691896257,
        "bleu3": 0.3254992452916931,
        "bleu4": 0.24028114141347542,
        "bert_precision": 0.9813332557678223,
        "bert_recall": 0.9813332557678223,
        "bert_f1": 0.9813332557678223,
        "meteor": 0.625,
        "sbert_similarity": 0.9378072023391724
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline have a picnic?",
      "prediction": "27 June 2023",
      "reference": "The week before 6 July 2023",
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.2222222222222222,
        "rouge1_f": 0.2222222222222222,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2222222222222222,
        "bleu1": 0.12262648039048077,
        "bleu2": 0.04749303163563625,
        "bleu3": 0.044556965439969995,
        "bleu4": 0.0417991745584234,
        "bert_precision": 0.9310631155967712,
        "bert_recall": 0.8989740610122681,
        "bert_f1": 0.9147372245788574,
        "meteor": 0.08771929824561403,
        "sbert_similarity": 0.804999828338623
      }
    },
    {
      "sample_id": 0,
      "question": "Would Caroline likely have Dr. Seuss books on her bookshelf?",
      "prediction": "Yes, given that Caroline mentions classics and stories from different cultures in her library.",
      "reference": "Yes, since she collects classic children's books",
      "category": 3,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.09523809523809523,
        "rouge1_f": 0.18181818181818182,
        "rouge2_f": 0.0,
        "rougeL_f": 0.18181818181818182,
        "bleu1": 0.12500000000000003,
        "bleu2": 0.09128709291752769,
        "bleu3": 0.04033183084278514,
        "bleu4": 0.026012784404037925,
        "bert_precision": 0.8974241018295288,
        "bert_recall": 0.9257596731185913,
        "bert_f1": 0.9113717079162598,
        "meteor": 0.12987012987012989,
        "sbert_similarity": 0.6458326578140259
      }
    },
    {
      "sample_id": 0,
      "question": "What books has Melanie read?",
      "prediction": "Melanie reads that book you recommended a while ago.",
      "reference": "\"Nothing is Impossible\", \"Charlotte's Web\"",
      "category": 1,
      "strategy": "multi_hop",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8598034977912903,
        "bert_recall": 0.8445367813110352,
        "bert_f1": 0.8521018028259277,
        "meteor": 0.0,
        "sbert_similarity": 0.18820880353450775
      }
    },
    {
      "sample_id": 0,
      "question": "What does Melanie do to destress?",
      "prediction": "Melaniesays she is carving out me-time each day by running, reading, or playing her violin.",
      "reference": "Running, pottery",
      "category": 1,
      "strategy": "multi_hop",
      "metrics": {
        "exact_match": 0,
        "f1": 0.11764705882352941,
        "rouge1_f": 0.1111111111111111,
        "rouge2_f": 0.0,
        "rougeL_f": 0.1111111111111111,
        "bleu1": 0.11111111111111109,
        "bleu2": 0.08084520834544433,
        "bleu3": 0.035619862080836485,
        "bleu4": 0.02284411468856457,
        "bert_precision": 0.8182244300842285,
        "bert_recall": 0.8464357256889343,
        "bert_f1": 0.8320909738540649,
        "meteor": 0.15151515151515152,
        "sbert_similarity": 0.28430643677711487
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline go to the LGBTQ conference?",
      "prediction": "2 days ago",
      "reference": "10 July 2023",
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7725777626037598,
        "bert_recall": 0.8062412738800049,
        "bert_f1": 0.7890506386756897,
        "meteor": 0.0,
        "sbert_similarity": 0.3253958821296692
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie read the book \"nothing is impossible\"?",
      "prediction": "2023",
      "reference": 2022,
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.9776392579078674,
        "bert_recall": 0.9776392579078674,
        "bert_f1": 0.9776392579078674,
        "meteor": 0.0,
        "sbert_similarity": 0.9072221517562866
      }
    },
    {
      "sample_id": 0,
      "question": "Would Caroline pursue writing as a career option?",
      "prediction": "No",
      "reference": "LIkely no; though she likes reading, she wants to be a counselor",
      "category": 3,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.15384615384615385,
        "rouge2_f": 0.0,
        "rougeL_f": 0.15384615384615385,
        "bleu1": 2.2603294069810542e-06,
        "bleu2": 7.14778918831783e-07,
        "bleu3": 4.945061934077801e-07,
        "bleu4": 4.0194972443398975e-07,
        "bert_precision": 0.8570750951766968,
        "bert_recall": 0.8017058968544006,
        "bert_f1": 0.8284663558006287,
        "meteor": 0.0,
        "sbert_similarity": 0.1082494780421257
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline go to the adoption meeting?",
      "prediction": "8 May 2023",
      "reference": "The friday before 15 July 2023",
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.2222222222222222,
        "rouge1_f": 0.2222222222222222,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2222222222222222,
        "bleu1": 0.12262648039048077,
        "bleu2": 0.04749303163563625,
        "bleu3": 0.044556965439969995,
        "bleu4": 0.0417991745584234,
        "bert_precision": 0.929634690284729,
        "bert_recall": 0.8632327318191528,
        "bert_f1": 0.8952040076255798,
        "meteor": 0.08771929824561403,
        "sbert_similarity": 0.7700949311256409
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie go to the pottery workshop?",
      "prediction": "Yesterday",
      "reference": "The Friday before 15 July 2023",
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8690820336341858,
        "bert_recall": 0.8011569976806641,
        "bert_f1": 0.833738386631012,
        "meteor": 0.0,
        "sbert_similarity": 0.45421934127807617
      }
    },
    {
      "sample_id": 0,
      "question": "Would Melanie be considered a member of the LGBTQ community?",
      "prediction": "No",
      "reference": "Likely no, she does not refer to herself as part of it",
      "category": 3,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.15384615384615385,
        "rouge1_f": 0.15384615384615385,
        "rouge2_f": 0.0,
        "rougeL_f": 0.15384615384615385,
        "bleu1": 6.14421235332821e-06,
        "bleu2": 1.9429705464260385e-06,
        "bleu3": 1.3442071996008229e-06,
        "bleu4": 1.0926126318830351e-06,
        "bert_precision": 0.8528546094894409,
        "bert_recall": 0.8152381181716919,
        "bert_f1": 0.8336222171783447,
        "meteor": 0.0,
        "sbert_similarity": 0.17811238765716553
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie go camping in June?",
      "prediction": "27 Jun 2023",
      "reference": "The week before 27 June 2023",
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.4444444444444444,
        "rouge1_f": 0.4444444444444444,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4444444444444444,
        "bleu1": 0.24525296078096154,
        "bleu2": 0.06716528945733123,
        "bleu3": 0.05600870148614917,
        "bleu4": 0.04970787578611783,
        "bert_precision": 0.9422374963760376,
        "bert_recall": 0.9041226506233215,
        "bert_f1": 0.9227866530418396,
        "meteor": 0.17543859649122806,
        "sbert_similarity": 0.7460024356842041
      }
    },
    {
      "sample_id": 0,
      "question": "What LGBTQ+ events has Caroline participated in?",
      "prediction": "Caroline has participated in various LGBTQ+ events including her school event, an LGBTQ conference, and a transgender conference.",
      "reference": "Pride parade, school speech, support group",
      "category": 1,
      "strategy": "multi_hop",
      "metrics": {
        "exact_match": 0,
        "f1": 0.08695652173913045,
        "rouge1_f": 0.08333333333333333,
        "rouge2_f": 0.0,
        "rougeL_f": 0.08333333333333333,
        "bleu1": 0.14285714285714285,
        "bleu2": 0.026726124191242442,
        "bleu3": 0.016210225632977325,
        "bleu4": 0.012021577610863726,
        "bert_precision": 0.854860782623291,
        "bert_recall": 0.865573525428772,
        "bert_f1": 0.860183835029602,
        "meteor": 0.06944444444444446,
        "sbert_similarity": 0.38098108768463135
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline go to a pride parade during the summer?",
      "prediction": "3 July",
      "reference": "The week before 3 July 2023",
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.5,
        "rouge1_f": 0.5,
        "rouge2_f": 0.33333333333333337,
        "rougeL_f": 0.5,
        "bleu1": 0.1353352832366127,
        "bleu2": 0.1353352832366127,
        "bleu3": 0.06330106782582003,
        "bleu4": 0.04279677428117006,
        "bert_precision": 0.9019911289215088,
        "bert_recall": 0.8574107885360718,
        "bert_f1": 0.8791362047195435,
        "meteor": 0.33482142857142855,
        "sbert_similarity": 0.6684080362319946
      }
    },
    {
      "sample_id": 0,
      "question": "What events has Caroline participated in to help children?",
      "prediction": "Caroline's participation includes running a charity race and attending advocacy events.",
      "reference": "Mentoring program, school speech",
      "category": 1,
      "strategy": "multi_hop",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8694913387298584,
        "bert_recall": 0.8547799587249756,
        "bert_f1": 0.8620728850364685,
        "meteor": 0.0,
        "sbert_similarity": 0.23696088790893555
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie go camping in July?",
      "prediction": "July 15th, 2023",
      "reference": "two weekends before 17 July 2023",
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.4444444444444444,
        "rouge1_f": 0.4444444444444444,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4444444444444444,
        "bleu1": 0.3032653298563167,
        "bleu2": 0.07830277146770757,
        "bleu3": 0.05844171443814127,
        "bleu4": 0.05795053470733952,
        "bert_precision": 0.9135595560073853,
        "bert_recall": 0.8749165534973145,
        "bert_f1": 0.893820583820343,
        "meteor": 0.17543859649122806,
        "sbert_similarity": 0.6287984848022461
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline join a mentorship program?",
      "prediction": "7:55 pm on 9 June, 2023",
      "reference": "The weekend before 17 July 2023",
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.16666666666666666,
        "rouge1_f": 0.15384615384615383,
        "rouge2_f": 0.0,
        "rougeL_f": 0.15384615384615383,
        "bleu1": 0.14285714285714285,
        "bleu2": 0.048795003647426664,
        "bleu3": 0.037468614372419724,
        "bleu4": 0.033031643180138064,
        "bert_precision": 0.8869984149932861,
        "bert_recall": 0.8974564671516418,
        "bert_f1": 0.892196774482727,
        "meteor": 0.08333333333333333,
        "sbert_similarity": 0.6964206695556641
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie paint recently?",
      "prediction": "A painting of a sunflower on a canvas",
      "reference": "sunset",
      "category": 1,
      "strategy": "multi_hop",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8411660194396973,
        "bert_recall": 0.8563950657844543,
        "bert_f1": 0.8487122654914856,
        "meteor": 0.0,
        "sbert_similarity": 0.2863440215587616
      }
    },
    {
      "sample_id": 0,
      "question": "What activities has Melanie done with her family?",
      "prediction": "Melanie has gone camping at the beach and volunteered at a youth center.",
      "reference": "Pottery, painting, camping, museum, swimming, hiking",
      "category": 1,
      "strategy": "multi_hop",
      "metrics": {
        "exact_match": 0,
        "f1": 0.1111111111111111,
        "rouge1_f": 0.10526315789473684,
        "rouge2_f": 0.0,
        "rougeL_f": 0.10526315789473684,
        "bleu1": 0.07142857142857141,
        "bleu2": 0.023440361546924773,
        "bleu3": 0.017300021018422027,
        "bleu4": 0.01428363257865929,
        "bert_precision": 0.8608473539352417,
        "bert_recall": 0.8327680826187134,
        "bert_f1": 0.8465749621391296,
        "meteor": 0.0,
        "sbert_similarity": 0.3167785704135895
      }
    },
    {
      "sample_id": 0,
      "question": "In what ways is Caroline participating in the LGBTQ community?",
      "prediction": "Caroline attends LGBTQ support groups and participates in LGBTQ events, promoting understanding and acceptance.",
      "reference": "Joining activist group, going to pride parades, participating in an art show, mentoring program",
      "category": 1,
      "strategy": "multi_hop",
      "metrics": {
        "exact_match": 0,
        "f1": 0.07692307692307691,
        "rouge1_f": 0.21428571428571427,
        "rouge2_f": 0.07692307692307693,
        "rougeL_f": 0.21428571428571427,
        "bleu1": 0.1174266328516845,
        "bleu2": 0.027118519234780553,
        "bleu3": 0.017721665377947404,
        "bleu4": 0.013741794079912908,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.13392857142857142,
        "sbert_similarity": 0.44331541657447815
      }
    },
    {
      "sample_id": 0,
      "question": "How many times has Melanie gone to the beach in 2023?",
      "prediction": "Once",
      "reference": 2,
      "category": 1,
      "strategy": "multi_hop",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.4686262011528015
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline join a new activist group?",
      "prediction": "12 July, 2023",
      "reference": "The Tuesday before 20 July 2023",
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.4444444444444444,
        "rouge1_f": 0.4444444444444444,
        "rouge2_f": 0.28571428571428575,
        "rougeL_f": 0.4444444444444444,
        "bleu1": 0.3032653298563167,
        "bleu2": 0.07830277146770757,
        "bleu3": 0.05844171443814127,
        "bleu4": 0.05795053470733952,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.08771929824561403,
        "sbert_similarity": 0.7995254993438721
      }
    },
    {
      "sample_id": 0,
      "question": "Would Melanie be more interested in going to a national park or a theme park?",
      "prediction": "Melaniesays: 'That sounds great, Caroline! It's awesome having stuff around that make us think of good connections and times.'",
      "reference": "National park; she likes the outdoors",
      "category": 3,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.16200131177902222
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of art does Caroline make?",
      "prediction": "pottery",
      "reference": "abstract art",
      "category": 1,
      "strategy": "multi_hop",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.41050368547439575
      }
    },
    {
      "sample_id": 0,
      "question": "When is Melanie's daughter's birthday?",
      "prediction": "8 May 2023",
      "reference": "13 August",
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.5455352067947388
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline attend a pride parade in August?",
      "prediction": "8 May 2023",
      "reference": "The Friday before 14 August 2023",
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.2222222222222222,
        "rouge1_f": 0.2222222222222222,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2222222222222222,
        "bleu1": 0.12262648039048077,
        "bleu2": 0.04749303163563625,
        "bleu3": 0.044556965439969995,
        "bleu4": 0.0417991745584234,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.08771929824561403,
        "sbert_similarity": 0.7999818325042725
      }
    },
    {
      "sample_id": 0,
      "question": "Would Melanie be considered an ally to the transgender community?",
      "prediction": "Yes",
      "reference": "Yes, she is supportive",
      "category": 3,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.4,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4,
        "bleu1": 0.01831563888873418,
        "bleu2": 0.00579191356895553,
        "bleu3": 0.004007025187889067,
        "bleu4": 0.003257032351754417,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.28309470415115356
      }
    },
    {
      "sample_id": 0,
      "question": "Who supports Caroline when she has a negative experience?",
      "prediction": "The love and encouragement from her support system.",
      "reference": "Her mentors, family, and friends",
      "category": 1,
      "strategy": "multi_hop",
      "metrics": {
        "exact_match": 0,
        "f1": 0.3076923076923077,
        "rouge1_f": 0.3076923076923077,
        "rouge2_f": 0.0,
        "rougeL_f": 0.15384615384615385,
        "bleu1": 0.2222222222222222,
        "bleu2": 0.05270462766947299,
        "bleu3": 0.03528075103412339,
        "bleu4": 0.028517539529041507,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.18867924528301888,
        "sbert_similarity": 0.6054939031600952
      }
    },
    {
      "sample_id": 0,
      "question": "What types of pottery have Melanie and her kids made?",
      "prediction": "Their own pots",
      "reference": "bowls, cup",
      "category": 1,
      "strategy": "multi_hop",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.3862660527229309
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline and Melanie go to a pride fesetival together?",
      "prediction": "15 July 2023",
      "reference": 2022,
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.6823171377182007
      }
    },
    {
      "sample_id": 0,
      "question": "What would Caroline's political leaning likely be?",
      "prediction": "Caroline seems to lean towards the LGBTQ+ activism and mental health community.",
      "reference": "Liberal",
      "category": 3,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.2519932985305786
      }
    },
    {
      "sample_id": 0,
      "question": "What has Melanie painted?",
      "prediction": "Melaniesays that she painted a sunset last year",
      "reference": "Horse, sunset, sunrise",
      "category": 1,
      "strategy": "multi_hop",
      "metrics": {
        "exact_match": 0,
        "f1": 0.18181818181818182,
        "rouge1_f": 0.18181818181818182,
        "rouge2_f": 0.0,
        "rougeL_f": 0.18181818181818182,
        "bleu1": 0.12500000000000003,
        "bleu2": 0.04225771273642583,
        "bleu3": 0.032085442892067474,
        "bleu4": 0.02777619034011792,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.4692418873310089
      }
    },
    {
      "sample_id": 0,
      "question": "What are Melanie's pets' names?",
      "prediction": "Pup and kitty",
      "reference": "Oliver, Luna, Bailey",
      "category": 1,
      "strategy": "multi_hop",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.41748642921447754
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline apply to adoption agencies?",
      "prediction": "25 May 2023",
      "reference": "The week of 23 August 2023",
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.2222222222222222,
        "rouge1_f": 0.2222222222222222,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2222222222222222,
        "bleu1": 0.12262648039048077,
        "bleu2": 0.04749303163563625,
        "bleu3": 0.044556965439969995,
        "bleu4": 0.0417991745584234,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.08771929824561403,
        "sbert_similarity": 0.7327752709388733
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline draw a self-portrait?",
      "prediction": "24th August, 2023",
      "reference": "The week before 23 August 2023",
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.4444444444444444,
        "rouge1_f": 0.4444444444444444,
        "rouge2_f": 0.28571428571428575,
        "rougeL_f": 0.4444444444444444,
        "bleu1": 0.3032653298563167,
        "bleu2": 0.07830277146770757,
        "bleu3": 0.05844171443814127,
        "bleu4": 0.05795053470733952,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.08771929824561403,
        "sbert_similarity": 0.8358819484710693
      }
    },
    {
      "sample_id": 0,
      "question": "What subject have Caroline and Melanie both painted?",
      "prediction": "pottery",
      "reference": "Sunsets",
      "category": 1,
      "strategy": "multi_hop",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.2341538965702057
      }
    },
    {
      "sample_id": 0,
      "question": "What symbols are important to Caroline?",
      "prediction": "rainbow design on sidewalk and sunflowers/rose bouquet",
      "reference": "Rainbow flag, transgender symbol",
      "category": 1,
      "strategy": "multi_hop",
      "metrics": {
        "exact_match": 0,
        "f1": 0.18181818181818182,
        "rouge1_f": 0.16666666666666666,
        "rouge2_f": 0.0,
        "rougeL_f": 0.16666666666666666,
        "bleu1": 0.14285714285714285,
        "bleu2": 0.048795003647426664,
        "bleu3": 0.037468614372419724,
        "bleu4": 0.033031643180138064,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.11627906976744187,
        "sbert_similarity": 0.4008660912513733
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline encounter people on a hike and have a negative experience?",
      "prediction": "25 May 2023",
      "reference": "The week before 25 August 2023",
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.4444444444444444,
        "rouge1_f": 0.4444444444444444,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4444444444444444,
        "bleu1": 0.24525296078096154,
        "bleu2": 0.06716528945733123,
        "bleu3": 0.05600870148614917,
        "bleu4": 0.04970787578611783,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.17543859649122806,
        "sbert_similarity": 0.7951105833053589
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie make a plate in pottery class?",
      "prediction": "15 July 2023",
      "reference": "24 August 2023",
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.3333333333333333,
        "rouge1_f": 0.3333333333333333,
        "rouge2_f": 0.0,
        "rougeL_f": 0.3333333333333333,
        "bleu1": 0.3333333333333333,
        "bleu2": 0.12909944487358058,
        "bleu3": 0.12111838948674812,
        "bleu4": 0.11362193664674995,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.16666666666666666,
        "sbert_similarity": 0.8711563348770142
      }
    },
    {
      "sample_id": 0,
      "question": "Would Caroline be considered religious?",
      "prediction": "No",
      "reference": "Somewhat, but not extremely religious",
      "category": 3,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.2169199436903
      }
    },
    {
      "sample_id": 0,
      "question": "What instruments does Melanie play?",
      "prediction": "clarinet",
      "reference": "clarinet and violin",
      "category": 1,
      "strategy": "multi_hop",
      "metrics": {
        "exact_match": 0,
        "f1": 0.5,
        "rouge1_f": 0.5,
        "rouge2_f": 0.0,
        "rougeL_f": 0.5,
        "bleu1": 0.1353352832366127,
        "bleu2": 0.04279677428117006,
        "bleu3": 0.02960813390314045,
        "bleu4": 0.024066394763145416,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.17857142857142855,
        "sbert_similarity": 0.8449620604515076
      }
    },
    {
      "sample_id": 0,
      "question": "What musical artists/bands has Melanie seen?",
      "prediction": "Ed Sheeran",
      "reference": "Summer Sounds, Matt Patterson",
      "category": 1,
      "strategy": "multi_hop",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.20115764439105988
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie go to the park?",
      "prediction": "20 July 2023",
      "reference": "27 August 2023",
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.3333333333333333,
        "rouge1_f": 0.3333333333333333,
        "rouge2_f": 0.0,
        "rougeL_f": 0.3333333333333333,
        "bleu1": 0.3333333333333333,
        "bleu2": 0.12909944487358058,
        "bleu3": 0.12111838948674812,
        "bleu4": 0.11362193664674995,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.16666666666666666,
        "sbert_similarity": 0.8446174263954163
      }
    },
    {
      "sample_id": 0,
      "question": "When is Caroline's youth center putting on a talent show?",
      "prediction": "8 May",
      "reference": "September 2023",
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.4385889172554016
      }
    },
    {
      "sample_id": 0,
      "question": "Would Melanie likely enjoy the song \"The Four Seasons\" by Vivaldi?",
      "prediction": "Melanie would likely enjoy the song 'The Four Seasons' by Vivaldi.",
      "reference": "Yes; it's classical music",
      "category": 3,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.3087749183177948
      }
    },
    {
      "sample_id": 0,
      "question": "What are some changes Caroline has faced during her transition journey?",
      "prediction": "Carolineshasfacedtoughtimesandempathy",
      "reference": "Changes to her body, losing unsupportive friends",
      "category": 1,
      "strategy": "multi_hop",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.26873040199279785
      }
    },
    {
      "sample_id": 0,
      "question": "What does Melanie do with her family on hikes?",
      "prediction": "Melanie hikes with her family",
      "reference": "Roast marshmallows, tell stories",
      "category": 1,
      "strategy": "multi_hop",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.1657494604587555
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline go biking with friends?",
      "prediction": "12 July, 2023",
      "reference": "The weekend before 13 September 2023",
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.2222222222222222,
        "rouge1_f": 0.2222222222222222,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2222222222222222,
        "bleu1": 0.15163266492815836,
        "bleu2": 0.05536842069051654,
        "bleu3": 0.04649251600872798,
        "bleu4": 0.04873039689743777,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.08771929824561403,
        "sbert_similarity": 0.7228514552116394
      }
    },
    {
      "sample_id": 0,
      "question": "How long has Melanie been practicing art?",
      "prediction": "Since painting",
      "reference": "Since 2016",
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.5,
        "rouge1_f": 0.5,
        "rouge2_f": 0.0,
        "rougeL_f": 0.5,
        "bleu1": 0.5,
        "bleu2": 0.223606797749979,
        "bleu3": 0.1740444189610778,
        "bleu4": 0.1495348781221221,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.25,
        "sbert_similarity": 0.604637861251831
      }
    },
    {
      "sample_id": 0,
      "question": "What personality traits might Melanie say Caroline has?",
      "prediction": "Caroline is kind and supportive.",
      "reference": "Thoughtful, authentic, driven",
      "category": 3,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.2471514791250229
      }
    },
    {
      "sample_id": 0,
      "question": "What transgender-specific events has Caroline attended?",
      "prediction": "Carolinesays she went to a transgender conference two days ago and had an LGBTQ+ counseling workshop last Friday.",
      "reference": "Poetry reading, conference",
      "category": 1,
      "strategy": "multi_hop",
      "metrics": {
        "exact_match": 0,
        "f1": 0.09523809523809525,
        "rouge1_f": 0.09523809523809525,
        "rouge2_f": 0.0,
        "rougeL_f": 0.09523809523809525,
        "bleu1": 0.05263157894736841,
        "bleu2": 0.017099639201419235,
        "bleu3": 0.012523428510015045,
        "bleu4": 0.010182425646195498,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.11111111111111113,
        "sbert_similarity": 0.2925141453742981
      }
    },
    {
      "sample_id": 0,
      "question": "What book did Melanie read from Caroline's suggestion?",
      "prediction": "The Power",
      "reference": "\"Becoming Nicole\"",
      "category": 1,
      "strategy": "multi_hop",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.200547456741333
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie's friend adopt a child?",
      "prediction": "2023, 15 July",
      "reference": 2022,
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.6858455538749695
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie get hurt?",
      "prediction": "20 July, 2023",
      "reference": "September 2023",
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.4,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4,
        "bleu1": 0.25,
        "bleu2": 0.09128709291752769,
        "bleu3": 0.07665320007195604,
        "bleu4": 0.08034284189446518,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.2380952380952381,
        "sbert_similarity": 0.7461196184158325
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie's family go on a roadtrip?",
      "prediction": "20 July 2023",
      "reference": "The weekend before 20 October 2023",
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.4444444444444444,
        "rouge1_f": 0.4444444444444444,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4444444444444444,
        "bleu1": 0.24525296078096154,
        "bleu2": 0.06716528945733123,
        "bleu3": 0.05600870148614917,
        "bleu4": 0.04970787578611783,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.17543859649122806,
        "sbert_similarity": 0.7790975570678711
      }
    },
    {
      "sample_id": 0,
      "question": "How many children does Melanie have?",
      "prediction": "Two",
      "reference": 3,
      "category": 1,
      "strategy": "multi_hop",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.7066472172737122
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie go on a hike after the roadtrip?",
      "prediction": "Melaniesays: We enjoy hiking in the mountains and exploring forests. It's a cool way to connect with nature and each other.",
      "reference": "19 October 2023",
      "category": 1,
      "strategy": "multi_hop",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": -0.026648148894309998
      }
    },
    {
      "sample_id": 0,
      "question": "Would Melanie go on another roadtrip soon?",
      "prediction": "Melaniesays: I'm going to be off work for two weeks, so maybe you'll see me on a trip.",
      "reference": "Likely no; since this one went badly",
      "category": 3,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.1305629312992096
      }
    },
    {
      "sample_id": 0,
      "question": "What items has Melanie bought?",
      "prediction": "necklace",
      "reference": "Figurines, shoes",
      "category": 1,
      "strategy": "multi_hop",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.3392271399497986
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline pass the adoption interview?",
      "prediction": "25 May 2023",
      "reference": "The Friday before 22 October 2023",
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.2222222222222222,
        "rouge1_f": 0.2222222222222222,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2222222222222222,
        "bleu1": 0.12262648039048077,
        "bleu2": 0.04749303163563625,
        "bleu3": 0.044556965439969995,
        "bleu4": 0.0417991745584234,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.08771929824561403,
        "sbert_similarity": 0.7825596928596497
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie buy the figurines?",
      "prediction": "8 May",
      "reference": "21 October 2023",
      "category": 2,
      "strategy": "temporal",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.5965383052825928
      }
    },
    {
      "sample_id": 0,
      "question": "Would Caroline want to move back to her home country soon?",
      "prediction": "No",
      "reference": "No; she's in the process of adopting children.",
      "category": 3,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.19999999999999998,
        "rouge2_f": 0.0,
        "rougeL_f": 0.19999999999999998,
        "bleu1": 4.5399929762484854e-05,
        "bleu2": 1.435671836611194e-05,
        "bleu3": 9.93242240643695e-06,
        "bleu4": 8.07337603138401e-06,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.21591618657112122
      }
    },
    {
      "sample_id": 0,
      "question": "What did the charity race raise awareness for?",
      "prediction": "mental health",
      "reference": "mental health",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 0.46773514128719823,
        "bleu4": 0.316227766016838,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9375,
        "sbert_similarity": 0.9999999403953552
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie realize after the charity race?",
      "prediction": "Melanie realized that running the charity race had made her think more about taking care of her mind.",
      "reference": "self-care is important",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0909090909090909,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0909090909090909,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.2780553698539734
      }
    },
    {
      "sample_id": 0,
      "question": "How does Melanie prioritize self-care?",
      "prediction": "Melanie prioritizes self-care by taking time to do activities that refresh her and help her stay present for her family.",
      "reference": "by carving out some me-time each day for activities like running, reading, or playing the violin",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.17647058823529413,
        "rouge1_f": 0.21052631578947367,
        "rouge2_f": 0.0,
        "rougeL_f": 0.15789473684210528,
        "bleu1": 0.14285714285714285,
        "bleu2": 0.026726124191242442,
        "bleu3": 0.016210225632977325,
        "bleu4": 0.012021577610863726,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.09146341463414634,
        "sbert_similarity": 0.29249224066734314
      }
    },
    {
      "sample_id": 0,
      "question": "What are Caroline's plans for the summer?",
      "prediction": "Planning to go camping next month with their kids.",
      "reference": "researching adoption agencies",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.15573526918888092
      }
    },
    {
      "sample_id": 0,
      "question": "What type of individuals does the adoption agency Caroline is considering support?",
      "prediction": "LGBTQ+",
      "reference": "LGBTQ+ individuals",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.0,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.36787944117144233,
        "bleu2": 0.11633369384516798,
        "bleu3": 0.08048325236348887,
        "bleu4": 0.06541924356118012,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.2631578947368421,
        "sbert_similarity": 0.8889155387878418
      }
    },
    {
      "sample_id": 0,
      "question": "Why did Caroline choose the adoption agency?",
      "prediction": "Caroline applied to adoption agencies as she took the first step towards becoming a mom.",
      "reference": "because of their inclusivity and support for LGBTQ+ individuals",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.1001034677028656
      }
    },
    {
      "sample_id": 0,
      "question": "What is Caroline excited about in the adoption process?",
      "prediction": "Caroline is excited about applying to adoption agencies.",
      "reference": "creating a family for kids who need one",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.2937573790550232
      }
    },
    {
      "sample_id": 0,
      "question": "What does Melanie think about Caroline's decision to adopt?",
      "prediction": "Melanie thinks it is awesome.",
      "reference": "she thinks Caroline is doing something amazing and will be an awesome mom",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.33333333333333337,
        "rouge1_f": 0.33333333333333337,
        "rouge2_f": 0.0,
        "rougeL_f": 0.33333333333333337,
        "bleu1": 0.15570161195729887,
        "bleu2": 0.03114032239145978,
        "bleu3": 0.020167093291227033,
        "bleu4": 0.01673122705457702,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.08196721311475409,
        "sbert_similarity": 0.314594566822052
      }
    },
    {
      "sample_id": 0,
      "question": "How long have Mel and her husband been married?",
      "prediction": "5 years",
      "reference": "Mel and her husband have been married for 5 years.",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.33333333333333337,
        "rouge1_f": 0.33333333333333337,
        "rouge2_f": 0.19999999999999998,
        "rougeL_f": 0.33333333333333337,
        "bleu1": 0.011108996538242306,
        "bleu2": 0.011108996538242306,
        "bleu3": 0.005196068065373761,
        "bleu4": 0.0035129731579771513,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.05434782608695652,
        "sbert_similarity": 0.3471320867538452
      }
    },
    {
      "sample_id": 0,
      "question": "What does Caroline's necklace symbolize?",
      "prediction": "Caroline's necklace symbolizes love, faith and strength.",
      "reference": "love, faith, and strength",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.7272727272727273,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.6,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.5,
        "bleu2": 0.408248290463863,
        "bleu3": 0.27873428524501964,
        "bleu4": 0.13134549472120793,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.23255813953488375,
        "sbert_similarity": 0.4486634433269501
      }
    },
    {
      "sample_id": 0,
      "question": "What country is Caroline's grandma from?",
      "prediction": "United States",
      "reference": "Sweden",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.51800537109375
      }
    },
    {
      "sample_id": 0,
      "question": "What was grandma's gift to Caroline?",
      "prediction": "necklace",
      "reference": "necklace",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 0.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 0.316227766016838,
        "bleu3": 0.2187761623949553,
        "bleu4": 0.1778279410038923,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.5,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What is Melanie's hand-painted bowl a reminder of?",
      "prediction": "art and self-expression",
      "reference": "art and self-expression",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie and her family do while camping?",
      "prediction": "roasting marshmallows around the campfire and going on hikes.",
      "reference": "explored nature, roasted marshmallows, and went on a hike",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.3333333333333333,
        "rouge1_f": 0.5555555555555556,
        "rouge2_f": 0.125,
        "rougeL_f": 0.5555555555555556,
        "bleu1": 0.27145122541078787,
        "bleu2": 0.05224081268759072,
        "bleu3": 0.032441493690587776,
        "bleu4": 0.025132936350227657,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.16666666666666666,
        "sbert_similarity": 0.7031533122062683
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of counseling and mental health services is Caroline interested in pursuing?",
      "prediction": "Counseling and mental health as a career",
      "reference": "working with trans people, helping them accept themselves and supporting their mental health",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.3,
        "rouge1_f": 0.3,
        "rouge2_f": 0.1111111111111111,
        "rougeL_f": 0.3,
        "bleu1": 0.15766261764490386,
        "bleu2": 0.09831991632152833,
        "bleu3": 0.04234705031171946,
        "bleu4": 0.028439110602897978,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.20609318996415774,
        "sbert_similarity": 0.5015943050384521
      }
    },
    {
      "sample_id": 0,
      "question": "What workshop did Caroline attend recently?",
      "prediction": "LGBTQ+ counseling workshop",
      "reference": "LGBTQ+ counseling workshop",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 1.000000238418579
      }
    },
    {
      "sample_id": 0,
      "question": "What was discussed in the LGBTQ+ counseling workshop?",
      "prediction": "Different therapeutic methods and how to best work with trans people.",
      "reference": "therapeutic methods and how to best work with trans people",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.9523809523809523,
        "rouge1_f": 0.9523809523809523,
        "rouge2_f": 0.9473684210526316,
        "rougeL_f": 0.9523809523809523,
        "bleu1": 0.8333333333333334,
        "bleu2": 0.8257228238447705,
        "bleu3": 0.8187104363805253,
        "bleu4": 0.8070557274927982,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.8904779366825571,
        "sbert_similarity": 0.9825105667114258
      }
    },
    {
      "sample_id": 0,
      "question": "What motivated Caroline to pursue counseling?",
      "prediction": "Caroline's own journey and the support she received made a huge difference.",
      "reference": "her own journey and the support she received, and how counseling improved her life",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.5833333333333334,
        "rouge1_f": 0.5185185185185186,
        "rouge2_f": 0.48000000000000004,
        "rougeL_f": 0.5185185185185186,
        "bleu1": 0.4655313898520114,
        "bleu2": 0.4472680919719132,
        "bleu3": 0.4298906145354158,
        "bleu4": 0.40261268809521783,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.40760869565217384,
        "sbert_similarity": 0.5208863019943237
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of place does Caroline want to create for people?",
      "prediction": "A loving and accepting environment",
      "reference": "a safe and inviting place for people to grow",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.2857142857142857,
        "rouge1_f": 0.2857142857142857,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2857142857142857,
        "bleu1": 0.17973158564688863,
        "bleu2": 0.04493289641172216,
        "bleu3": 0.03199737863082477,
        "bleu4": 0.028709564316081952,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.11627906976744186,
        "sbert_similarity": 0.46271559596061707
      }
    },
    {
      "sample_id": 0,
      "question": "Did Melanie make the black and white bowl in the photo?",
      "prediction": "Melaniesays: Thanks, Caroline! Yeah, I made this bowl in my class.",
      "reference": "Yes",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.08477479219436646
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of books does Caroline have in her library?",
      "prediction": "kids' books",
      "reference": "kids' books - classics, stories from different cultures, educational books",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.3636363636363636,
        "rouge1_f": 0.3636363636363636,
        "rouge2_f": 0.2222222222222222,
        "rougeL_f": 0.3636363636363636,
        "bleu1": 0.03567399334725241,
        "bleu2": 0.03567399334725241,
        "bleu3": 0.03567399334725241,
        "bleu4": 0.020060960693725614,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.10869565217391304,
        "sbert_similarity": 0.7524629831314087
      }
    },
    {
      "sample_id": 0,
      "question": "What was Melanie's favorite book from her childhood?",
      "prediction": "Charlotte's Web",
      "reference": "\"Charlotte's Web\"",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 0.513417119032592,
        "bleu2": 0.513417119032592,
        "bleu3": 0.513417119032592,
        "bleu4": 0.288715663092199,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.9549331665039062
      }
    },
    {
      "sample_id": 0,
      "question": "What book did Caroline recommend to Melanie?",
      "prediction": "That book you read last year",
      "reference": "\"Becoming Nicole\"",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.1497146189212799
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline take away from the book \"Becoming Nicole\"?",
      "prediction": "Caroline felt inspired by Amy Ellis Nutt's true story about a trans girl and her family, finding hope for their own path.",
      "reference": "Lessons on self-acceptance and finding support",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.14285714285714288,
        "rouge1_f": 0.13333333333333333,
        "rouge2_f": 0.0,
        "rougeL_f": 0.13333333333333333,
        "bleu1": 0.07999999999999999,
        "bleu2": 0.01825741858350553,
        "bleu3": 0.01183531442162675,
        "bleu4": 0.009009113474307318,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.13157894736842107,
        "sbert_similarity": 0.25431641936302185
      }
    },
    {
      "sample_id": 0,
      "question": "What are the new shoes that Melanie got used for?",
      "prediction": "to liven up the house!",
      "reference": "Running",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.2987891435623169
      }
    },
    {
      "sample_id": 0,
      "question": "What is Melanie's reason for getting into running?",
      "prediction": "Melanie got into running to de-stress and clear her mind.",
      "reference": "To de-stress and clear her mind",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.7499999999999999,
        "rouge1_f": 0.7777777777777778,
        "rouge2_f": 0.7499999999999999,
        "rougeL_f": 0.7777777777777778,
        "bleu1": 0.5454545454545454,
        "bleu2": 0.5222329678670935,
        "bleu3": 0.49839100664976926,
        "bleu4": 0.4617366309441026,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.778125,
        "sbert_similarity": 0.5565808415412903
      }
    },
    {
      "sample_id": 0,
      "question": "What does Melanie say running has been great for?",
      "prediction": "running longer since our last chat - a great way to destress and clear my mind",
      "reference": "Her mental health",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.19482433795928955
      }
    },
    {
      "sample_id": 0,
      "question": "What did Mel and her kids make during the pottery workshop?",
      "prediction": "a clay sculpture",
      "reference": "pots",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.2861097455024719
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of pot did Mel and her kids make with clay?",
      "prediction": "A bowl",
      "reference": "a cup with a dog face on it",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.22222222222222224,
        "rouge1_f": 0.2,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2,
        "bleu1": 0.024893534183931972,
        "bleu2": 0.01113272692709733,
        "bleu3": 0.008665161385860336,
        "bleu4": 0.007444903200446295,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.06756756756756756,
        "sbert_similarity": 0.4042730927467346
      }
    },
    {
      "sample_id": 0,
      "question": "What creative project do Mel and her kids do together besides pottery?",
      "prediction": "painting",
      "reference": "painting",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 0.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 0.316227766016838,
        "bleu3": 0.2187761623949553,
        "bleu4": 0.1778279410038923,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.5,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What did Mel and her kids paint in their latest project in July 2023?",
      "prediction": "a painting",
      "reference": "a sunset with a palm tree",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.28571428571428575,
        "rouge1_f": 0.25,
        "rouge2_f": 0.0,
        "rougeL_f": 0.25,
        "bleu1": 0.06766764161830635,
        "bleu2": 0.030261889307125377,
        "bleu3": 0.02355435073584915,
        "bleu4": 0.020237345084409754,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.08928571428571427,
        "sbert_similarity": 0.22985491156578064
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline see at the council meeting for adoption?",
      "prediction": "a sign with a picture of a guinea pig",
      "reference": "many people wanting to create loving homes for children in need",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.03152526170015335
      }
    },
    {
      "sample_id": 0,
      "question": "What do sunflowers represent according to Caroline?",
      "prediction": "Sunflowers symbolize happiness and optimism.",
      "reference": "warmth and happiness",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.5,
        "rouge1_f": 0.5,
        "rouge2_f": 0.0,
        "rougeL_f": 0.25,
        "bleu1": 0.3333333333333333,
        "bleu2": 0.08164965809277261,
        "bleu3": 0.05665132701906204,
        "bleu4": 0.048549177170732344,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.3125,
        "sbert_similarity": 0.42255187034606934
      }
    },
    {
      "sample_id": 0,
      "question": "Why are flowers important to Melanie?",
      "prediction": "Flowers bring joy.",
      "reference": "They remind her to appreciate the small moments and were a part of her wedding decor",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.4201415181159973
      }
    },
    {
      "sample_id": 0,
      "question": "What inspired Caroline's painting for the art show?",
      "prediction": "The colors are so vivid and the whole thing looks really unified.",
      "reference": "visiting an LGBTQ center and wanting to capture unity and strength",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.09523809523809525,
        "rouge1_f": 0.08695652173913043,
        "rouge2_f": 0.0,
        "rougeL_f": 0.08695652173913043,
        "bleu1": 0.07692307692307693,
        "bleu2": 0.025318484177091663,
        "bleu3": 0.018733084686676876,
        "bleu4": 0.01553712569276035,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.04504504504504504,
        "sbert_similarity": 0.18380454182624817
      }
    },
    {
      "sample_id": 0,
      "question": "How often does Melanie go to the beach with her kids?",
      "prediction": "Melanie goes to the beach with her kids only once or twice a year.",
      "reference": "once or twice a year",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.5263157894736842,
        "rouge1_f": 0.5263157894736842,
        "rouge2_f": 0.47058823529411764,
        "rougeL_f": 0.5263157894736842,
        "bleu1": 0.3333333333333333,
        "bleu2": 0.30860669992418377,
        "bleu3": 0.2836979771131725,
        "bleu4": 0.2460137257692754,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.6726694915254238,
        "sbert_similarity": 0.3660851716995239
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie and her family see during their camping trip last year?",
      "prediction": "roasted marshmallows around the campfire and went on a hike",
      "reference": "Perseid meteor shower",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.06012829393148422
      }
    },
    {
      "sample_id": 0,
      "question": "How did Melanie feel while watching the meteor shower?",
      "prediction": "Melaniesays: It was one of those moments where I felt tiny and in awe of the universe.",
      "reference": "in awe of the universe",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.47619047619047616,
        "rouge1_f": 0.45454545454545453,
        "rouge2_f": 0.4,
        "rougeL_f": 0.45454545454545453,
        "bleu1": 0.2631578947368421,
        "bleu2": 0.2418254167033372,
        "bleu3": 0.22106152086783704,
        "bleu4": 0.18951629567590741,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.6401209677419355,
        "sbert_similarity": 0.5111637115478516
      }
    },
    {
      "sample_id": 0,
      "question": "Whose birthday did Melanie celebrate recently?",
      "prediction": "Melanie's daughter",
      "reference": "Melanie's daughter",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9375,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "Who performed at the concert at Melanie's daughter's birthday?",
      "prediction": "Melanie",
      "reference": "Matt Patterson",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.1757493019104004
      }
    },
    {
      "sample_id": 0,
      "question": "Why did Melanie choose to use colors and patterns in her pottery project?",
      "prediction": "Melanie chose to use colors and patterns in her pottery project because those designs are cool and add a unique aesthetic that complements her creative expression.",
      "reference": "She wanted to catch the eye and make people smile.",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.11764705882352941,
        "rouge1_f": 0.1111111111111111,
        "rouge2_f": 0.0,
        "rougeL_f": 0.1111111111111111,
        "bleu1": 0.11111111111111109,
        "bleu2": 0.02067245576486808,
        "bleu3": 0.012497943706942991,
        "bleu4": 0.009186672262412125,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.08620689655172414,
        "sbert_similarity": 0.275299608707428
      }
    },
    {
      "sample_id": 0,
      "question": "What pet does Caroline have?",
      "prediction": "kitty",
      "reference": "guinea pig",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.4827117919921875
      }
    },
    {
      "sample_id": 0,
      "question": "What pets does Melanie have?",
      "prediction": "A cat and a dog",
      "reference": "Two cats and a dog",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666665,
        "rouge1_f": 0.8000000000000002,
        "rouge2_f": 0.75,
        "rougeL_f": 0.8000000000000002,
        "bleu1": 0.6,
        "bleu2": 0.5477225575051662,
        "bleu3": 0.4677351412871982,
        "bleu4": 0.26591479484724945,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.7937500000000002,
        "sbert_similarity": 0.8987439870834351
      }
    },
    {
      "sample_id": 0,
      "question": "Where did Oliver hide his bone once?",
      "prediction": "Melanies's slipper",
      "reference": "In Melanie's slipper",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.8571428571428571,
        "rouge2_f": 0.8,
        "rougeL_f": 0.8571428571428571,
        "bleu1": 0.47768754038252614,
        "bleu2": 0.41368954504257255,
        "bleu3": 0.23323040081963617,
        "bleu4": 0.17216896116316355,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.17241379310344826,
        "sbert_similarity": 0.9013059139251709
      }
    },
    {
      "sample_id": 0,
      "question": "What activity did Caroline used to do with her dad?",
      "prediction": "not mentioned",
      "reference": "Horseback riding",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.11040369421243668
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline make for a local church?",
      "prediction": "a painting",
      "reference": "a stained glass window",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.3333333333333333,
        "rouge1_f": 0.3333333333333333,
        "rouge2_f": 0.0,
        "rougeL_f": 0.3333333333333333,
        "bleu1": 0.18393972058572117,
        "bleu2": 0.082260343798398,
        "bleu3": 0.06402736358640969,
        "bleu4": 0.05501080739920602,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.13157894736842105,
        "sbert_similarity": 0.3497351408004761
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline find in her neighborhood during her walk?",
      "prediction": "Caroline found a photograph featuring three stained glass windows in a church and an image of a church clock.",
      "reference": "a rainbow sidewalk",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.10526315789473684,
        "rouge1_f": 0.09090909090909091,
        "rouge2_f": 0.0,
        "rougeL_f": 0.09090909090909091,
        "bleu1": 0.05000000000000001,
        "bleu2": 0.01622214211307625,
        "bleu3": 0.01186947435439869,
        "bleu4": 0.009629943614188135,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.10869565217391304,
        "sbert_similarity": 0.16764843463897705
      }
    },
    {
      "sample_id": 0,
      "question": "Which song motivates Caroline to be courageous?",
      "prediction": "Brave",
      "reference": "Brave by Sara Bareilles",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.4,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4,
        "bleu1": 0.049787068367863944,
        "bleu2": 0.015744053406497194,
        "bleu3": 0.010892223754416544,
        "bleu4": 0.008853531856477262,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.13513513513513511,
        "sbert_similarity": 0.5007990598678589
      }
    },
    {
      "sample_id": 0,
      "question": "Which  classical musicians does Melanie enjoy listening to?",
      "prediction": "Bach and Mozart",
      "reference": "Bach and Mozart",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "Who is Melanie a fan of in terms of modern music?",
      "prediction": "Ed Sheeran's \"Perfect\"",
      "reference": "Ed Sheeran",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.5,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.3333333333333333,
        "bleu2": 0.25819888974716115,
        "bleu3": 0.12111838948674812,
        "bleu4": 0.08633400213704504,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.2380952380952381,
        "sbert_similarity": 0.7055439949035645
      }
    },
    {
      "sample_id": 0,
      "question": "How long has Melanie been creating art?",
      "prediction": "Seven years",
      "reference": "7 years",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.5,
        "rouge1_f": 0.5,
        "rouge2_f": 0.0,
        "rougeL_f": 0.5,
        "bleu1": 0.5,
        "bleu2": 0.223606797749979,
        "bleu3": 0.1740444189610778,
        "bleu4": 0.1495348781221221,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9375,
        "sbert_similarity": 0.95577472448349
      }
    },
    {
      "sample_id": 0,
      "question": "What precautionary sign did Melanie see at the caf?",
      "prediction": "a sign posted on a door stating that someone is not being able to leave",
      "reference": "A sign stating that someone is not being able to leave",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.88,
        "rouge1_f": 0.846153846153846,
        "rouge2_f": 0.75,
        "rougeL_f": 0.846153846153846,
        "bleu1": 0.7333333333333333,
        "bleu2": 0.6866065623255951,
        "bleu3": 0.6360749521034652,
        "bleu4": 0.5968774175634496,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.955125416847905,
        "sbert_similarity": 0.8908344507217407
      }
    },
    {
      "sample_id": 0,
      "question": "What advice does Caroline give for getting started with adoption?",
      "prediction": "It's important to start by researching adoption agencies and gaining support from friends and mentors.",
      "reference": "Do research, find an adoption agency or lawyer, gather necessary documents, and prepare emotionally.",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.14285714285714285,
        "rouge1_f": 0.26666666666666666,
        "rouge2_f": 0.07142857142857144,
        "rougeL_f": 0.26666666666666666,
        "bleu1": 0.16638937832733086,
        "bleu2": 0.03131334342651994,
        "bleu3": 0.01907152519570028,
        "bleu4": 0.01427369885303147,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.22384751773049644,
        "sbert_similarity": 0.7983685731887817
      }
    },
    {
      "sample_id": 0,
      "question": "What setback did Melanie face in October 2023?",
      "prediction": "Melanie faced a setback in October 2023 when she was hit by a car while crossing the street.",
      "reference": "She got hurt and had to take a break from pottery.",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.14285714285714285,
        "rouge1_f": 0.13793103448275862,
        "rouge2_f": 0.0,
        "rougeL_f": 0.13793103448275862,
        "bleu1": 0.15789473684210523,
        "bleu2": 0.029617443887954613,
        "bleu3": 0.017995886897626243,
        "bleu4": 0.01340082578177889,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.08547008547008547,
        "sbert_similarity": 0.3251628577709198
      }
    },
    {
      "sample_id": 0,
      "question": "What does Melanie do to keep herself busy during her pottery break?",
      "prediction": "Pottery",
      "reference": "Read a book and paint.",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.298631876707077
      }
    },
    {
      "sample_id": 0,
      "question": "What painting did Melanie show to Caroline on October 13, 2023?",
      "prediction": "[Image: a photo of a painting of a sunset with a pink sky]",
      "reference": "A painting inspired by sunsets with a pink sky.",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.47058823529411764,
        "rouge1_f": 0.6363636363636364,
        "rouge2_f": 0.5,
        "rougeL_f": 0.6363636363636364,
        "bleu1": 0.375,
        "bleu2": 0.3162277660168379,
        "bleu3": 0.2461034187732914,
        "bleu4": 0.18207052811092134,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.598404255319149,
        "sbert_similarity": 0.9033913612365723
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of painting did Caroline share with Melanie on October 13, 2023?",
      "prediction": "A lake sunrise",
      "reference": "An abstract painting with blue streaks on a wall.",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.16666666666666666,
        "rouge1_f": 0.16666666666666666,
        "rouge2_f": 0.0,
        "rougeL_f": 0.16666666666666666,
        "bleu1": 0.03232398928813501,
        "bleu2": 0.012519027219593387,
        "bleu3": 0.011745088573097433,
        "bleu4": 0.011018142789200103,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.05952380952380952,
        "sbert_similarity": 0.19741468131542206
      }
    },
    {
      "sample_id": 0,
      "question": "What was the poetry reading that Caroline attended about?",
      "prediction": "The poem discussed how it connects to one's roots and family.",
      "reference": "It was a transgender poetry reading where transgender people shared their stories.",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.09090909090909091,
        "rouge1_f": 0.08333333333333333,
        "rouge2_f": 0.0,
        "rougeL_f": 0.08333333333333333,
        "bleu1": 0.15384615384615385,
        "bleu2": 0.03580574370197164,
        "bleu3": 0.023547737997202885,
        "bleu4": 0.018476860420522198,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.04201680672268908,
        "sbert_similarity": 0.42075976729393005
      }
    },
    {
      "sample_id": 0,
      "question": "What did the posters at the poetry reading say?",
      "prediction": "Those posters were amazing, so much pride and strength!",
      "reference": "\"Trans Lives Matter\"",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.13888888888888892,
        "sbert_similarity": 0.08538060635328293
      }
    },
    {
      "sample_id": 0,
      "question": "What does Caroline's drawing symbolize for her?",
      "prediction": "freedom and being real",
      "reference": "Freedom and being true to herself.",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.6,
        "rouge1_f": 0.6,
        "rouge2_f": 0.5,
        "rougeL_f": 0.6,
        "bleu1": 0.354274914555761,
        "bleu2": 0.3340135926488844,
        "bleu3": 0.2989505394514747,
        "bleu4": 0.1878296463217631,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.5076628352490421,
        "sbert_similarity": 0.6762144565582275
      }
    },
    {
      "sample_id": 0,
      "question": "How do Melanie and Caroline describe their journey through life together?",
      "prediction": "Melanie and Caroline describe their journey as creating meaningful moments, exploring nature together, cherishing family time, and providing support to each other.",
      "reference": "An ongoing adventure of learning and growing.",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.07142857142857142,
        "rouge1_f": 0.06896551724137931,
        "rouge2_f": 0.0,
        "rougeL_f": 0.06896551724137931,
        "bleu1": 0.07692307692307693,
        "bleu2": 0.017541160386140592,
        "bleu3": 0.011366029557861331,
        "bleu4": 0.008640609739997756,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.058823529411764705,
        "sbert_similarity": 0.23402152955532074
      }
    },
    {
      "sample_id": 0,
      "question": "What happened to Melanie's son on their road trip?",
      "prediction": "The accident scared Melanie but fortunately her son was okay.",
      "reference": "He got into an accident",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.13333333333333333,
        "rouge1_f": 0.13333333333333333,
        "rouge2_f": 0.0,
        "rougeL_f": 0.13333333333333333,
        "bleu1": 0.0909090909090909,
        "bleu2": 0.03015113445777637,
        "bleu3": 0.022461584318318094,
        "bleu4": 0.018850319022747353,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.09090909090909091,
        "sbert_similarity": 0.47921833395957947
      }
    },
    {
      "sample_id": 0,
      "question": "How did Melanie's son handle the accident?",
      "prediction": "Fortunately, your son was unharmed and that was a reminder that life is precious.",
      "reference": "He was scared but reassured by his family",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.1,
        "rouge1_f": 0.09090909090909091,
        "rouge2_f": 0.0,
        "rougeL_f": 0.09090909090909091,
        "bleu1": 0.0625,
        "bleu2": 0.02041241452319315,
        "bleu3": 0.015007489164383502,
        "bleu4": 0.012300686288463768,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.058139534883720936,
        "sbert_similarity": 0.37942612171173096
      }
    },
    {
      "sample_id": 0,
      "question": "How did Melanie feel about her family after the accident?",
      "prediction": "Melanie felt thankful and grateful to have her family during the difficult time.",
      "reference": "They are important and mean the world to her",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.3636363636363637,
        "rouge1_f": 0.3636363636363637,
        "rouge2_f": 0.0,
        "rougeL_f": 0.27272727272727276,
        "bleu1": 0.2857142857142857,
        "bleu2": 0.046880723093849545,
        "bleu3": 0.02733546260131627,
        "bleu4": 0.020200106912694155,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.2127659574468085,
        "sbert_similarity": 0.27938175201416016
      }
    },
    {
      "sample_id": 0,
      "question": "How did Melanie's children handle the accident?",
      "prediction": "They handled the accident bravely and remained calm.",
      "reference": "They were scared but resilient",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.15384615384615385,
        "rouge1_f": 0.15384615384615385,
        "rouge2_f": 0.0,
        "rougeL_f": 0.15384615384615385,
        "bleu1": 0.11111111111111109,
        "bleu2": 0.03726779962499649,
        "bleu3": 0.028067124621919234,
        "bleu4": 0.023980296761827107,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.09433962264150944,
        "sbert_similarity": 0.5456444621086121
      }
    },
    {
      "sample_id": 0,
      "question": "How did Melanie feel after the accident?",
      "prediction": "in awe",
      "reference": "Grateful and thankful for her family",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.2567145526409149
      }
    },
    {
      "sample_id": 0,
      "question": "What was Melanie's reaction to her children enjoying the Grand Canyon?",
      "prediction": "Melaniesays: 'Glad your son is okay, Melanie. Life's unpredictable, but moments like these remind us how important our loved ones are.",
      "reference": "She was happy and thankful",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.38328972458839417
      }
    },
    {
      "sample_id": 0,
      "question": "What do Melanie's family give her?",
      "prediction": "A rock",
      "reference": "Strength and motivation",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.11318114399909973
      }
    },
    {
      "sample_id": 0,
      "question": "How did Melanie feel about her family supporting her?",
      "prediction": "inspired",
      "reference": "She appreciated them a lot",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.2016112208366394
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie do after the road trip to relax?",
      "prediction": "Melanie took a bike ride.",
      "reference": "Went on a nature walk or hike",
      "category": 4,
      "strategy": "factual",
      "metrics": {
        "exact_match": 0,
        "f1": 0.16666666666666666,
        "rouge1_f": 0.16666666666666666,
        "rouge2_f": 0.0,
        "rougeL_f": 0.16666666666666666,
        "bleu1": 0.141080287481769,
        "bleu2": 0.04887164517296948,
        "bleu3": 0.03814940555479757,
        "bleu4": 0.03455747170954952,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.07352941176470587,
        "sbert_similarity": 0.2985152304172516
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline realize after her charity race?",
      "prediction": "self-care is important",
      "reference": "self-care is important",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 0.9999999403953552
      }
    },
    {
      "sample_id": 0,
      "question": "What are Melanie's plans for the summer with respect to adoption?",
      "prediction": "Not mentioned in the conversation",
      "reference": "researching adoption agencies",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.010256841778755188
      }
    },
    {
      "sample_id": 0,
      "question": "What type of individuals does the adoption agency Melanie is considering support?",
      "prediction": "Not mentioned in the conversation or LGBTQ+ individuals",
      "reference": "LGBTQ+ individuals",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.4,
        "rouge2_f": 0.25,
        "rougeL_f": 0.4,
        "bleu1": 0.25,
        "bleu2": 0.18898223650461357,
        "bleu3": 0.08622792534209149,
        "bleu4": 0.05873949094699214,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.7211538461538463,
        "sbert_similarity": 0.7128360271453857
      }
    },
    {
      "sample_id": 0,
      "question": "Why did Melanie choose the adoption agency?",
      "prediction": "because of their inclusivity and support for LGBTQ+ individuals",
      "reference": "because of their inclusivity and support for LGBTQ+ individuals",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9993141289437586,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "What is Melanie excited about in her adoption process?",
      "prediction": "Creating a family for kids who need one",
      "reference": "creating a family for kids who need one",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9990234375,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What does Melanie's necklace symbolize?",
      "prediction": "love, faith, and strength",
      "reference": "love, faith, and strength",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9921875,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "What country is Melanie's grandma from?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Sweden",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.12741497159004211
      }
    },
    {
      "sample_id": 0,
      "question": "What was grandma's gift to Melanie?",
      "prediction": "necklace",
      "reference": "necklace",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 0.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 0.316227766016838,
        "bleu3": 0.2187761623949553,
        "bleu4": 0.1778279410038923,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.5,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What was grandpa's gift to Caroline?",
      "prediction": "Not mentioned in the conversation or necklace",
      "reference": "necklace",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 0,
        "f1": 0.25,
        "rouge1_f": 0.25,
        "rouge2_f": 0.0,
        "rougeL_f": 0.25,
        "bleu1": 0.14285714285714285,
        "bleu2": 0.048795003647426664,
        "bleu3": 0.037468614372419724,
        "bleu4": 0.033031643180138064,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.31250000000000006,
        "sbert_similarity": 0.6756765246391296
      }
    },
    {
      "sample_id": 0,
      "question": "What is Caroline's hand-painted bowl a reminder of?",
      "prediction": "art and self-expression",
      "reference": "art and self-expression",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline and her family do while camping?",
      "prediction": "roasted marshmallows, going on a hike",
      "reference": "explored nature, roasted marshmallows, and went on a hike",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666667,
        "rouge1_f": 0.6666666666666667,
        "rouge2_f": 0.4615384615384615,
        "rougeL_f": 0.6666666666666667,
        "bleu1": 0.48404410457807934,
        "bleu2": 0.4268867747668464,
        "bleu3": 0.34698361368304864,
        "bleu4": 0.1552645155070156,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.5563218390804598,
        "sbert_similarity": 0.8256447315216064
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of counseling and mental health services is Melanie interested in pursuing?",
      "prediction": "working with mental health",
      "reference": "working with trans people, helping them accept themselves and supporting their mental health",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 0,
        "f1": 0.47058823529411764,
        "rouge1_f": 0.47058823529411764,
        "rouge2_f": 0.26666666666666666,
        "rougeL_f": 0.47058823529411764,
        "bleu1": 0.0820849986238988,
        "bleu2": 0.06702212072187047,
        "bleu3": 0.026718605101848716,
        "bleu4": 0.019723477162273965,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.30991735537190085,
        "sbert_similarity": 0.6272724270820618
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of counseling workshop did Melanie attend recently?",
      "prediction": "Not mentioned in the conversation",
      "reference": "LGBTQ+ counseling workshop",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.11074957251548767
      }
    },
    {
      "sample_id": 0,
      "question": "What motivated Melanie to pursue counseling?",
      "prediction": "her own journey and the support she received, and how counseling improved her life",
      "reference": "her own journey and the support she received, and how counseling improved her life",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9998177842565598,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of place does Melanie want to create for people?",
      "prediction": "Not mentioned in the conversation",
      "reference": "a safe and inviting place for people to grow",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.10203893482685089
      }
    },
    {
      "sample_id": 0,
      "question": "Did Caroline make the black and white bowl in the photo?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Yes",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.1172415167093277
      }
    },
    {
      "sample_id": 0,
      "question": "What are the new shoes that Caroline got used for?",
      "prediction": "Running",
      "reference": "Running",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 0.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 0.316227766016838,
        "bleu3": 0.2187761623949553,
        "bleu4": 0.1778279410038923,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.5,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What is Caroline's reason for getting into running?",
      "prediction": "To de-stress and clear her mind",
      "reference": "To de-stress and clear her mind",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9976851851851852,
        "sbert_similarity": 1.000000238418579
      }
    },
    {
      "sample_id": 0,
      "question": "What does Caroline say running has been great for?",
      "prediction": "Her mental health",
      "reference": "Her mental health",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie see at the council meeting for adoption?",
      "prediction": "Not mentioned in the conversation or many people wanting to create loving homes for children in need",
      "reference": "many people wanting to create loving homes for children in need",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 0,
        "f1": 0.8148148148148148,
        "rouge1_f": 0.7857142857142858,
        "rouge2_f": 0.7692307692307693,
        "rougeL_f": 0.7857142857142858,
        "bleu1": 0.6470588235294118,
        "bleu2": 0.6359337738364604,
        "bleu3": 0.626674120796503,
        "bleu4": 0.6102169202557912,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9479196352237105,
        "sbert_similarity": 0.9088597893714905
      }
    },
    {
      "sample_id": 0,
      "question": "What inspired Melanie's painting for the art show?",
      "prediction": "Not mentioned in the conversation",
      "reference": "visiting an LGBTQ center and wanting to capture unity and strength",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": -0.0016056559979915619
      }
    },
    {
      "sample_id": 0,
      "question": "What inspired Caroline's sculpture for the art show?",
      "prediction": "Not mentioned in the conversation",
      "reference": "visiting an LGBTQ center and wanting to capture unity and strength",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": -0.0016056559979915619
      }
    },
    {
      "sample_id": 0,
      "question": "How often does Caroline go to the beach with her kids?",
      "prediction": "Not mentioned in the conversation",
      "reference": "once or twice a year",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.05305672064423561
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline and her family see during their camping trip last year?",
      "prediction": "The view from the top was amazing! The 2 younger kids love nature.",
      "reference": "Perseid meteor shower",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.14332574605941772
      }
    },
    {
      "sample_id": 0,
      "question": "How did Caroline feel while watching the meteor shower?",
      "prediction": "in awe of the universe",
      "reference": "in awe of the universe",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.996,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "Why did Caroline choose to use colors and patterns in her pottery project?",
      "prediction": "She wanted to catch the eye and make people smile.",
      "reference": "She wanted to catch the eye and make people smile.",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9995,
        "sbert_similarity": 1.000000238418579
      }
    },
    {
      "sample_id": 0,
      "question": "Is Oscar Melanie's pet?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Yes",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.1172415167093277
      }
    },
    {
      "sample_id": 0,
      "question": "Where did Oscar hide his bone once?",
      "prediction": "Not mentioned in the conversation",
      "reference": "In Melanie's slipper",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 0,
        "f1": 0.25,
        "rouge1_f": 0.22222222222222224,
        "rouge2_f": 0.0,
        "rougeL_f": 0.22222222222222224,
        "bleu1": 0.2,
        "bleu2": 0.07071067811865477,
        "bleu3": 0.05665132701906204,
        "bleu4": 0.05372849659117709,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.15625,
        "sbert_similarity": 0.17263296246528625
      }
    },
    {
      "sample_id": 0,
      "question": "What activity did Melanie used to do with her dad?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Horseback riding",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.05627930909395218
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie make for a local church?",
      "prediction": "Not mentioned in the conversation",
      "reference": "a stained glass window",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.03617015480995178
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie find in her neighborhood during her walk?",
      "prediction": "Not mentioned in the conversation",
      "reference": "a rainbow sidewalk",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": -0.04855134338140488
      }
    },
    {
      "sample_id": 0,
      "question": "Which song motivates Melanie to be courageous?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Brave by Sara Bareilles",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": -0.004309762269258499
      }
    },
    {
      "sample_id": 0,
      "question": "What type of instrument does Caroline play?",
      "prediction": "clarinet",
      "reference": "clarinet and violin",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 0,
        "f1": 0.5,
        "rouge1_f": 0.5,
        "rouge2_f": 0.0,
        "rougeL_f": 0.5,
        "bleu1": 0.1353352832366127,
        "bleu2": 0.04279677428117006,
        "bleu3": 0.02960813390314045,
        "bleu4": 0.024066394763145416,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.17857142857142855,
        "sbert_similarity": 0.8449620604515076
      }
    },
    {
      "sample_id": 0,
      "question": "Which classical musicians does Caroline enjoy listening to?",
      "prediction": "Bach and Mozart",
      "reference": "Bach and Mozart",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "Who is Caroline a fan of in terms of modern music?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Ed Sheeran",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.09608790278434753
      }
    },
    {
      "sample_id": 0,
      "question": "What precautionary sign did Caroline see at the caf?",
      "prediction": "A sign stating that someone is not being able to leave",
      "reference": "A sign stating that someone is not being able to leave",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9996243425995492,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "What setback did Caroline face recently?",
      "prediction": "Not mentioned in the conversation",
      "reference": "She got hurt and had to take a break from pottery.",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.03774169832468033
      }
    },
    {
      "sample_id": 0,
      "question": "What does Caroline do to keep herself busy during her pottery break?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Read a book and paint.",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.08983367681503296
      }
    },
    {
      "sample_id": 0,
      "question": "What was the poetry reading that Melanie attended about?",
      "prediction": "It was a transgender poetry reading where transgender people shared their stories.",
      "reference": "It was a transgender poetry reading where transgender people shared their stories.",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9997106481481481,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "What happened to Caroline's son on their road trip?",
      "prediction": "He got into an accident",
      "reference": "He got into an accident",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.996,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "How did Caroline's son handle the accident?",
      "prediction": "He was scared but reassured by his family",
      "reference": "He was scared but reassured by his family",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9990234375,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "How did Caroline feel about her family after the accident?",
      "prediction": "They are important and mean the world to her",
      "reference": "They are important and mean the world to her",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9993141289437586,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "How did Caroline's children handle the accident?",
      "prediction": "They were scared but resilient",
      "reference": "They were scared but resilient",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.996,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "How did Caroline feel after the accident?",
      "prediction": "Grateful and thankful for her family",
      "reference": "Grateful and thankful for her family",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9976851851851852,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What was Caroline's reaction to her children enjoying the Grand Canyon?",
      "prediction": "She was happy and thankful",
      "reference": "She was happy and thankful",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.996,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline do after the road trip to relax?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Went on a nature walk or hike",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.0,
        "sbert_similarity": 0.06870588660240173
      }
    },
    {
      "sample_id": 0,
      "question": "What does Caroline love most about camping with her family?",
      "prediction": "Being present and bonding with her family",
      "reference": "Being present and bonding with her family",
      "category": 5,
      "strategy": "abstention",
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.0,
        "bert_recall": 0.0,
        "bert_f1": 0.0,
        "meteor": 0.9985422740524781,
        "sbert_similarity": 1.0000001192092896
      }
    }
  ]
}